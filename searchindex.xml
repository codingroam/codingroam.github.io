<?xml version="1.0" encoding="utf-8" standalone="yes"?><search><entry><title>B树与B+树</title><url>/post/b%E6%A0%91%E4%B8%8Eb+%E6%A0%91/</url><categories><category>Mysql</category></categories><tags><tag>数据结构</tag><tag>Mysql</tag></tags><content type="html"> B树、B+树 mysql存储引擎
一，b树 b树（balance tree）和b+树应用在数据库索引，可以认为是m叉的多路平衡查找树，但是从理论上讲，二叉树查找速度和比较次数都是最小的，为什么不用二叉树呢？
​ 平衡二叉树的查找效率是非常高的，并可以通过降低树的深度来提高查找的效率。但是当数据量非常大，树的存储的元素数量是有限的，这样会导致二叉查找树结构由于树的深度过大而造成磁盘I/O读写过于频繁，进而导致查询效率低下。另外数据量过大会导致内存空间不够容纳平衡二叉树所有结点的情况。B树是解决这个问题的很好的结构。数据库索引是存储在磁盘上的，当数据量大时，就不能把整个索引全部加载到内存了，只能逐一加载每一个磁盘页（对应索引树的节点）。所以我们要减少IO次数，对于树来说，IO次数就是树的高度，而“矮胖”就是b树的特征之一，它的每个节点最多包含m个孩子，m称为b树的阶，m的大小取决于磁盘页的大小。
​ b树在查询时的比较次数并不比二叉树少，尤其是节点中的数非常多时，但是内存的比较速度非常快，耗时可以忽略，所以只要树的高度低，IO少，就可以提高查询性能，这是b树的优势之一。
二，b+树 b+树，是b树的一种变体，查询性能更好。m阶的b+树的特征：
有n棵子树的非叶子结点中含有n个关键字（b树是n-1个），这些关键字不保存数据，只用来索引，所有数据都保存在叶子节点（b树是每个关键字都保存数据）。 所有的叶子结点中包含了全部关键字的信息，及指向含这些关键字记录的指针，且叶子结点本身依关键字的大小自小而大顺序链接。 所有的非叶子结点可以看成是索引部分，结点中仅含其子树中的最大（或最小）关键字。 通常在b+树上有两个头指针，一个指向根结点，一个指向关键字最小的叶子结点。 同一个数字会在不同节点中重复出现，根节点的最大元素就是b+树的最大元素。
三、b+树相比于b树的查询优势： b+树的中间节点不保存数据，所以磁盘页能容纳更多节点元素，更“矮胖”； b+树查询必须查找到叶子节点，b树只要匹配到即可不用管元素位置，因此b+树查找更稳定（并不慢）； 对于范围查找来说，b+树只需遍历叶子节点链表即可，b树却需要重复地中序遍历。 四、图示 B+树 InnoDB
MyISAM</content></entry><entry><title>Git设置SSH方式</title><url>/post/git%E8%AE%BE%E7%BD%AEssh%E6%96%B9%E5%BC%8F/</url><categories><category>problem-solving</category><category>Git</category></categories><tags><tag>Git</tag><tag>linux</tag><tag>problem-solving</tag></tags><content type="html"> Linux环境Git上传出现：The requested URL returned error: 403解决办法小记
Git设置SSH方式 一、Gitee场景 ​ 阿里云环境push代码失败，代码托管为Gitee。切换https方式到ssh后提交成功，方式如下：
1、在linux生成sshkey $ ssh-keygen -t rsa -C &ldquo;xxxxx@xxxxx.com
&rdquo; 按照提示完成三次回车，即可生成 ssh key cat ~/.ssh/id_rsa.pub 2、将ssh key添加到gitee仓库 通过仓库主页 「管理」->「部署公钥管理」 点击黄色方框中添加个人公钥超链接 3、在linux终端输入ssh -T git@gitee.com
首次使用需要确认并添加主机到本机SSH可信列表。若返回 Hi XXX! You've successfully authenticated, but Gitee.com does not provide shell access. 内容，则证明添加成功。
4、修改原先https的下载方式 git config &ndash;list 查看配置得到 remote.origin.url=https://gitee.com/wk_acme/git_study.git 修改 git config remote.origin.url git@gitee.com
:wk_acme/git_study.git 5、push代码成功 二、Github场景 1、首先需要检查你电脑是否已经有 SSH key 运行 git Bash 客户端，输入如下代码：
$ cd ~/.ssh $ ls 这两个命令就是检查是否已经存在 id_rsa.pub 或 id_dsa.pub 文件，如果文件已经存在，那么你可以跳过步骤2，直接进入步骤3。
2、创建一个 SSH key $ ssh-keygen -t rsa -C "your_email@example.com" 代码参数含义：
-t 指定密钥类型，默认是 rsa ，可以省略。 -C 设置注释文字，比如邮箱。 -f 指定密钥文件存储文件名。
以上代码省略了 -f 参数，因此，运行上面那条命令后会让你输入一个文件名，用于保存刚才生成的 SSH key 代码，如：
Generating public/private rsa key pair. # Enter file in which to save the key (/c/Users/you/.ssh/id_rsa): [Press enter] 当然，你也可以不输入文件名，使用默认文件名（推荐），那么就会生成 id_rsa 和 id_rsa.pub 两个秘钥文件。
接着又会提示你输入两次密码（该密码是你push文件的时候要输入的密码，而不是github管理者的密码），
当然，你也可以不输入密码，直接按回车。那么push的时候就不需要输入密码，直接提交到github上了，如：
Enter passphrase (empty for no passphrase): # Enter same passphrase again: 接下来，就会显示如下代码提示，如：
Your identification has been saved in /c/Users/you/.ssh/id_rsa. # Your public key has been saved in /c/Users/you/.ssh/id_rsa.pub. # The key fingerprint is: # 01:0f:f4:3b:ca:85:d6:17:a1:7d:f0:68:9d:f0:a2:db your_email@example.com 当你看到上面这段代码的收，那就说明，你的 SSH key 已经创建成功，你只需要添加到github的SSH key上就可以了。
3、添加你的 SSH key 到 github上面去 首先你需要拷贝 id_rsa.pub 文件的内容，你可以用编辑器打开文件复制，也可以用git命令复制该文件的内容，如：
$ clip &lt; ~/.ssh/id_rsa.pub 　Window 使用 clip 命令复制，Mac 则使用 pbcopy 命令
登录你的github账号，从又上角的设置（ Account Settings
）进入，然后点击菜单栏的 SSH key 进入页面添加 SSH key。
点击 Add SSH key 按钮添加一个 SSH key 。把你复制的 SSH key 代码粘贴到 key 所对应的输入框中，记得 SSH key 代码的前后不要留有空格或者回车。当然，上面的 Title 所对应的输入框你也可以输入一个该 SSH key 显示在 github 上的一个别名。默认的会使用你的邮件名称。
4、测试一下该SSH key 在git Bash 中输入以下代码
$ ssh -T git@github.com 当你输入以上代码时，会有一段警告代码，如：
The authenticity of host 'github.com (207.97.227.239)' can't be established. # RSA key fingerprint is 16:27:ac:a5:76:28:2d:36:63:1b:56:4d:eb:df:a6:48. # Are you sure you want to continue connecting (yes/no)? 这是正常的，你输入 yes 回车既可。如果你创建 SSH key 的时候设置了密码，接下来就会提示你输入密码，如：
Enter passphrase for key '/c/Users/Administrator/.ssh/id_rsa': 当然如果你密码输错了，会再要求你输入，知道对了为止。
注意：输入密码时如果输错一个字就会不正确，使用删除键是无法更正的。
密码正确后你会看到下面这段话，如：
Hi username! You've successfully authenticated, but GitHub does not # provide shell access. 成功！</content></entry><entry><title>Spring基础汇总</title><url>/post/spring%E5%9F%BA%E7%A1%80%E6%B1%87%E6%80%BB/</url><categories><category>Spring</category></categories><tags><tag>Spring</tag><tag>java</tag></tags><content type="html"> Spring基础汇总
Spring基础汇总 1.简介 1.1.简介 简介
Spring : 春天 —>给软件行业带来了春天
2002年，Rod Jahnson首次推出了Spring框架
雏形interface21框架。
2004年3月24日，Spring框架以interface21框架为基础，经过重新设计，发布了1.0正式版。
很难想象Rod Johnson的学历 , 他是悉尼大学的博士，然而他的专业不是计算机，而是音乐学。
Spring理念 : 使现有技术更加实用 . 本身就是一个大杂烩 , 整合现有的框架技术
官网 : http://spring.io/
官方下载地址 : https://repo.spring.io/libs-release-local/org/springframework/spring/
GitHub : https://github.com/spring-projects
&lt;!-- https://mvnrepository.com/artifact/org.springframework/spring-webmvc --> &lt;dependency> &lt;groupId>org.springframework&lt;/groupId> &lt;artifactId>spring-webmvc&lt;/artifactId> &lt;version>5.2.0.RELEASE&lt;/version> &lt;/dependency> &lt;!-- https://mvnrepository.com/artifact/org.springframework/spring-jdbc --> &lt;dependency> &lt;groupId>org.springframework&lt;/groupId> &lt;artifactId>spring-jdbc&lt;/artifactId> &lt;version>5.2.0.RELEASE&lt;/version> &lt;/dependency> 1.2.优点 优点
1、Spring是一个开源免费的框架 , 容器 .
2、Spring是一个轻量级的框架 , 非侵入式的 .
3、控制反转 IoC , 面向切面 Aop
4、对事物的支持 , 对框架的支持
…
一句话概括：
Spring是一个轻量级的控制反转(IoC)和面向切面(AOP)的容器（框架）。
1.3.组成 组成
Spring 框架是一个分层架构，由 7 个定义良好的模块组成。Spring 模块构建在核心容器之上，核心容器定义了创建、配置和管理 bean 的方式 .
组成 Spring 框架的每个模块（或组件）都可以单独存在，或者与其他一个或多个模块联合实现。每个模块的功能如下：
核心容器：核心容器提供 Spring 框架的基本功能。核心容器的主要组件是 BeanFactory，它是工厂模式的实现。BeanFactory 使用控制反转（IOC） 模式将应用程序的配置和依赖性规范与实际的应用程序代码分开。 Spring 上下文：Spring 上下文是一个配置文件，向 Spring 框架提供上下文信息。Spring 上下文包括企业服务，例如 JNDI、EJB、电子邮件、国际化、校验和调度功能。 Spring AOP：通过配置管理特性，Spring AOP 模块直接将面向切面的编程功能 , 集成到了 Spring 框架中。所以，可以很容易地使 Spring 框架管理任何支持 AOP的对象。Spring AOP 模块为基于 Spring 的应用程序中的对象提供了事务管理服务。通过使用 Spring AOP，不用依赖组件，就可以将声明性事务管理集成到应用程序中。 Spring DAO：JDBC DAO 抽象层提供了有意义的异常层次结构，可用该结构来管理异常处理和不同数据库供应商抛出的错误消息。异常层次结构简化了错误处理，并且极大地降低了需要编写的异常代码数量（例如打开和关闭连接）。Spring DAO 的面向 JDBC 的异常遵从通用的 DAO 异常层次结构。 Spring ORM：Spring 框架插入了若干个 ORM 框架，从而提供了 ORM 的对象关系工具，其中包括 JDO、Hibernate 和 iBatis SQL Map。所有这些都遵从 Spring 的通用事务和 DAO 异常层次结构。 Spring Web 模块：Web 上下文模块建立在应用程序上下文模块之上，为基于 Web 的应用程序提供了上下文。所以，Spring 框架支持与 Jakarta Struts 的集成。Web 模块还简化了处理多部分请求以及将请求参数绑定到域对象的工作。 Spring MVC 框架：MVC 框架是一个全功能的构建 Web 应用程序的 MVC 实现。通过策略接口，MVC 框架变成为高度可配置的，MVC 容纳了大量视图技术，其中包括 JSP、Velocity、Tiles、iText 和 POI。 1.4.扩展 拓展
Spring Boot与Spring Cloud
Spring Boot 是 Spring 的一套快速配置脚手架，可以基于Spring Boot 快速开发单个微服务; Spring Cloud是基于Spring Boot实现的； Spring Boot专注于快速、方便集成的单个微服务个体，Spring Cloud关注全局的服务治理框架； Spring Boot使用了约束优于配置的理念，很多集成方案已经帮你选择好了，能不配置就不配置 , Spring Cloud很大的一部分是基于Spring Boot来实现，Spring Boot可以离开Spring Cloud独立使用开发项目，但是Spring Cloud离不开Spring Boot，属于依赖的关系。 SpringBoot在SpringClound中起到了承上启下的作用，如果你要学习SpringCloud必须要学习SpringBoot。 2.IOC理论推导 IoC基础
新建一个空白的maven项目
2.1.分析实现 分析实现
我们先用我们原来的方式写一段代码 .
1、先写一个UserDao接口
public interface UserDao { public void getUser(); } 123 2、再去写Dao的实现类
public class UserDaoImpl implements UserDao { @Override public void getUser() { System.out.println("获取用户数据"); } } 3、然后去写UserService的接口
public interface UserService { public void getUser(); } 4、最后写Service的实现类
public class UserServiceImpl implements UserService { private UserDao userDao = new UserDaoImpl(); @Override public void getUser() { userDao.getUser(); } } 5、测试一下
@Test public void test(){ UserService service = new UserServiceImpl(); service.getUser(); } 这是我们原来的方式 , 开始大家也都是这么去写的对吧 . 那我们现在修改一下 .
把Userdao的实现类增加一个 .
public class UserDaoMySqlImpl implements UserDao { @Override public void getUser() { System.out.println("MySql获取用户数据"); } } 123456 紧接着我们要去使用MySql的话 , 我们就需要去service实现类里面修改对应的实现
public class UserServiceImpl implements UserService { private UserDao userDao = new UserDaoMySqlImpl(); @Override public void getUser() { userDao.getUser(); } } 在假设, 我们再增加一个Userdao的实现类 .
public class UserDaoOracleImpl implements UserDao { @Override public void getUser() { System.out.println("Oracle获取用户数据"); } } 那么我们要使用Oracle , 又需要去service实现类里面修改对应的实现 . 假设我们的这种需求非常大 , 这种方式就根本不适用了, 甚至反人类对吧 , 每次变动 , 都需要修改大量代码 . 这种设计的耦合性太高了, 牵一发而动全身 .
那我们如何去解决呢 ?
我们可以在需要用到他的地方 , 不去实现它 , 而是留出一个接口 , 利用set , 我们去代码里修改下 .
public class UserServiceImpl implements UserService { private UserDao userDao; // 利用set实现 public void setUserDao(UserDao userDao) { this.userDao = userDao; } @Override public void getUser() { userDao.getUser(); } } 现在去我们的测试类里 , 进行测试 ;
@Test public void test(){ UserServiceImpl service = new UserServiceImpl(); service.setUserDao( new UserDaoMySqlImpl() ); service.getUser(); //那我们现在又想用Oracle去实现呢 service.setUserDao( new UserDaoOracleImpl() ); service.getUser(); } 大家发现了区别没有 ? 可能很多人说没啥区别 . 但是同学们 , 他们已经发生了根本性的变化 , 很多地方都不一样了 . 仔细去思考一下 , 以前所有东西都是由程序去进行控制创建 , 而现在是由我们自行控制创建对象 , 把主动权交给了调用者 . 程序不用去管怎么创建,怎么实现了 . 它只负责提供一个接口 .
这种思想 , 从本质上解决了问题 , 我们程序员不再去管理对象的创建了 , 更多的去关注业务的实现 . 耦合性大大降低 . 这也就是IOC的原型 !
2.2.IOC本质 IOC本质
控制反转IoC(Inversion of Control)，是一种设计思想，DI(依赖注入)是实现IoC的一种方法，也有人认为DI只是IoC的另一种说法。没有IoC的程序中 , 我们使用面向对象编程 , 对象的创建与对象间的依赖关系完全硬编码在程序中，对象的创建由程序自己控制，控制反转后将对象的创建转移给第三方，个人认为所谓控制反转就是：获得依赖对象的方式反转了。
IoC是Spring框架的核心内容，使用多种方式完美的实现了IoC，可以使用XML配置，也可以使用注解，新版本的Spring也可以零配置实现IoC。
Spring容器在初始化时先读取配置文件，根据配置文件或元数据创建与组织对象存入容器中，程序使用时再从Ioc容器中取出需要的对象。
采用XML方式配置Bean的时候，Bean的定义信息是和实现分离的，而采用注解的方式可以把两者合为一体，Bean的定义信息直接以注解的形式定义在实现类中，从而达到了零配置的目的。
控制反转是一种通过描述（XML或注解）并通过第三方去生产或获取特定对象的方式。在Spring中实现控制反转的是IoC容器，其实现方法是依赖注入（Dependency Injection,DI）。
3.HelloSpring 导入Jar包
注 : spring 需要导入commons-logging进行日志记录 . 我们利用maven , 他会自动下载对应的依赖项 .
&lt;dependency> &lt;groupId>org.springframework&lt;/groupId> &lt;artifactId>spring-webmvc&lt;/artifactId> &lt;version>5.1.10.RELEASE&lt;/version> &lt;/dependency> 编写代码
1、编写一个Hello实体类
public class Hello { private String name; public String getName() { return name; } public void setName(String name) { this.name = name; } public void show(){ System.out.println("Hello,"+ name ); } } 2、编写我们的spring文件 , 这里我们命名为beans.xml
&lt;?xml version="1.0" encoding="UTF-8"?> &lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"> &lt;!--bean就是java对象 , 由Spring创建和管理--> &lt;bean id="hello" class="com.kuang.pojo.Hello"> &lt;property name="name" value="Spring"/> &lt;/bean> &lt;/beans> 3、我们可以去进行测试了 .
@Test public void test(){ //解析beans.xml文件 , 生成管理相应的Bean对象 ApplicationContext context = new ClassPathXmlApplicationContext("beans.xml"); //getBean : 参数即为spring配置文件中bean的id . Hello hello = (Hello) context.getBean("hello"); hello.show(); } 思考
Hello 对象是谁创建的 ? hello 对象是由Spring创建的 Hello 对象的属性是怎么设置的 ? hello 对象的属性是由Spring容器设置的 这个过程就叫控制反转 :
控制 : 谁来控制对象的创建 , 传统应用程序的对象是由程序本身控制创建的 , 使用Spring后 , 对象是由Spring来创建的 反转 : 程序本身不创建对象 , 而变成被动的接收对象 . 依赖注入 : 就是利用set方法来进行注入的.
IOC是一种编程思想，由主动的编程变成被动的接收
可以通过newClassPathXmlApplicationContext去浏览一下底层源码 .
修改案例一
我们在案例一中， 新增一个Spring配置文件beans.xml
&lt;?xml version="1.0" encoding="UTF-8"?> &lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"> &lt;bean id="MysqlImpl" class="com.kuang.dao.impl.UserDaoMySqlImpl"/> &lt;bean id="OracleImpl" class="com.kuang.dao.impl.UserDaoOracleImpl"/> &lt;bean id="ServiceImpl" class="com.kuang.service.impl.UserServiceImpl"> &lt;!--注意: 这里的name并不是属性 , 而是set方法后面的那部分 , 首字母小写--> &lt;!--引用另外一个bean , 不是用value 而是用 ref--> &lt;property name="userDao" ref="OracleImpl"/> &lt;/bean> &lt;/beans> 测试！
@Test public void test2(){ ApplicationContext context = new ClassPathXmlApplicationContext("beans.xml"); UserServiceImpl serviceImpl = (UserServiceImpl) context.getBean("ServiceImpl"); serviceImpl.getUser(); } 123456 OK , 到了现在 , 我们彻底不用再程序中去改动了 , 要实现不同的操作 , 只需要在xml配置文件中进行修改 , 所谓的IoC,一句话搞定 : 对象由Spring 来创建 , 管理 , 装配 !
4.IOC创建对象方式 4.1.通过无参构造方法来创建 通过无参构造方法来创建
1、User.java
public class User { private String name; public User() { System.out.println("user无参构造方法"); } public void setName(String name) { this.name = name; } public void show(){ System.out.println("name="+ name ); } } 1234567891011121314151617 2、beans.xml
&lt;?xml version="1.0" encoding="UTF-8"?> &lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"> &lt;bean id="user" class="com.kuang.pojo.User"> &lt;property name="name" value="kuangshen"/> &lt;/bean> &lt;/beans> 3、测试类
@Test public void test(){ ApplicationContext context = new ClassPathXmlApplicationContext("beans.xml"); //在执行getBean的时候, user已经创建好了 , 通过无参构造 User user = (User) context.getBean("user"); //调用对象的方法 . user.show(); } 结果可以发现，在调用show方法之前，User对象已经通过无参构造初始化了！
4.2.通过有参构造方法来创建 通过有参构造方法来创建
1、UserT . java
public class UserT { private String name; public UserT(String name) { this.name = name; } public void setName(String name) { this.name = name; } public void show(){ System.out.println("name="+ name ); } } 2、beans.xml 有三种方式编写
&lt;!-- 第一种根据index参数下标设置 --> &lt;bean id="userT" class="com.kuang.pojo.UserT"> &lt;!-- index指构造方法 , 下标从0开始 --> &lt;constructor-arg index="0" value="kuangshen2"/> &lt;/bean> &lt;!-- 第二种根据参数名字设置 --> &lt;bean id="userT" class="com.kuang.pojo.UserT"> &lt;!-- name指参数名 --> &lt;constructor-arg name="name" value="kuangshen2"/> &lt;/bean> &lt;!-- 第三种根据参数类型设置 --> &lt;bean id="userT" class="com.kuang.pojo.UserT"> &lt;constructor-arg type="java.lang.String" value="kuangshen2"/> &lt;/bean> 3、测试
@Test public void testT(){ ApplicationContext context = new ClassPathXmlApplicationContext("beans.xml"); UserT user = (UserT) context.getBean("userT"); user.show(); } 123456 结论：在配置文件加载的时候。其中管理的对象都已经初始化了！
5.Spring配置 5.1.别名 别名
alias 设置别名 , 为bean设置别名 , 可以设置多个别名
&lt;!--设置别名：在获取Bean的时候可以使用别名获取--> &lt;alias name="userT" alias="userNew"/> 5.2.Bean的配置 Bean的配置
&lt;!--bean就是java对象,由Spring创建和管理--> &lt;!-- id 是bean的标识符,要唯一,如果没有配置id,name就是默认标识符 如果配置id,又配置了name,那么name是别名 name可以设置多个别名,可以用逗号,分号,空格隔开 如果不配置id和name,可以根据applicationContext.getBean(.class)获取对象; class是bean的全限定名=包名+类名 --> &lt;bean id="hello" name="hello2 h2,h3;h4" class="com.kuang.pojo.Hello"> &lt;property name="name" value="Spring"/> &lt;/bean> 5.3.import import
团队的合作通过import来实现 .
&lt;import resource="{path}/beans.xml"/> 1 6.依赖注入（DI） Dependency Injection
概念
依赖注入（Dependency Injection,DI）。 依赖 : 指Bean对象的创建依赖于容器 . Bean对象的依赖资源 . 注入 : 指Bean对象所依赖的资源 , 由容器来设置和装配 . 6.1.构造器注入 构造器注入
我们在之前的案例已经讲过了
6.2.Set 注入 （重点） Set 注入 （重点）
要求被注入的属性 , 必须有set方法 , set方法的方法名由set + 属性首字母大写 , 如果属性是boolean类型 , 没有set方法 , 是 is .
测试pojo类 :
Address.java
public class Address { private String address; public String getAddress() { return address; } public void setAddress(String address) { this.address = address; } } Student.java
package com.kuang.pojo; import java.util.List; import java.util.Map; import java.util.Properties; import java.util.Set; public class Student { private String name; private Address address; private String[] books; private List&lt;String> hobbys; private Map&lt;String,String> card; private Set&lt;String> games; private String wife; private Properties info; public void setName(String name) { this.name = name; } public void setAddress(Address address) { this.address = address; } public void setBooks(String[] books) { this.books = books; } public void setHobbys(List&lt;String> hobbys) { this.hobbys = hobbys; } public void setCard(Map&lt;String, String> card) { this.card = card; } public void setGames(Set&lt;String> games) { this.games = games; } public void setWife(String wife) { this.wife = wife; } public void setInfo(Properties info) { this.info = info; } public void show(){ System.out.println("name="+ name + ",address="+ address.getAddress() + ",books=" ); for (String book:books){ System.out.print("&lt;&lt;"+book+">>\t"); } System.out.println("\n爱好:"+hobbys); System.out.println("card:"+card); System.out.println("games:"+games); System.out.println("wife:"+wife); System.out.println("info:"+info); } } 6.3.扩展的注入 1、常量注入
&lt;bean id="student" class="com.kuang.pojo.Student"> &lt;property name="name" value="小明"/> &lt;/bean> 测试：
@Test public void test01(){ ApplicationContext context = new ClassPathXmlApplicationContext("applicationContext.xml"); Student student = (Student) context.getBean("student"); System.out.println(student.getName()); } 2、Bean注入
注意点：这里的值是一个引用，ref
&lt;bean id="addr" class="com.kuang.pojo.Address"> &lt;property name="address" value="重庆"/> &lt;/bean> &lt;bean id="student" class="com.kuang.pojo.Student"> &lt;property name="name" value="小明"/> &lt;property name="address" ref="addr"/> &lt;/bean> 3、数组注入
&lt;bean id="student" class="com.kuang.pojo.Student"> &lt;property name="name" value="小明"/> &lt;property name="address" ref="addr"/> &lt;property name="books"> &lt;array> &lt;value>西游记&lt;/value> &lt;value>红楼梦&lt;/value> &lt;value>水浒传&lt;/value> &lt;/array> &lt;/property> &lt;/bean> 4、List注入
&lt;property name="hobbys"> &lt;list> &lt;value>听歌&lt;/value> &lt;value>看电影&lt;/value> &lt;value>爬山&lt;/value> &lt;/list> &lt;/property> 5、Map注入
&lt;property name="card"> &lt;map> &lt;entry key="中国邮政" value="456456456465456"/> &lt;entry key="建设" value="1456682255511"/> &lt;/map> &lt;/property> 6、set注入
&lt;property name="games"> &lt;set> &lt;value>LOL&lt;/value> &lt;value>BOB&lt;/value> &lt;value>COC&lt;/value> &lt;/set> &lt;/property> 7、Null注入
&lt;property name="wife">&lt;null/>&lt;/property> 8、Properties注入
&lt;property name="info"> &lt;props> &lt;prop key="学号">20190604&lt;/prop> &lt;prop key="性别">男&lt;/prop> &lt;prop key="姓名">小明&lt;/prop> &lt;/props> &lt;/property> 测试结果： 9、p命名和c命名注入
p命名和c命名注入
User.java ：【注意：这里没有有参构造器！】
public class User { private String name; private int age; public void setName(String name) { this.name = name; } public void setAge(int age) { this.age = age; } @Override public String toString() { return "User{" + "name='" + name + '\'' + ", age=" + age + '}'; } } 1、P命名空间注入 : 需要在头文件中加入约束文件
导入约束 : xmlns:p="http://www.springframework.org/schema/p" &lt;!--P(属性: properties)命名空间 , 直接注入属性--> &lt;bean id="user" class="com.kuang.pojo.User" p:name="狂神" p:age="18"/> 2、c 命名空间注入 : 需要在头文件中加入约束文件
导入约束 : xmlns:c="http://www.springframework.org/schema/c" &lt;!--C(构造: Constructor)命名空间 , 使用构造器注入--> &lt;bean id="user" class="com.kuang.pojo.User" c:name="狂神" c:age="18"/> 发现问题：爆红了，刚才我们没有写有参构造！
解决：把有参构造器加上，这里也能知道，c 就是所谓的构造器注入！
测试代码：
@Test public void test02(){ ApplicationContext context = new ClassPathXmlApplicationContext("applicationContext.xml"); User user = (User) context.getBean("user"); System.out.println(user); } 6.4.Bean的作用域 Bean的作用域
在Spring中，那些组成应用程序的主体及由Spring IoC容器所管理的对象，被称之为bean。简单地讲，bean就是由IoC容器初始化、装配及管理的对象 . 几种作用域中，request、session作用域仅在基于web的应用中使用（不必关心你所采用的是什么web应用框架），只能用在基于web的Spring ApplicationContext环境。
Singleton(单例模式) 当一个bean的作用域为Singleton，那么Spring IoC容器中只会存在一个共享的bean实例，并且所有对bean的请求，只要id与该bean定义相匹配，则只会返回bean的同一实例。Singleton是单例类型，就是在创建起容器时就同时自动创建了一个bean的对象，不管你是否使用，他都存在了，每次获取到的对象都是同一个对象。注意，Singleton作用域是Spring中的缺省作用域。要在XML中将bean定义成singleton，可以这样配置：
&lt;bean id="ServiceImpl" class="cn.csdn.service.ServiceImpl" scope="singleton"> 测试：
@Test public void test03(){ ApplicationContext context = new ClassPathXmlApplicationContext("applicationContext.xml"); User user = (User) context.getBean("user"); User user2 = (User) context.getBean("user"); System.out.println(user==user2); } Prototype(原型模式) 当一个bean的作用域为Prototype，表示一个bean定义对应多个对象实例。Prototype作用域的bean会导致在每次对该bean请求（将其注入到另一个bean中，或者以程序的方式调用容器的getBean()方法）时都会创建一个新的bean实例。Prototype是原型类型，它在我们创建容器的时候并没有实例化，而是当我们获取bean的时候才会去创建一个对象，而且我们每次获取到的对象都不是同一个对象。根据经验，对有状态的bean应该使用prototype作用域，而对无状态的bean则应该使用singleton作用域。在XML中将bean定义成prototype，可以这样配置：
&lt;bean id="account" class="com.foo.DefaultAccount" scope="prototype"/> 或者 &lt;bean id="account" class="com.foo.DefaultAccount" singleton="false"/> Request 当一个bean的作用域为Request，表示在一次HTTP请求中，一个bean定义对应一个实例；即每个HTTP请求都会有各自的bean实例，它们依据某个bean定义创建而成。该作用域仅在基于web的Spring ApplicationContext情形下有效。考虑下面bean定义：
&lt;bean id="loginAction" class=cn.csdn.LoginAction" scope="request"/> 1 针对每次HTTP请求，Spring容器会根据loginAction bean的定义创建一个全新的LoginAction bean实例，且该loginAction bean实例仅在当前HTTP request内有效，因此可以根据需要放心的更改所建实例的内部状态，而其他请求中根据loginAction bean定义创建的实例，将不会看到这些特定于某个请求的状态变化。当处理请求结束，request作用域的bean实例将被销毁。
Session 当一个bean的作用域为Session，表示在一个HTTP Session中，一个bean定义对应一个实例。该作用域仅在基于web的Spring ApplicationContext情形下有效。考虑下面bean定义：
&lt;bean id="userPreferences" class="com.foo.UserPreferences" scope="session"/> 1 针对某个HTTP Session，Spring容器会根据userPreferences bean定义创建一个全新的userPreferences bean实例，且该userPreferences bean仅在当前HTTP Session内有效。与request作用域一样，可以根据需要放心的更改所创建实例的内部状态，而别的HTTP Session中根据userPreferences创建的实例，将不会看到这些特定于某个HTTP Session的状态变化。当HTTP Session最终被废弃的时候，在该HTTP Session作用域内的bean也会被废弃掉。
7.Bean的自动装配 自动装配说明
自动装配是使用spring满足bean依赖的一种方法 spring会在应用上下文中为某个bean寻找其依赖的bean。 Spring中bean有三种装配机制，分别是：
在xml中显式配置； 在java中显式配置； 隐式的bean发现机制和自动装配。 这里我们主要讲第三种：自动化的装配bean。
Spring的自动装配需要从两个角度来实现，或者说是两个操作：
组件扫描(component scanning)：spring会自动发现应用上下文中所创建的bean； 自动装配(autowiring)：spring自动满足bean之间的依赖，也就是我们说的IoC/DI； 组件扫描和自动装配组合发挥巨大威力，使得显示的配置降低到最少。
推荐不使用自动装配xml配置 , 而使用注解 .
** **
测试环境搭建
1、新建一个项目
2、新建两个实体类，Cat Dog 都有一个叫的方法
public class Cat { public void shout() { System.out.println("miao~"); } } public class Dog { public void shout() { System.out.println("wang~"); } } 3、新建一个用户类 User
public class User { private Cat cat; private Dog dog; private String str; } 4、编写Spring配置文件
&lt;?xml version="1.0" encoding="UTF-8"?> &lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"> &lt;bean id="dog" class="com.kuang.pojo.Dog"/> &lt;bean id="cat" class="com.kuang.pojo.Cat"/> &lt;bean id="user" class="com.kuang.pojo.User"> &lt;property name="cat" ref="cat"/> &lt;property name="dog" ref="dog"/> &lt;property name="str" value="qinjiang"/> &lt;/bean> &lt;/beans> 5、测试
public class MyTest { @Test public void testMethodAutowire() { ApplicationContext context = new ClassPathXmlApplicationContext("beans.xml"); User user = (User) context.getBean("user"); user.getCat().shout(); user.getDog().shout(); } } 结果正常输出，环境OK
7.1.byName byName
autowire byName (按名称自动装配)
由于在手动配置xml过程中，常常发生字母缺漏和大小写等错误，而无法对其进行检查，使得开发效率降低。
采用自动装配将避免这些错误，并且使配置简单化。
测试：
1、修改bean配置，增加一个属性 autowire=“byName”
&lt;bean id="user" class="com.kuang.pojo.User" autowire="byName"> &lt;property name="str" value="qinjiang"/> &lt;/bean> 2、再次测试，结果依旧成功输出！
3、我们将 cat 的bean id修改为 catXXX
4、再次测试， 执行时报空指针java.lang.NullPointerException。因为按byName规则找不对应set方法，真正的setCat就没执行，对象就没有初始化，所以调用时就会报空指针错误。
小结：
当一个bean节点带有 autowire byName的属性时。
将查找其类中所有的set方法名，例如setCat，获得将set去掉并且首字母小写的字符串，即cat。 去spring容器中寻找是否有此字符串名称id的对象。 如果有，就取出注入；如果没有，就报空指针异常。 7.2.byType byType
autowire byType (按类型自动装配)
使用autowire byType首先需要保证：同一类型的对象，在spring容器中唯一。如果不唯一，会报不唯一的异常。
NoUniqueBeanDefinitionException 测试：
1、将user的bean配置修改一下 ： autowire=“byType”
2、测试，正常输出
3、在注册一个cat 的bean对象！
&lt;bean id="dog" class="com.kuang.pojo.Dog"/> &lt;bean id="cat" class="com.kuang.pojo.Cat"/> &lt;bean id="cat2" class="com.kuang.pojo.Cat"/> &lt;bean id="user" class="com.kuang.pojo.User" autowire="byType"> &lt;property name="str" value="qinjiang"/> &lt;/bean> 1234567 4、测试，报错：NoUniqueBeanDefinitionException
5、删掉cat2，将cat的bean名称改掉！测试！因为是按类型装配，所以并不会报异常，也不影响最后的结果。甚至将id属性去掉，也不影响结果。
这就是按照类型自动装配！
7.3.使用注解 使用注解
jdk1.5开始支持注解，spring2.5开始全面支持注解。
准备工作：利用注解的方式注入属性。
1、在spring配置文件中引入context文件头
xmlns:context="http://www.springframework.org/schema/context" http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd 2、开启属性注解支持！
&lt;context:annotation-config/> @Autowired @Autowired是按类型自动转配的，不支持id匹配。 需要导入 spring-aop的包！ 测试：
1、将User类中的set方法去掉，使用@Autowired注解
public class User { @Autowired private Cat cat; @Autowired private Dog dog; private String str; public Cat getCat() { return cat; } public Dog getDog() { return dog; } public String getStr() { return str; } } 2、此时配置文件内容
&lt;context:annotation-config/> &lt;bean id="dog" class="com.kuang.pojo.Dog"/> &lt;bean id="cat" class="com.kuang.pojo.Cat"/> &lt;bean id="user" class="com.kuang.pojo.User"/> 3、测试，成功输出结果！
【小狂神科普时间】
@Autowired(required=false) 说明：false，对象可以为null；true，对象必须存对象，不能为null。
//如果允许对象为null，设置required = false,默认为true @Autowired(required = false) private Cat cat; @Qualifier @Autowired是根据类型自动装配的，加上@Qualifier则可以根据byName的方式自动装配 @Qualifier不能单独使用。 测试实验步骤：
1、配置文件修改内容，保证类型存在对象。且名字不为类的默认名字！
&lt;bean id="dog1" class="com.kuang.pojo.Dog"/> &lt;bean id="dog2" class="com.kuang.pojo.Dog"/> &lt;bean id="cat1" class="com.kuang.pojo.Cat"/> &lt;bean id="cat2" class="com.kuang.pojo.Cat"/> 2、没有加Qualifier测试，直接报错
3、在属性上添加Qualifier注解
@Autowired @Qualifier(value = "cat2") private Cat cat; @Autowired @Qualifier(value = "dog2") private Dog dog; 测试，成功输出！
@Resource @Resource如有指定的name属性，先按该属性进行byName方式查找装配； 其次再进行默认的byName方式进行装配； 如果以上都不成功，则按byType的方式自动装配。 都不成功，则报异常。 实体类：
public class User { //如果允许对象为null，设置required = false,默认为true @Resource(name = "cat2") private Cat cat; @Resource private Dog dog; private String str; } beans.xml
&lt;bean id="dog" class="com.kuang.pojo.Dog"/> &lt;bean id="cat1" class="com.kuang.pojo.Cat"/> &lt;bean id="cat2" class="com.kuang.pojo.Cat"/> &lt;bean id="user" class="com.kuang.pojo.User"/> 测试：结果OK
配置文件2：beans.xml ， 删掉cat2
&lt;bean id="dog" class="com.kuang.pojo.Dog"/> &lt;bean id="cat1" class="com.kuang.pojo.Cat"/> 实体类上只保留注解
@Resource private Cat cat; @Resource private Dog dog; 结果：OK
结论：先进行byName查找，失败；再进行byType查找，成功。
小结
@Autowired与@Resource异同：
1、@Autowired与@Resource都可以用来装配bean。都可以写在字段上，或写在setter方法上。
2、@Autowired默认按类型装配（属于spring规范），默认情况下必须要求依赖对象必须存在，如果要允许null 值，可以设置它的required属性为false，如：@Autowired(required=false) ，如果我们想使用名称装配可以结合@Qualifier注解进行使用
3、@Resource（属于J2EE复返），默认按照名称进行装配，名称可以通过name属性进行指定。如果没有指定name属性，当注解写在字段上时，默认取字段名进行按照名称查找，如果注解写在setter方法上默认取属性名进行装配。当找不到与名称匹配的bean时才按照类型进行装配。但是需要注意的是，如果name属性一旦指定，就只会按照名称进行装配。
它们的作用相同都是用注解方式注入对象，但执行顺序不同。@Autowired先byType，@Resource先byName。
8.使用注解开发 说明
在spring4之后，想要使用注解形式，必须得要引入aop的包
在配置文件当中，还得要引入一个context约束
&lt;?xml version="1.0" encoding="UTF-8"?> &lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd"> &lt;/beans> 8.1.Bean的实现 我们之前都是使用 bean 的标签进行bean注入，但是实际开发中，我们一般都会使用注解！
1、配置扫描哪些包下的注解 &lt;!--指定注解扫描包--> &lt;context:component-scan base-package="com.kuang.pojo"/> 2、在指定包下编写类，增加注解
@Component("user") // 相当于配置文件中 &lt;bean id="user" class="当前注解的类"/> public class User { public String name = "秦疆"; } 3、测试
@Test public void test(){ ApplicationContext applicationContext = new ClassPathXmlApplicationContext("beans.xml"); User user = (User) applicationContext.getBean("user"); System.out.println(user.name); } 8.2.属性注入 使用注解注入属性
1、可以不用提供set方法，直接在直接名上添加@value(“值”)
@Component("user") // 相当于配置文件中 &lt;bean id="user" class="当前注解的类"/> public class User { @Value("秦疆") // 相当于配置文件中 &lt;property name="name" value="秦疆"/> public String name; } 2、如果提供了set方法，在set方法上添加@value(“值”);
@Component("user") public class User { public String name; @Value("秦疆") public void setName(String name) { this.name = name; } } 8.3.衍生注解 我们这些注解，就是替代了在配置文件当中配置步骤而已！更加的方便快捷！
@Component三个衍生注解
为了更好的进行分层，Spring可以使用其它三个注解，功能一样，目前使用哪一个功能都一样。
@Controller：controller层 @Service：service层 @Repository：dao层 写上这些注解，就相当于将这个类交给Spring管理装配了！
8.4.自动装配注解 在Bean的自动装配已经讲过了，可以回顾！
8.5.作用域 @scope
singleton：默认的，Spring会采用单例模式创建这个对象。关闭工厂 ，所有的对象都会销毁。 prototype：多例模式。关闭工厂 ，所有的对象不会销毁。内部的垃圾回收机制会回收 @Controller("user") @Scope("prototype") public class User { @Value("秦疆") public String name; } 8.6.小结 XML与注解比较
XML可以适用任何场景 ，结构清晰，维护方便 注解不是自己提供的类使用不了，开发简单方便 xml与注解整合开发 ：推荐最佳实践
xml管理Bean 注解完成属性注入 使用过程中， 可以不用扫描，扫描是为了类上的注解 &lt;context:annotation-config/> 作用：
进行注解驱动注册，从而使注解生效 用于激活那些已经在spring容器里注册过的bean上面的注解，也就是显示的向Spring注册 如果不扫描包，就需要手动配置bean 如果不加注解驱动，则注入的值为null！ 9.基于Java类进行配置 JavaConfig 原来是 Spring 的一个子项目，它通过 Java 类的方式提供 Bean 的定义信息，在 Spring4 的版本， JavaConfig 已正式成为 Spring4 的核心功能 。
测试：
1、编写一个实体类，Dog
@Component //将这个类标注为Spring的一个组件，放到容器中！ public class Dog { public String name = "dog"; } 2、新建一个config配置包，编写一个MyConfig配置类
@Configuration //代表这是一个配置类 public class MyConfig { @Bean //通过方法注册一个bean，这里的返回值就Bean的类型，方法名就是bean的id！ public Dog dog(){ return new Dog(); } } 3、测试
@Test public void test2(){ ApplicationContext applicationContext = new AnnotationConfigApplicationContext(MyConfig.class); Dog dog = (Dog) applicationContext.getBean("dog"); System.out.println(dog.name); } 4、成功输出结果！
导入其他配置如何做呢？
1、我们再编写一个配置类！
@Configuration //代表这是一个配置类 public class MyConfig2 { } 2、在之前的配置类中我们来选择导入这个配置类
@Configuration @Import(MyConfig2.class) //导入合并其他配置类，类似于配置文件中的 inculde 标签 public class MyConfig { @Bean public Dog dog(){ return new Dog(); } } 关于这种Java类的配置方式，我们在之后的SpringBoot 和 SpringCloud中还会大量看到，我们需要知道这些注解的作用即可！
10.代理模式 为什么要学习代理模式，因为AOP的底层机制就是动态代理！
代理模式：
静态代理 动态代理 学习aop之前 , 我们要先了解一下代理模式！
10.1静态代理 静态代理角色分析
抽象角色 : 一般使用接口或者抽象类来实现 真实角色 : 被代理的角色 代理角色 : 代理真实角色 ; 代理真实角色后 , 一般会做一些附属的操作 . 客户 : 使用代理角色来进行一些操作 . 代码实现
Rent . java 即抽象角色
//抽象角色：租房 public interface Rent { public void rent(); } Host . java 即真实角色
//真实角色: 房东，房东要出租房子 public class Host implements Rent{ public void rent() { System.out.println("房屋出租"); } } Proxy . java 即代理角色
//代理角色：中介 public class Proxy implements Rent { private Host host; public Proxy() { } public Proxy(Host host) { this.host = host; } //租房 public void rent(){ seeHouse(); host.rent(); fare(); } //看房 public void seeHouse(){ System.out.println("带房客看房"); } //收中介费 public void fare(){ System.out.println("收中介费"); } Client . java 即客户
//客户类，一般客户都会去找代理！ public class Client { public static void main(String[] args) { //房东要租房 Host host = new Host(); //中介帮助房东 Proxy proxy = new Proxy(host); //你去找中介！ proxy.rent(); } } 分析：在这个过程中，你直接接触的就是中介，就如同现实生活中的样子，你看不到房东，但是你依旧租到了房东的房子通过代理，这就是所谓的代理模式，程序源自于生活，所以学编程的人，一般能够更加抽象的看待生活中发生的事情。
静态代理的好处:
可以使得我们的真实角色更加纯粹 . 不再去关注一些公共的事情 . 公共的业务由代理来完成 . 实现了业务的分工 , 公共业务发生扩展时变得更加集中和方便 . 缺点 :
类多了 , 多了代理类 , 工作量变大了 . 开发效率降低 . 我们想要静态代理的好处，又不想要静态代理的缺点，所以 , 就有了动态代理 !
10.2.静态代理再理解 同学们练习完毕后，我们再来举一个例子，巩固大家的学习！
练习步骤：
1、创建一个抽象角色，比如咋们平时做的用户业务，抽象起来就是增删改查！
//抽象角色：增删改查业务 public interface UserService { void add(); void delete(); void update(); void query(); } 2、我们需要一个真实对象来完成这些增删改查操作
//真实对象，完成增删改查操作的人 public class UserServiceImpl implements UserService { public void add() { System.out.println("增加了一个用户"); } public void delete() { System.out.println("删除了一个用户"); } public void update() { System.out.println("更新了一个用户"); } public void query() { System.out.println("查询了一个用户"); } } 3、需求来了，现在我们需要增加一个日志功能，怎么实现！
思路1 ：在实现类上增加代码 【麻烦！】 思路2：使用代理来做，能够不改变原来的业务情况下，实现此功能就是最好的了！ 4、设置一个代理类来处理日志！代理角色
//代理角色，在这里面增加日志的实现 public class UserServiceProxy implements UserService { private UserServiceImpl userService; public void setUserService(UserServiceImpl userService) { this.userService = userService; } public void add() { log("add"); userService.add(); } public void delete() { log("delete"); userService.delete(); } public void update() { log("update"); userService.update(); } public void query() { log("query"); userService.query(); } public void log(String msg){ System.out.println("执行了"+msg+"方法"); } } 5、测试访问类：
public class Client { public static void main(String[] args) { //真实业务 UserServiceImpl userService = new UserServiceImpl(); //代理类 UserServiceProxy proxy = new UserServiceProxy(); //使用代理类实现日志功能！ proxy.setUserService(userService); proxy.add(); } } OK，到了现在代理模式大家应该都没有什么问题了，重点大家需要理解其中的思想；
我们在不改变原来的代码的情况下，实现了对原有功能的增强，这是AOP中最核心的思想
聊聊AOP：纵向开发，横向开发
10.3动态代理 动态代理的角色和静态代理的一样 . 动态代理的代理类是动态生成的 . 静态代理的代理类是我们提前写好的 动态代理分为两类 : 一类是基于接口动态代理 , 一类是基于类的动态代理 基于接口的动态代理&mdash;-JDK动态代理 基于类的动态代理–cglib 现在用的比较多的是 javasist 来生成动态代理 . 百度一下javasist 我们这里使用JDK的原生代码来实现，其余的道理都是一样的！、 JDK的动态代理需要了解两个类
核心 : InvocationHandler 和 Proxy ， 打开JDK帮助文档看看
【InvocationHandler：调用处理程序】
Object invoke(Object proxy, 方法 method, Object[] args)； //参数 //proxy - 调用该方法的代理实例 //method -所述方法对应于调用代理实例上的接口方法的实例。方法对象的声明类将是该方法声明的接口，它可以是代理类继承该方法的代理接口的超级接口。 //args -包含的方法调用传递代理实例的参数值的对象的阵列，或null如果接口方法没有参数。原始类型的参数包含在适当的原始包装器类的实例中，例如java.lang.Integer或java.lang.Boolean 。 【Proxy : 代理】
//生成代理类 public Object getProxy(){ return Proxy.newProxyInstance(this.getClass().getClassLoader(), rent.getClass().getInterfaces(),this); } 代码实现
抽象角色和真实角色和之前的一样！
Rent . java 即抽象角色
//抽象角色：租房 public interface Rent { public void rent(); } 1234 Host . java 即真实角色
//真实角色: 房东，房东要出租房子 public class Host implements Rent{ public void rent() { System.out.println("房屋出租"); } } 123456 ProxyInvocationHandler. java 即代理角色
public class ProxyInvocationHandler implements InvocationHandler { private Rent rent; public void setRent(Rent rent) { this.rent = rent; } //生成代理类，重点是第二个参数，获取要代理的抽象角色！之前都是一个角色，现在可以代理一类角色 public Object getProxy(){ return Proxy.newProxyInstance(this.getClass().getClassLoader(), rent.getClass().getInterfaces(),this); } // proxy : 代理类 method : 代理类的调用处理程序的方法对象. // 处理代理实例上的方法调用并返回结果 @Override public Object invoke(Object proxy, Method method, Object[] args) throwsThrowable { seeHouse(); //核心：本质利用反射实现！ Object result = method.invoke(rent, args); fare(); return result; } //看房 public void seeHouse(){ System.out.println("带房客看房"); } //收中介费 public void fare(){ System.out.println("收中介费"); } } 12345678910111213141516171819202122232425262728293031323334 Client . java
//租客 public class Client { public static void main(String[] args) { //真实角色 Host host = new Host(); //代理实例的调用处理程序 ProxyInvocationHandler pih = new ProxyInvocationHandler(); pih.setRent(host); //将真实角色放置进去！ Rent proxy = (Rent)pih.getProxy(); //动态生成对应的代理类！ proxy.rent(); } } 核心：一个动态代理 , 一般代理某一类业务 , 一个动态代理可以代理多个类，代理的是接口！、
10.4深化理解 我们来使用动态代理实现代理我们后面写的UserService！
我们也可以编写一个通用的动态代理实现的类！所有的代理对象设置为Object即可！
public class ProxyInvocationHandler implements InvocationHandler { private Object target; public void setTarget(Object target) { this.target = target; } //生成代理类 public Object getProxy(){ return Proxy.newProxyInstance(this.getClass().getClassLoader(), target.getClass().getInterfaces(),this); } // proxy : 代理类 // method : 代理类的调用处理程序的方法对象. public Object invoke(Object proxy, Method method, Object[] args) throwsThrowable { log(method.getName()); Object result = method.invoke(target, args); return result; } public void log(String methodName){ System.out.println("执行了"+methodName+"方法"); } } 测试！
public class Test { public static void main(String[] args) { //真实对象 UserServiceImpl userService = new UserServiceImpl(); //代理对象的调用处理程序 ProxyInvocationHandler pih = new ProxyInvocationHandler(); pih.setTarget(userService); //设置要代理的对象 UserService proxy = (UserService)pih.getProxy(); //动态生成代理类！ proxy.delete(); } } 测试，增删改查，查看结果！
10.5动态代理的好处 静态代理有的它都有，静态代理没有的，它也有！
可以使得我们的真实角色更加纯粹 . 不再去关注一些公共的事情 . 公共的业务由代理来完成 . 实现了业务的分工 , 公共业务发生扩展时变得更加集中和方便 . 一个动态代理 , 一般代理某一类业务 一个动态代理可以代理多个类，代理的是接口！ 11.AOP 11.1.什么是AOP AOP（Aspect Oriented Programming）意为：面向切面编程，通过预编译方式和运行期动态代理实现程序功能的统一维护的一种技术。AOP是OOP的延续，是软件开发中的一个热点，也是Spring框架中的一个重要内容，是函数式编程的一种衍生范型。利用AOP可以对业务逻辑的各个部分进行隔离，从而使得业务逻辑各部分之间的耦合度降低，提高程序的可重用性，同时提高了开发的效率。
11.2.Aop在Spring中的作用 提供声明式事务；允许用户自定义切面
以下名词需要了解下：
横切关注点：跨越应用程序多个模块的方法或功能。即是，与我们业务逻辑无关的，但是我们需要关注的部分，就是横切关注点。如日志 , 安全 , 缓存 , 事务等等 … 切面（ASPECT）：横切关注点 被模块化 的特殊对象。即，它是一个类。 通知（Advice）：切面必须要完成的工作。即，它是类中的一个方法。 目标（Target）：被通知对象。 代理（Proxy）：向目标对象应用通知之后创建的对象。 切入点（PointCut）：切面通知 执行的 “地点”的定义。 连接点（JointPoint）：与切入点匹配的执行点。 SpringAOP中，通过Advice定义横切逻辑，Spring中支持5种类型的Advice:
即 Aop 在 不改变原有代码的情况下 , 去增加新的功能 .
11.3.使用Spring实现Aop 【重点】使用AOP织入，需要导入一个依赖包！
&lt;!-- https://mvnrepository.com/artifact/org.aspectj/aspectjweaver --> &lt;dependency> &lt;groupId>org.aspectj&lt;/groupId> &lt;artifactId>aspectjweaver&lt;/artifactId> &lt;version>1.9.4&lt;/version> &lt;/dependency> 11.3.1.通过 Spring API 实现 第一种方式
首先编写我们的业务接口和实现类
public interface UserService { public void add(); public void delete(); public void update(); public void search(); } public class UserServiceImpl implements UserService{ @Override public void add() { System.out.println("增加用户"); } @Override public void delete() { System.out.println("删除用户"); } @Override public void update() { System.out.println("更新用户"); } @Override public void search() { System.out.println("查询用户"); } } 然后去写我们的增强类 , 我们编写两个 , 一个前置增强 一个后置增强
public class Log implements MethodBeforeAdvice { //method : 要执行的目标对象的方法 //objects : 被调用的方法的参数 //Object : 目标对象 @Override public void before(Method method, Object[] objects, Object o) throws Throwable { System.out.println( o.getClass().getName() + "的" + method.getName() + "方法被执行了"); } } public class AfterLog implements AfterReturningAdvice { //returnValue 返回值 //method被调用的方法 //args 被调用的方法的对象的参数 //target 被调用的目标对象 @Override public void afterReturning(Object returnValue, Method method, Object[] args,Object target) throws Throwable { System.out.println("执行了" + target.getClass().getName() +"的"+method.getName()+"方法," +"返回值："+returnValue); } } 最后去spring的文件中注册 , 并实现aop切入实现 , 注意导入约束 .
&lt;?xml version="1.0" encoding="UTF-8"?> &lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:aop="http://www.springframework.org/schema/aop" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd"> &lt;!--注册bean--> &lt;bean id="userService" class="com.kuang.service.UserServiceImpl"/> &lt;bean id="log" class="com.kuang.log.Log"/> &lt;bean id="afterLog" class="com.kuang.log.AfterLog"/> &lt;!--aop的配置--> &lt;aop:config> &lt;!--切入点 expression:表达式匹配要执行的方法--> &lt;aop:pointcut id="pointcut" expression="execution(* com.kuang.service.UserServiceImpl.*(..))"/> &lt;!--执行环绕; advice-ref执行方法 . pointcut-ref切入点--> &lt;aop:advisor advice-ref="log" pointcut-ref="pointcut"/> &lt;aop:advisor advice-ref="afterLog" pointcut-ref="pointcut"/> &lt;/aop:config> &lt;/beans> 测试
public class MyTest { @Test public void test(){ ApplicationContext context = newClassPathXmlApplicationContext("beans.xml"); UserService userService = (UserService) context.getBean("userService"); userService.search(); } } Aop的重要性 : 很重要 . 一定要理解其中的思路 , 主要是思想的理解这一块 .
Spring的Aop就是将公共的业务 (日志 , 安全等) 和领域业务结合起来 , 当执行领域业务时 , 将会把公共业务加进来 . 实现公共业务的重复利用 . 领域业务更纯粹 , 程序猿专注领域业务 , 其本质还是动态代理 .
11.3.2.自定义类来实现Aop 第二种方式
目标业务类不变依旧是userServiceImpl
第一步 : 写我们自己的一个切入类
public class DiyPointcut { public void before(){ System.out.println("---------方法执行前---------"); } public void after(){ System.out.println("---------方法执行后---------"); } 去spring中配置
&lt;!--第二种方式自定义实现--> &lt;!--注册bean--> &lt;bean id="diy" class="com.kuang.config.DiyPointcut"/> &lt;!--aop的配置--> &lt;aop:config> &lt;!--第二种方式：使用AOP的标签实现--> &lt;aop:aspect ref="diy"> &lt;aop:pointcut id="diyPonitcut" expression="execution(* com.kuang.service.UserServiceImpl.*(..))"/> &lt;aop:before pointcut-ref="diyPonitcut" method="before"/> &lt;aop:after pointcut-ref="diyPonitcut" method="after"/> &lt;/aop:aspect> &lt;/aop:config> 测试：
public class MyTest { @Test public void test(){ ApplicationContext context = newClassPathXmlApplicationContext("beans.xml"); UserService userService = (UserService) context.getBean("userService"); userService.add(); } } 11.3.4.使用注解实现 第三种方式
第一步：编写一个注解实现的增强类
package com.kuang.config; import org.aspectj.lang.ProceedingJoinPoint; import org.aspectj.lang.annotation.After; import org.aspectj.lang.annotation.Around; import org.aspectj.lang.annotation.Aspect; import org.aspectj.lang.annotation.Before; @Aspect public class AnnotationPointcut { @Before("execution(* com.kuang.service.UserServiceImpl.*(..))") public void before(){ System.out.println("---------方法执行前---------"); } @After("execution(* com.kuang.service.UserServiceImpl.*(..))") public void after(){ System.out.println("---------方法执行后---------"); } @Around("execution(* com.kuang.service.UserServiceImpl.*(..))") public void around(ProceedingJoinPoint jp) throws Throwable { System.out.println("环绕前"); System.out.println("签名:"+jp.getSignature()); //执行目标方法proceed Object proceed = jp.proceed(); System.out.println("环绕后"); System.out.println(proceed); } } 第二步：在Spring配置文件中，注册bean，并增加支持注解的配置
&lt;!--第三种方式:注解实现--> &lt;bean id="annotationPointcut" class="com.kuang.config.AnnotationPointcut"/> &lt;aop:aspectj-autoproxy/> aop:aspectj-autoproxy：说明
通过aop命名空间的&lt;aop:aspectj-autoproxy />声明自动为spring容器中那些配置@aspectJ切面的bean创建代理，织入切面。当然，spring 在内部依旧采用AnnotationAwareAspectJAutoProxyCreator进行自动代理的创建工作，但具体实现的细节已经被&lt;aop:aspectj-autoproxy />隐藏起来了 &lt;aop:aspectj-autoproxy />有一个proxy-target-class属性，默认为false，表示使用jdk动态代理织入增强，当配为&lt;aop:aspectj-autoproxy poxy-target-class="true"/>时，表示使用CGLib动态代理技术织入增强。不过即使proxy-target-class设置为false，如果目标类没有声明接口，则spring将自动使用CGLib动态代理。 12.整合MyBatis 步骤 1、导入相关jar包
junit
&lt;dependency> &lt;groupId>junit&lt;/groupId> &lt;artifactId>junit&lt;/artifactId> &lt;version>4.12&lt;/version> &lt;/dependency> mybatis
&lt;dependency> &lt;groupId>org.mybatis&lt;/groupId> &lt;artifactId>mybatis&lt;/artifactId> &lt;version>3.5.2&lt;/version> &lt;/dependency> mysql-connector-java
&lt;dependency> &lt;groupId>mysql&lt;/groupId> &lt;artifactId>mysql-connector-java&lt;/artifactId> &lt;version>5.1.47&lt;/version> &lt;/dependency> spring相关
&lt;dependency> &lt;groupId>org.springframework&lt;/groupId> &lt;artifactId>spring-webmvc&lt;/artifactId> &lt;version>5.1.10.RELEASE&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework&lt;/groupId> &lt;artifactId>spring-jdbc&lt;/artifactId> &lt;version>5.1.10.RELEASE&lt;/version> &lt;/dependency> aspectJ AOP 织入器
&lt;!-- https://mvnrepository.com/artifact/org.aspectj/aspectjweaver --> &lt;dependency> &lt;groupId>org.aspectj&lt;/groupId> &lt;artifactId>aspectjweaver&lt;/artifactId> &lt;version>1.9.4&lt;/version> &lt;/dependency> mybatis-spring整合包 【重点】
&lt;dependency> &lt;groupId>org.mybatis&lt;/groupId> &lt;artifactId>mybatis-spring&lt;/artifactId> &lt;version>2.0.2&lt;/version> &lt;/dependency> 配置Maven静态资源过滤问题！
&lt;build> &lt;resources> &lt;resource> &lt;directory>src/main/java&lt;/directory> &lt;includes> &lt;include>**/*.properties&lt;/include> &lt;include>**/*.xml&lt;/include> &lt;/includes> &lt;filtering>true&lt;/filtering> &lt;/resource> &lt;/resources> &lt;/build> 2、编写配置文件
3、代码实现
12.1回忆MyBatis 编写pojo实体类
package com.kuang.pojo; public class User { private int id; //id private String name; //姓名 private String pwd; //密码 } 实现mybatis的配置文件
&lt;?xml version="1.0" encoding="UTF-8" ?> &lt;!DOCTYPE configuration PUBLIC "-//mybatis.org//DTD Config 3.0//EN" "http://mybatis.org/dtd/mybatis-3-config.dtd"> &lt;configuration> &lt;typeAliases> &lt;package name="com.kuang.pojo"/> &lt;/typeAliases> &lt;environments default="development"> &lt;environment id="development"> &lt;transactionManager type="JDBC"/> &lt;dataSource type="POOLED"> &lt;property name="driver" value="com.mysql.jdbc.Driver"/> &lt;property name="url" value="jdbc:mysql://localhost:3306/mybatis?useSSL=true&amp;amp;useUnicode=true&amp;amp;characterEncoding=utf8"/> &lt;property name="username" value="root"/> &lt;property name="password" value="123456"/> &lt;/dataSource> &lt;/environment> &lt;/environments> &lt;mappers> &lt;package name="com.kuang.dao"/> &lt;/mappers> &lt;/configuration> UserDao接口编写
public interface UserMapper { public List&lt;User> selectUser(); } 接口对应的Mapper映射文件
&lt;?xml version="1.0" encoding="UTF-8" ?> &lt;!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd"> &lt;mapper namespace="com.kuang.dao.UserMapper"> &lt;select id="selectUser" resultType="User"> select * from user &lt;/select> &lt;/mapper> 测试类
@Test public void selectUser() throws IOException { String resource = "mybatis-config.xml"; InputStream inputStream = Resources.getResourceAsStream(resource); SqlSessionFactory sqlSessionFactory = newSqlSessionFactoryBuilder().build(inputStream); SqlSession sqlSession = sqlSessionFactory.openSession(); UserMapper mapper = sqlSession.getMapper(UserMapper.class); List&lt;User> userList = mapper.selectUser(); for (User user: userList){ System.out.println(user); } sqlSession.close(); } 12.2.MyBatis-Spring学习 引入Spring之前需要了解mybatis-spring包中的一些重要类；
http://www.mybatis.org/spring/zh/index.html
什么是 MyBatis-Spring？
MyBatis-Spring 会帮助你将 MyBatis 代码无缝地整合到 Spring 中。
知识基础
在开始使用 MyBatis-Spring 之前，你需要先熟悉 Spring 和 MyBatis 这两个框架和有关它们的术语。这很重要
MyBatis-Spring 需要以下版本：
MyBatis-Spring MyBatis Spring 框架 Spring Batch Java 2.0 3.5+ 5.0+ 4.0+ Java 8+ 1.3 3.4+ 3.2.2+ 2.1+ Java 6+ 如果使用 Maven 作为构建工具，仅需要在 pom.xml 中加入以下代码即可：
&lt;dependency> &lt;groupId>org.mybatis&lt;/groupId> &lt;artifactId>mybatis-spring&lt;/artifactId> &lt;version>2.0.2&lt;/version> &lt;/dependency> 要和 Spring 一起使用 MyBatis，需要在 Spring 应用上下文中定义至少两样东西：一个 SqlSessionFactory 和至少一个数据映射器类。
在 MyBatis-Spring 中，可使用SqlSessionFactoryBean来创建 SqlSessionFactory。要配置这个工厂 bean，只需要把下面代码放在 Spring 的 XML 配置文件中：
&lt;bean id="sqlSessionFactory" class="org.mybatis.spring.SqlSessionFactoryBean"> &lt;property name="dataSource" ref="dataSource" /> &lt;/bean> 注意：SqlSessionFactory需要一个 DataSource（数据源）。这可以是任意的 DataSource，只需要和配置其它 Spring 数据库连接一样配置它就可以了。
在基础的 MyBatis 用法中，是通过 SqlSessionFactoryBuilder 来创建 SqlSessionFactory 的。而在 MyBatis-Spring 中，则使用 SqlSessionFactoryBean 来创建。
在 MyBatis 中，你可以使用 SqlSessionFactory 来创建 SqlSession。一旦你获得一个 session 之后，你可以使用它来执行映射了的语句，提交或回滚连接，最后，当不再需要它的时候，你可以关闭 session。
SqlSessionFactory有一个唯一的必要属性：用于 JDBC 的 DataSource。这可以是任意的 DataSource 对象，它的配置方法和其它 Spring 数据库连接是一样的。
一个常用的属性是 configLocation，它用来指定 MyBatis 的 XML 配置文件路径。它在需要修改 MyBatis 的基础配置非常有用。通常，基础配置指的是 &lt; settings> 或 &lt; typeAliases>元素。
需要注意的是，这个配置文件并不需要是一个完整的 MyBatis 配置。确切地说，任何环境配置（），数据源（）和 MyBatis 的事务管理器（）都会被忽略。SqlSessionFactoryBean 会创建它自有的 MyBatis 环境配置（Environment），并按要求设置自定义环境的值。
SqlSessionTemplate 是 MyBatis-Spring 的核心。作为 SqlSession 的一个实现，这意味着可以使用它无缝代替你代码中已经在使用的 SqlSession。
模板可以参与到 Spring 的事务管理中，并且由于其是线程安全的，可以供多个映射器类使用，你应该总是用 SqlSessionTemplate 来替换 MyBatis 默认的 DefaultSqlSession 实现。在同一应用程序中的不同类之间混杂使用可能会引起数据一致性的问题。
可以使用 SqlSessionFactory 作为构造方法的参数来创建 SqlSessionTemplate 对象。
&lt;bean id="sqlSession" class="org.mybatis.spring.SqlSessionTemplate"> &lt;constructor-arg index="0" ref="sqlSessionFactory" /> &lt;/bean> 现在，这个 bean 就可以直接注入到你的 DAO bean 中了。你需要在你的 bean 中添加一个 SqlSession 属性，就像下面这样：
public class UserDaoImpl implements UserDao { private SqlSession sqlSession; public void setSqlSession(SqlSession sqlSession) { this.sqlSession = sqlSession; } public User getUser(String userId) { return sqlSession.getMapper...; } } 按下面这样，注入 SqlSessionTemplate：
&lt;bean id="userDao" class="org.mybatis.spring.sample.dao.UserDaoImpl"> &lt;property name="sqlSession" ref="sqlSession" /> &lt;/bean> 12.3.整合实现一 1、引入Spring配置文件beans.xml
&lt;?xml version="1.0" encoding="UTF-8"?> &lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"> 2、配置数据源替换mybaits的数据源
&lt;!--配置数据源：数据源有非常多，可以使用第三方的，也可使使用Spring的--> &lt;bean id="dataSource"class="org.springframework.jdbc.datasource.DriverManagerDataSource"> &lt;property name="driverClassName" value="com.mysql.jdbc.Driver"/> &lt;property name="url" value="jdbc:mysql://localhost:3306/mybatis?useSSL=true&amp;amp;useUnicode=true&amp;amp;characterEncoding=utf8"/> &lt;property name="username" value="root"/> &lt;property name="password" value="123456"/> &lt;/bean> 3、配置SqlSessionFactory，关联MyBatis
&lt;!--配置SqlSessionFactory--> &lt;bean id="sqlSessionFactory" class="org.mybatis.spring.SqlSessionFactoryBean"> &lt;property name="dataSource" ref="dataSource"/> &lt;!--关联Mybatis--> &lt;property name="configLocation" value="classpath:mybatis-config.xml"/> &lt;property name="mapperLocations" value="classpath:com/kuang/dao/*.xml"/> &lt;/bean> 4、注册sqlSessionTemplate，关联sqlSessionFactory；
&lt;!--注册sqlSessionTemplate , 关联sqlSessionFactory--> &lt;bean id="sqlSession" class="org.mybatis.spring.SqlSessionTemplate"> &lt;!--利用构造器注入--> &lt;constructor-arg index="0" ref="sqlSessionFactory"/> &lt;/bean> 5、增加Dao接口的实现类；私有化sqlSessionTemplate
public class UserDaoImpl implements UserMapper { //sqlSession不用我们自己创建了，Spring来管理 private SqlSessionTemplate sqlSession; public void setSqlSession(SqlSessionTemplate sqlSession) { this.sqlSession = sqlSession; } public List&lt;User> selectUser() { UserMapper mapper = sqlSession.getMapper(UserMapper.class); return mapper.selectUser(); } } 6、注册bean实现
&lt;bean id="userDao" class="com.kuang.dao.UserDaoImpl"> &lt;property name="sqlSession" ref="sqlSession"/> &lt;/bean> 7、测试
@Test public void test2(){ ApplicationContext context = newClassPathXmlApplicationContext("beans.xml"); UserMapper mapper = (UserMapper) context.getBean("userDao"); List&lt;User> user = mapper.selectUser(); System.out.println(user); } 结果成功输出！现在我们的Mybatis配置文件的状态！发现都可以被Spring整合！
&lt;?xml version="1.0" encoding="UTF-8" ?> &lt;!DOCTYPE configuration PUBLIC "-//mybatis.org//DTD Config 3.0//EN" "http://mybatis.org/dtd/mybatis-3-config.dtd"> &lt;configuration> &lt;typeAliases> &lt;package name="com.kuang.pojo"/> &lt;/typeAliases> &lt;/configuration> 12.4.整合实现二 mybatis-spring1.2.3版以上的才有这个 .
官方文档截图 :
dao继承Support类 , 直接利用 getSqlSession() 获得 , 然后直接注入SqlSessionFactory . 比起方式1 , 不需要管理SqlSessionTemplate , 而且对事务的支持更加友好 . 可跟踪源码查看
测试：
1、将我们上面写的UserDaoImpl修改一下
public class UserDaoImpl extends SqlSessionDaoSupport implements UserMapper { public List&lt;User> selectUser() { UserMapper mapper = getSqlSession().getMapper(UserMapper.class); return mapper.selectUser(); } } 2、修改bean的配置
&lt;bean id="userDao" class="com.kuang.dao.UserDaoImpl"> &lt;property name="sqlSessionFactory" ref="sqlSessionFactory" /> &lt;/bean> 3、测试
@Test public void test2(){ ApplicationContext context = new ClassPathXmlApplicationContext("beans.xml"); UserMapper mapper = (UserMapper) context.getBean("userDao"); List&lt;User> user = mapper.selectUser(); System.out.println(user); } 总结 : 整合到spring以后可以完全不要mybatis的配置文件，除了这些方式可以实现整合之外，我们还可以使用注解来实现，这个等我们后面学习SpringBoot的时候还会测试整合！
13.声明式事务 13.1.回顾事务 事务在项目开发过程非常重要，涉及到数据的一致性的问题，不容马虎！ 事务管理是企业级应用程序开发中必备技术，用来确保数据的完整性和一致性。 事务就是把一系列的动作当成一个独立的工作单元，这些动作要么全部完成，要么全部不起作用。
事务四个属性ACID
原子性（atomicity） 事务是原子性操作，由一系列动作组成，事务的原子性确保动作要么全部完成，要么完全不起作用 一致性（consistency） 一旦所有事务动作完成，事务就要被提交。数据和资源处于一种满足业务规则的一致性状态中 隔离性（isolation） 可能多个事务会同时处理相同的数据，因此每个事务都应该与其他事务隔离开来，防止数据损坏 持久性（durability） 事务一旦完成，无论系统发生什么错误，结果都不会受到影响。通常情况下，事务的结果被写到持久化存储器中 测试 将上面的代码拷贝到一个新项目中
在之前的案例中，我们给userDao接口新增两个方法，删除和增加用户；
//添加一个用户 int addUser(User user); //根据id删除用户 int deleteUser(int id); mapper文件，我们故意把 deletes 写错，测试！
&lt;insert id="addUser" parameterType="com.kuang.pojo.User"> insert into user (id,name,pwd) values (#{id},#{name},#{pwd}) &lt;/insert> &lt;delete id="deleteUser" parameterType="int"> deletes from user where id = #{id} &lt;/delete> 编写接口的实现类，在实现类中，我们去操作一波
public class UserDaoImpl extends SqlSessionDaoSupport implements UserMapper { //增加一些操作 public List&lt;User> selectUser() { User user = new User(4,"小明","123456"); UserMapper mapper = getSqlSession().getMapper(UserMapper.class); mapper.addUser(user); mapper.deleteUser(4); return mapper.selectUser(); } //新增 public int addUser(User user) { UserMapper mapper = getSqlSession().getMapper(UserMapper.class); return mapper.addUser(user); } //删除 public int deleteUser(int id) { UserMapper mapper = getSqlSession().getMapper(UserMapper.class); return mapper.deleteUser(id); } } 测试
@Test public void test2(){ ApplicationContext context = new ClassPathXmlApplicationContext("beans.xml"); UserMapper mapper = (UserMapper) context.getBean("userDao"); List&lt;User> user = mapper.selectUser(); System.out.println(user); } 报错：sql异常，delete写错了
结果 ：插入成功！
没有进行事务的管理；我们想让他们都成功才成功，有一个失败，就都失败，我们就应该需要事务！
以前我们都需要自己手动管理事务，十分麻烦！
但是Spring给我们提供了事务管理，我们只需要配置即可；
13.2.Spring中的事务管理 Spring在不同的事务管理API之上定义了一个抽象层，使得开发人员不必了解底层的事务管理API就可以使用Spring的事务管理机制。Spring支持编程式事务管理和声明式的事务管理。
编程式事务管理
将事务管理代码嵌到业务方法中来控制事务的提交和回滚 缺点：必须在每个事务操作业务逻辑中包含额外的事务管理代码 声明式事务管理
一般情况下比编程式事务好用。 将事务管理代码从业务方法中分离出来，以声明的方式来实现事务管理。 将事务管理作为横切关注点，通过aop方法模块化。Spring中通过Spring AOP框架支持声明式事务管理。 使用Spring管理事务，注意头文件的约束导入 : tx
xmlns:tx="http://www.springframework.org/schema/tx" http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd"> 事务管理器
无论使用Spring的哪种事务管理策略（编程式或者声明式）事务管理器都是必须的。 就是 Spring的核心事务管理抽象，管理封装了一组独立于技术的方法。 JDBC事务
&lt;bean id="transactionManager"class="org.springframework.jdbc.datasource.DataSourceTransactionManager"> &lt;property name="dataSource" ref="dataSource" /> &lt;/bean> 配置好事务管理器后我们需要去配置事务的通知
&lt;!--配置事务通知--> &lt;tx:advice id="txAdvice" transaction-manager="transactionManager"> &lt;tx:attributes> &lt;!--配置哪些方法使用什么样的事务,配置事务的传播特性--> &lt;tx:method name="add" propagation="REQUIRED"/> &lt;tx:method name="delete" propagation="REQUIRED"/> &lt;tx:method name="update" propagation="REQUIRED"/> &lt;tx:method name="search*" propagation="REQUIRED"/> &lt;tx:method name="get" read-only="true"/> &lt;tx:method name="*" propagation="REQUIRED"/> &lt;/tx:attributes> &lt;/tx:advice> spring事务传播特性：
事务传播行为就是多个事务方法相互调用时，事务如何在这些方法间传播。spring支持7种事务传播行为：
propagation_requierd：如果当前没有事务，就新建一个事务，如果已存在一个事务中，加入到这个事务中，这是最常见的选择。 propagation_supports：支持当前事务，如果没有当前事务，就以非事务方法执行。 propagation_mandatory：使用当前事务，如果没有当前事务，就抛出异常。 propagation_required_new：新建事务，如果当前存在事务，把当前事务挂起。 propagation_not_supported：以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。 propagation_never：以非事务方式执行操作，如果当前事务存在则抛出异常。 propagation_nested：如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行与propagation_required类似的操作 Spring 默认的事务传播行为是 PROPAGATION_REQUIRED，它适合于绝大多数的情况。
假设 ServiveX#methodX() 都工作在事务环境下（即都被 Spring 事务增强了），假设程序中存在如下的调用链：Service1#method1()->Service2#method2()->Service3#method3()，那么这 3 个服务类的 3 个方法通过 Spring 的事务传播机制都工作在同一个事务中。
就好比，我们刚才的几个方法存在调用，所以会被放在一组事务当中！
配置AOP
导入aop的头文件！
&lt;!--配置aop织入事务--> &lt;aop:config> &lt;aop:pointcut id="txPointcut" expression="execution(* com.kuang.dao.*.*(..))"/> &lt;aop:advisor advice-ref="txAdvice" pointcut-ref="txPointcut"/> &lt;/aop:config> 进行测试
删掉刚才插入的数据，再次测试！
@Test public void test2(){ ApplicationContext context = new ClassPathXmlApplicationContext("beans.xml"); UserMapper mapper = (UserMapper) context.getBean("userDao"); List&lt;User> user = mapper.selectUser(); System.out.println(user); }</content></entry><entry><title>精通Git</title><url>/post/%E7%B2%BE%E9%80%9Agit/</url><categories><category>Git</category></categories><tags><tag>Git</tag></tags><content type="html"> 精通Git
精通Git 1、Git基础 （1）三种状态 Git 有三种状态，你的文件可能处于其中之一：已提交（committed）、已修改（modified）和已暂存（staged）。已提交表示数据已经安全的保存在本地数据库中。已修改表示修改了文件，但还没保存到数据库中。已暂存表示对一个已修改文件的当前版本做了标记，使之包含在下次提交的快照中
由此引入 Git 项目的三个工作区域的概念：Git 仓库、工作目录以及暂存区域。
Git 仓库目录是 Git 用来保存项目的元数据和对象数据库的地方。这是 Git 中最重要的部分，从其它计算机克隆仓库时，拷贝的就是这里的数据。
工作目录是对项目的某个版本独立提取出来的内容。这些从 Git 仓库的压缩数据库中提取出来的文件，放在磁盘上供你使用或修改。
暂存区域是一个文件，保存了下次将提交的文件列表信息，一般在 Git 仓库目录中。有时候也被称作`‘索引’&rsquo;，不过一般说法还是叫暂存区域。
总结：如果 Git 目录中保存着的特定版本文件，就属于已提交状态。如果作了修改并已放入暂存区域，就属于已暂存状态。如果自上次取出后，作了修改但还没有放到暂存区域，就是已修改状态。
（2）记录数据方式 Git直接记录快照，而非差异比较
Git 和其它版本控制系统（包括 Subversion 和近似工具）的主要差别在于 Git 对待数据的方法。概念上来区分，其它大部分系统以文件变更列表的方式存储信息。这类系统（CVS、Subversion、Perforce、Bazaar 等等）将它们保存的信息看作是一组基本文件和每个文件随时间逐步累积的差异。
Git 不按照以上方式对待或保存数据。反之，Git 更像是把数据看作是对小型文件系统的一组快照。每次你提交
更新，或在 Git 中保存项目状态时，它主要对当时的全部文件制作一个快照并保存这个快照的索引。为了高效，如果文件没有修改，Git 不再重新存储该文件，而是只保留一个链接指向之前存储的文件。Git 对待数据更像是一个 快照流。
Git 更像是一个小型的文件系统，提供了许多以此为基础构建的超强工具，而不只是一个简单的 VCS
（3）近乎所有操作都是本地执行和保证文件完整性** 2、配置信息 ​ &ndash;global 选项，那么该命令只需要运行一次，因为之后无论你在该系统上做任何事情， Git 都会使用那些信息。当你想针对特定项目使用不同的用户名称与邮件地址时，可以在那个项目目录下运行没有 &ndash;global 选项的命令来配置
git config &ndash;global user.name &ldquo;kw&rdquo;
git config &ndash;global user.email 1121034507@qq.com
git config &ndash;list &lt;!--命令来列出所有 Git 当时能找到的配置-->
git config &ndash;globalcredential.helper cache/store 缓存用户名/密码，cache-15分钟 store-永久
配置Git可以用git config &ndash;list查看配置项，再使用命令git config 配置项 设置值
3、git基础操作 git init &lt;!--在当前目录初始化git-->
**$ git add *.c ** &lt;!--暂存命令，添加一个或多个文件到暂存区（开始跟踪一个新文件，或者把已跟踪的文件放到暂存区，概括起来就是添加内容到下一次提交中）-->
$ git add LICENSE
$ git commit -m &lsquo;initial project version&rsquo; &lt;!--提交命令,将暂存区文件提交到本地仓库-->
git clone https://github.com/libgit2/libgit2
[别名]&lt;!--克隆远程仓库-->
**git status **&lt;!--检查当前文件状态-->
$ git status -s
M README &lt;!--右边的 M 表示该文件被修改了但是还没放入暂存区-->
M lib/simplegit.rb &lt;!--左边的 M文件被修改了并将修改后的文件放入了暂存区-->
MM Rakefile &lt;!--在工作区被修改并提交到暂存区后又在工作区中被修改了，所以在暂存区和工作区都有该文件被修改了的记录-->
**A lib/git.rb ** &lt;!--新添加到暂存区中的文件前面有 A 标记，修改过的文件前面有 M 标记-->
?? LICENSE.txt &lt;!--新添加的未跟踪文件前面有 ?? 标记-->
git diff &lt;!--**查看已暂存和未暂存的修改**-->
要查看尚未暂存的文件更新了哪些部分，不加参数直接输入 git diff： 要查看已暂存的将要添加到下次提交里的内容，可以用 git diff &ndash;cached/&ndash;staged git commit -m &ldquo;message&rdquo; &lt;!--将暂存区文件提交到本地仓库-->
git commit -a -m &ldquo;message&rdquo; &lt;!--将已追踪文件提交到本地仓库，省略git add .操作-->
**git rm 文件名 **&lt;!--从已跟踪文件清单中移除（确切地说，是从暂存区域移除），然后提交。该命令连带从工作目录中删除文件-->
git rm &ndash;cached README&lt;!--从本地仓库删除，当然也包括暂存区和工作目录-->
**git rm log/\*.log **&lt;!--删除 log/ 目录下扩展名为 .log 的所有文件。星号 * 之前的反斜杠 \，因为 Git 有它自己的文件模式扩展匹配方式-->
git rm \*~ &lt;!--删除以 ~ 结尾的所有文件-->
git mv file_from file_to &lt;!--改名操作-->
**git log **&lt;!--查看提交历史-->
git log -p -2 &lt;!--（-p）查看提交差异，2表示最近两次提交-->**
**git log &ndash;stat **&lt;!--简略信息-->**
**git log &ndash;pretty=format:"%h - %an, %ar : %s" ** &lt;!-- --pretty。这个选项可以指定使用不同于默认格式的方式展示提交历史-->
ca82a6d - Scott Chacon, 6 years ago : changed the version number 085bb3b - Scott Chacon, 6 years ago : removed unnecessary test a11bef0 - Scott Chacon, 6 years ago : first commit ​ 用 &ndash;author 选项显示指定作者的提交，用 &ndash;grep 选项搜索提交说明中的关键字。（请注意，如果要得到同时满足这两个选项搜索条件的提交，就必须用 &ndash;all-match 选项。否则，满足任意一个条件的提交都会被匹配出来）。另一个非常有用的筛选选项是 -S，可以列出那些添加或移除了某些字符串的提交。比如说，你想找出添加或移除了某一个特定函数的引用的提交，你可以这样使用： $ git log -Sfunction_name
​
选项 说明 -(n) 仅显示最近的 n 条提交 &ndash;since, &ndash;after 仅显示指定时间之后的提交。 &ndash;until, &ndash;before 仅显示指定时间之前的提交 &ndash;author 仅显示指定作者相关的提交。 &ndash;committer 仅显示指定提交者相关的提交。 &ndash;grep 仅显示含指定关键字的提交 -S 仅显示添加或移除了某个关键字的提交 git tag 查看标签
git tag -a v1.4 -m &lsquo;my version 1.4&rsquo; 增加标签V1.4
git tag tagname 轻量标签
$ git log --pretty=oneline 15027957951b64cf874c3557a0f3547bd83b3ff6 Merge branch 'experiment' a6b4c97498bd301d84096da251c98a07c7723e65 beginning write support 0d52aaab4479697da7686c15f77a3d64d9165190 one more thing $ git tag -a v1.2 0d52aaa //对历史提交打标签，如果不加提交校验和会对在最近一次的提交打tag git push origin [tagname] 推送tag到远程仓库（git push不会推送tag）
git push origin &ndash;tags 推送所有标签
git checkout -b [branchname] [tagname] 在特定的标签上创建一个新分支
Switched to a new branch &lsquo;version2&rsquo;
git config 设置别名
$ git config --global alias.co checkout $ git config --global alias.br branch $ git config --global alias.ci commit $ git config --global alias.st status 4、Git分支 ​ Git 保存的不是文件的变化或者差异，而是一系列不同时刻的文件快照。Git 的分支，其实本质上仅仅是指向提交对象的可变指针。Git 的默认分支名字是 master。在多次提交操作之后，其实已经有一个指向最后那个提交对象的 master 分支。它会在每次的提交操作中自动向前移动。Git 又是怎么知道当前在哪一个分支上呢？也很简单，它有一个名为 HEAD 的特殊指针
git branch testing 创建分支testing
git checkout testing 切换分支
$ vim test.txt $ git commit -a -m 'made a change' 如图所示，testing 分支向前移动了，但是 master 分支却没有，它仍然指向运行 git checkout 时所指的对象。分支切换会改变你工作目录中的文件在切换分支时，一定要注意你工作目录里的文件会被改变。如果是切换到一个较旧的分支，你的工作目录会恢复到该分支最后一次提交时的样子。如果 Git 不能干净利落地完成这个任务，它将禁止切换分支，要留意工作目录和暂存区里那些还没有被提交的修改，它可能会和你即将检出的分支产生冲突从而阻止 Git 切换到该分支（Git 会自动添加、删除、修改文件以确保此时你的工作目录和这个分支最后一次提交时的样子一模一样）
git checkout -b iss53 新建并检出分支iss53
//等于以下两条命令 $ git branch iss53 $ git checkout iss53 ​ 从一个远程跟踪分支检出一个本地分支会自动创建一个叫做 “跟踪分支”（有时候也叫做 “上游分支”）。跟踪分支是与远程分支有直接关系的本地分支。如果在一个跟踪分支上输入 git pull，Git 能自动地识别去哪个服务器上抓取、合并到哪个分支。
​ 当克隆一个仓库时，它通常会自动地创建一个跟踪 origin/master 的 master 分支。然而，如果你愿意的话可以设置其他的跟踪分支 - 其他远程仓库上的跟踪分支，或者不跟踪 master 分支。最简单的就是之前看到的例子，运行 git checkout -b [branch] [remotename]/[branch]。这是一个十分常用的操作所以 Git 提供了 &ndash;track 快捷方式：
$ git checkout --track origin/serverfix Branch serverfix set up to track remote branch serverfix from origin. Switched to a new branch 'serverfix' 如果想要将本地分支与远程分支设置为不同名字，你可以轻松地增加一个不同名字的本地分支的上一个命令：
$ git checkout -b sf origin/serverfix Branch sf set up to track remote branch serverfix from origin. Switched to a new branch 'sf' 现在，本地分支 sf 会自动从 origin/serverfix 拉取。
设置已有的本地分支跟踪一个刚刚拉取下来的远程分支，或者想要修改正在跟踪的上游分支，你可以在任意时间使用 -u 或 &ndash;set-upstream-to 选项运行 git branch 来显式地设置。
$ git branch -u origin/serverfix Branch serverfix set up to track remote branch serverfix from origin. git merge 合并分支
$ git checkout master //检出master分支 $ git merge hotfix //合并testing分支到master 遇到冲突时的分支合并：如果在两个不同的分支中，对同一个文件的同一个部分进行了不同的修改，Git 就没法干净的合并它们，这就是合并冲突
​
$ git merge iss53 Auto-merging index.html CONFLICT (content): Merge conflict in index.html Automatic merge failed; fix conflicts and then commit the result. //查看具体冲突信息 $ git status On branch master You have unmerged paths. (fix conflicts and run "git commit") Unmerged paths: (use "git add &lt;file>..." to mark resolution) both modified: index.html no changes added to commit (use "git add" and/or "git commit -a") //解决冲突 手动修改冲突文件后，对每个文件使用 git add 命令来将其标记为冲突已解决 $ git add index.html //查看状态，已无冲突 $ git status On branch master All conflicts fixed but you are still merging. (use "git commit" to conclude merge) Changes to be committed: modified: index.html //合并提交 $ git commit 使用git commit提交合并 git branch 分支管理，不加任务参数情况下显示所有分支列表
$ git branch  iss53 * master //当前检出分支  testing git branch -v 要查看每一个分支的最后一次提交
$ git branch -v  iss53 93b412c fix javascript issue * master 7a98805 Merge branch 'iss53'  testing 782fd34 add scott to the author list in the readmes git branch -vv 查看设置的所有跟踪分支
$ git branch -vv  iss53 7e424c3 [origin/iss53: ahead 2] forgot the brackets  master 1ae2a45 [origin/master] deploying index fix * serverfix f8674d9 [teamone/server-fix-good: ahead 3, behind 1] this should do it  testing 5ea463a trying something new ​ 这里可以看到 iss53 分支正在跟踪 origin/iss53 并且 “ahead” 是 2，意味着本地有两个提交还没有推送到服务器上。也能看到 master 分支正在跟踪 origin/master 分支并且是最新的。接下来可以看到serverfix 分支正在跟踪 teamone 服务器上的 server-fix-good 分支并且领先 2 落后 1，意味着服务器上有一次提交还没有合并入同时本地有三次提交还没有推送。最后看到 testing 分支并没有跟踪任何远程分支。
​ 需要重点注意的一点是这些数字的值来自于你从每个服务器上最后一次抓取的数据。这个命令并没有连接服务器，它只会告诉你关于本地缓存的服务器数据。如果想要统计最新的领先与落后数字，需要在运行此命令前抓取所有的远程仓库。可以像这样做：$ git fetch &ndash;all; git branch -vv
git branch [&ndash;no-merged/&ndash;merged] 查看已经合并或尚未合并到当前分支的分支
git branch -d branchname 删除分支 -d无法删除未合并的分支，-D可以强制删除
远程分支 git ls-remote (remote)或者git remote show (remote)来显示远程分支列表或者详细信息
​ Git 的 clone 命令会为你自动将其命名为 origin，拉取它的所有数据，创建一个指向它的 master 分支的指针，并且在本地将命名为 origin/master。Git 也会给你一个与 origin 的 master 分支在指向同一个地方的本地 master 分支，这样你就有工作的基础
​ 远程仓库名字 “origin” 与分支名字 “master” 一样，在 Git 中并没有任何特别的含义一样。同时 “master” 是当你运行 git init 时默认的起始分支名字，原因仅仅是它的广泛使用，“origin” 是当你运行 git clone 时默认的远程仓库名字。如果你运行 git clone -o booyah，那么你默认的远程分支名字将会是 booyah/master
​ ​ 如果你在本地的 master 分支做了一些工作，然而在同一时间，其他人推送提交到 git.ourcompany.com 并更新了它的 master 分支，那么你的提交历史将向不同的方向前进。也许，只要你不与 origin 服务器连接，你的 origin/master 指针就不会移动。
​ git fetch origin 在进行同步工作工作时，从远程仓库抓取本地没有的数据，更新本地数据库并将origin/master向后移动
​
git remote add 添加远程仓库分支
git remote add 别名 远程仓库
git fetch 拉取远程仓库
​ 当 git fetch 命令从服务器上抓取本地没有的数据时，它并不会修改工作目录中的内容。它只会获取数据然后让你自己合并。然而，有一个命令叫作 git pull 在大多数情况下它的含义是一个 git fetch 紧接着一个git merge 命令。如果有一个像之前章节中演示的设置好的跟踪分支，不管它是显式地设置还是通过 clone 或checkout 命令为你创建的，git pull 都会查找当前分支所跟踪的服务器与分支，从服务器上抓取数据然后尝试合并入那个远程分支。
​ 运行 git fetch teamone 来抓取远程仓库 teamone 有而本地没有的数据。因为那台服务器上现
有的数据是 origin 服务器上的一个子集，所以 Git 并不会抓取数据而是会设置远程跟踪分支
teamone/master 指向 teamone 的 master 分支
git push 推送
git push (remote) (branch)
git push &ndash;all 推送到所有远程仓库
git push origin &ndash;delete serverfix 删除远程分支serverfix
$ git push origin --delete serverfix To https://github.com/schacon/simplegit  - [deleted] serverfix 变基
在 Git 中整合来自不同分支的修改主要有两种方法：merge 以及 rebase
​ ​ 之前介绍过，整合分支最容易的方法是 merge 命令。它会把两个分支的最新快照（C3 和 C4）以及二者最近的共同祖先（C2）进行三方合并，合并的结果是生成一个新的快照（并提交）。
使用rebase也可以达到目的，提取在 C4 中引入的补丁和修改，然后在 C3 的基础上再应用一次。在 Git 中，这种操作就叫做 变基。你可以使用 rebase 命令将提交到某一分支上的所有修改都移至另一分支上，就好像“重新播放”一样
$ git checkout experiment $ git rebase master First, rewinding head to replay your work on top of it... Applying: added staged command 它的原理是首先找到这两个分支（即当前分支 experiment、变基操作的目标基底分支 master）的最近共同祖先 C2，然后对比当前分支相对于该祖先的历次提交，提取相应的修改并存为临时文件，然后将当前分支指向目标基底 C3, 最后以此将之前另存为临时文件的修改依序应用。（译注：写明了 commit id，以便理解，下同）
现在回到 master 分支，进行一次快进合并。
$ git checkout master $ git merge experiment ​ 此时，C4&rsquo; 指向的快照就和上面使用 merge 命令的例子中 C5 指向的快照一模一样了。这两种整合方法的最终结果没有任何区别，但是变基使得提交历史更加整洁。你在查看一个经过变基的分支的历史记录时会发现，尽管实际的开发工作是并行的，但它们看上去就像是先后串行的一样，提交历史是一条直线没有分叉。
​ 一般我们这样做的目的是为了确保在向远程分支推送时能保持提交历史的整洁——例如向某个别人维护的项目贡献代码时。在这种情况下，你首先在自己的分支里进行开发，当开发完成时你需要先将你的代码变基到origin/master 上，然后再向主项目提交修改。这样的话，该项目的维护者就不再需要进行整合工作，只需要快进合并便可。
​ 请注意，无论是通过变基，还是通过三方合并，整合的最终结果所指向的快照始终是一样的，只不过提交历史不同罢了。变基是将一系列提交按照原有次序依次应用到另一分支上，而合并是把最终结果合在一起。
变基的风险
呃，奇妙的变基也并非完美无缺，要用它得遵守一条准则：不要对在你的仓库外有副本的分支执行变基。</content></entry><entry><title>Spring学习记录</title><url>/post/spring%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</url><categories><category>Spring</category><category>源码</category></categories><tags><tag>Spring</tag><tag>源码</tag></tags><content type="html"> 根据雷神《spring注解驱动开发》整理记录知识点
Spring学习记录 本文是一篇spring(4.3.12.release版本)源码相关的文章。本文的源码解析就不按照传统的去贴代码的方式去讲解spring源码了，本文的源码解析以流程的方式来讲解spring在每一步都干了什么，所以谓之曰spring源码导读。。。。
在正式开始spring源码导读之前，读者总得知道spring里的各个标签是干啥的吧，因此文中前一部分罗列了spring常见的注解用法。并搞了点SpringAOP和spring事务源码的解析作为后面正式开始的导读的开胃菜
介绍完了，让我们开始吧！！！。
spring注解 @Configuration 用于标注配置类 @Bean 结合@Configuration（full mode）使用或结合@Component（light mode）使用。可以导入第三方组件,入方法有参数默认从IOC容器中获取，可以指定initMethod和destroyMethod 指定初始化和销毁方法,多实例对象不会调用销毁方法. 包扫描@ComponentScan (@ComponentScans可以配置多个扫描,@TypeFilter:指定过滤规则,自己实现TypeFilter类) 组件(@Service、@Controller、@Repository):包扫描+组件注解导入注解。 @Scope:设置组件作用域 1.prototype:多例的2.singleton:单例的（默认值） @Lazy 懒加载 @Conditional({Condition}):按照一定的条件进行判断,满足条件给容器中注册Bean,传入Condition数组,，使用时需自己创建类继承Condition然后重写match方法。 @Import[快速给容器中导入一个组件] Import(类名),容器中就会自动注册这个组件，id默认是组件的全名 ImportSelector：返回需要导入的组件的全类名的数组 ImportBeanDefinitionRegistrar：手动注册bean FactoryBean:工厂Bean,交给spring用来生产Bean到spring容器中.可以通过前缀&amp;来获取工厂Bean本身. @Value:给属性赋值,也可以使用SpEL和外部文件的值 @PropertySource:读取外部配置文件中的k/v保存到运行环境中,结合@value使用,或使用ConfigurableEnvironment获取 @Profile:结合@Bean使用,默认为default环境,可以通过命令行参数来切换环境 自定义组件使用Spring容器底层的组件:需要让自定义组件实现xxxAware，(例如:ApplicationContextAware),spring在创建对象的时候,会帮我们自动注入。spring通过BeanPostProcessor机制来实现XXXXAware的自动注入。 ApplicationContextProcessor.java private void invokeAwareInterfaces(Object bean) { if (bean instanceof Aware) { if (bean instanceof ResourceLoaderAware) { ((ResourceLoaderAware)bean).setResourceLoader(this.applicationContext); } if (bean instanceof ApplicationContextAware) { ((ApplicationContextAware)bean).setApplicationContext(this.applicationContext); } } } @Autowried 装配优先级如下: 使用按照类型去容器中找对应的组件 按照属性名称去作为组件id去找对应的组件 @Qualifier:指定默认的组件,结合@Autowried使用 &ndash;标注在构造器:spring创建对象调用构造器创建对象 &ndash;标注在方法上: @Primary:spring自动装配的时候,默认首先bean,配合@Bean使用 @Resource(JSR250):jsr规范:按照组件名称进行装配 @Inject(JSR330):jsr规范和@Autowired功能一致,不支持require=false; Bean生命周期: 初始化和销毁
通过@Bean 指定init-method和destroy-method 实现InitializingBean定义初始化逻辑,实现DisposableBean定义销毁方法 实现BeanPostProcessor接口的后置拦截器放入容器中，可以拦截bean初始化，并可以在被拦截的Bean的初始化前后进行一些处理工作。 spring底层常用的BeanPostProcessor：
* BeanValidationPostProcessor用来实现数据校验 * AutowireAnnotationBeanPostProcessor,@Autowire实现 * ApplicationContextProcessor实现XXXAware的自动注入。 执行时机
doCreateBean -populateBean（）：给bean的各种属性赋值 -initializeBean（）：初始化bean -处理Aware方法 -applyBeanPostProcessorsBeforeInitialization：后置处理器的实例化前拦截 -invokeInitMethods:执行@Bean指定的initMethod -applyBeanPostProcessorsAfterInitialization：后置处理器的实例化后拦截 SpringAOP实现原理 使用步骤
@EnableAspectJAutoProxy 开启基于注解的aop模式 @Aspect：定义切面类，切面类里定义通知 @PointCut 切入点，可以写切入点表达式，指定在哪个方法切入 通知方法 @Before(前置通知) @After(后置通知) @AfterReturning(返回通知) @AfterTrowing(异常通知)@Around(环绕通知) JoinPoint：连接点,是一个类，配合通知使用，用于获取切入的点的信息 SpringAop原理
@EnableAspectJAutoProxy @EnableAspectJAutoProxy 通过@Import(AspectJAutoProxyRegistrar.class)给spring容器中导入了一个AnnotationAwareAspectJAutoProxyCreator。 AnnotationAwareAspectJAutoProxyCreator实现了InstantiationAwareBeanPostProcessor,InstantiationAwareBeanPostProcessor是一个BeanPostProcessor。它可以拦截spring的Bean初始化(Initialization)前后和实例化(Initialization)前后。 AnnotationAwareAspectJAutoProxyCreator的postProcessBeforeInstantiation(bean实例化前)：会通过调用isInfrastructureClass(beanClass)来判断 被拦截的类是否是基础类型的Advice、PointCut、Advisor、AopInfrastructureBean，或者是否是切面（@Aspect），若是则放入adviseBean集合。这里主要是用来处理我们的切面类。 AnnotationAwareAspectJAutoProxyCreator的BeanPostProcessorsAfterInitialization（bean初始化后）： 首先找到被拦截的Bean的匹配的增强器（通知方法），这里有切入点表达式匹配的逻辑 将增强器保存到proxyFactory中， 根据被拦截的Bean是否实现了接口，spring自动决定使用JdkDynamicAopProxy还是ObjenesisCglibAopProxy 最后返回被拦截的Bean的代理对象，注册到spring容器中 代理Bean的目标方法执行过程：CglibAopProxy.intercept(); 保存所有的增强器，并处理转换为一个拦截器链 如果没有拦截器链，就直接执行目标方法 如果有拦截器链，就将目标方法，拦截器链等信息传入并创建CglibMethodInvocation对象，并调用proceed()方法获取返回值。proceed方法内部会依次执行拦截器链。 spring 声明式事务 基本步骤
配置数据源：DataSource 配置事务管理器来控制事务：PlatformTransactionManager @EnableTransactionManagement开启基于注解的事务管理功能 给方法上面标注@Transactional标识当前方法是一个事务方法 声明式事务实现原理
@EnableTransactionManagement利用TransactionManagementConfigurationSelector给spring容器中导入两个组件：AutoProxyRegistrar和ProxyTransactionManagementConfiguration AutoProxyRegistrar给spring容器中注册一个InfrastructureAdvisorAutoProxyCreator，InfrastructureAdvisorAutoProxyCreator实现了InstantiationAwareBeanPostProcessor,InstantiationAwareBeanPostProcessor是一个BeanPostProcessor。它可以拦截spring的Bean初始化(Initialization)前后和实例化(Initialization)前后。利用后置处理器机制在被拦截的bean创建以后包装该bean并返回一个代理对象代理对象执行方法利用拦截器链进行调用（同springAop的原理） ProxyTransactionManagementConfiguration：是一个spring的配置类,它为spring容器注册了一个BeanFactoryTransactionAttributeSourceAdvisor,是一个事务事务增强器。它有两个重要的字段：AnnotationTransactionAttributeSource和TransactionInterceptor。 AnnotationTransactionAttributeSource：用于解析事务注解的相关信息 TransactionInterceptor：事务拦截器，在事务方法执行时，都会调用TransactionInterceptor的invoke->invokeWithinTransaction方法，这里面通过配置的PlatformTransactionManager控制着事务的提交和回滚。 Spring 扩展(钩子) BeanFactoryPostProcessor：beanFactory后置处理器，的拦截时机：所有Bean的定义信息已经加载到容器，但还没有被实例化。可以对beanFactory进行一些操作。 BeanPostProcessor：bean后置处理器，拦截时机：bean创建对象初始化前后进行拦截工作。可以对每一个Bean进行一些操作。 BeanDefinitionRegistryPostProcessor：是BeanFactoryPostProcessor的子接口，拦截时机：所有Bean的定义信息已经加载到容器，但还没有被实例化，可以对每一个Bean的BeanDefinition进行一些操作。 ApplicationListener,自定义ApplicationListener实现类并加入到容器中,可以监听spring容器中发布的事件。spring在创建容器的时候（finishRefresh（）方法）会发布ContextRefreshedEvent事件，关闭的时候（doClose()）会发布ContextClosedEvent事件。也可以通过spring容器的publishEvent发布自己的事件。 事件发布流程：publishEvent方法 获取事件的多播器，getApplicationEventMulticaster()。 调用multicastEvent(applicationEvent, eventType)派发事件。获取到所有的ApplicationListener,即getApplicationListeners()，然后同步或者异步的方式执行监听器的onApplicationEvent。 事件的多播器的初始化中（initApplicationEventMulticaster（）），如果容器中没有配置applicationEventMulticaster，就使用SimpleApplicationEventMulticaster。然后获取所有的监听器，并把它们注册到SimpleApplicationEventMulticaster中。 @EventListener(class={})：在普通的业务逻辑的方法上监听事件特定的事件。原理：EventListenerMethodProcessor是一个SmartInitializingSingleton，当所有的单例bean都初始化完以后， 容器会回调该接口的方法afterSingletonsInstantiated(),该方法里会遍历容器中所有的bean，并判断每一个bean里是否带有@EventListener注解的Method，然后创建ApplicationListenerMethodAdapter存储并包装该Method，最后将ApplicationListenerMethodAdapter添加到spring容器中。 Spring源代码分析 spring核心逻辑AbstractApplicationContext的refresh()方法如下
public void refresh() { synchronized (this.startupShutdownMonitor) { // 刷新前的预准备工作 prepareRefresh(); // 提取bean的配置信息并封装成BeanDefinition实例，然后将其添加到注册中心。注册中心是一个ConcurrentHashMap&lt;String,BeanDefinition>类型，key为Bean的名字，value为BeanDefinition实例。 ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); //对beanFactory进行一些配置，注册一些BeanPostProcessor和一些特殊的Bean。 prepareBeanFactory(beanFactory);
//留给子类在BeanFactory准备工作完成后处理一些工作。
postProcessBeanFactory(beanFactory);
//调用 BeanFactory的后置处理器。
invokeBeanFactoryPostProcessors(beanFactory);
//注册Bean的后置处理器。
registerBeanPostProcessors(beanFactory);
//国际化相关功能
initMessageSource();
//初始化事件派发器；
initApplicationEventMulticaster();
// 提供给子容器类，供子容器去实例化其他的特殊的Bean
onRefresh();
// 处理容器中已有的ApplicationListener
registerListeners();
//初始化容器中剩余的单实例bean
finishBeanFactoryInitialization(beanFactory);
//最后一步
finishRefresh();
}
}
prepareRefresh() 记录启动时间，设置容器的active和close状态。 initPropertySources():提供给子容器类，子容器类可覆盖该方法进行一些自定义的属性设置。 getEnvironment().validateRequiredProperties()：检验属性的合法性 this.earlyApplicationEvents = new LinkedHashSet() ：保存容器中的一些早期的事件，待事件多播器创建后执行。 obtainFreshBeanFactory() 提取bean的配置信息并封装成BeanDefinition实例，然后将其添加到注册中心。注册中心是一个ConcurrentHashMap&lt;String,BeanDefinition>类型，key为Bean的名字，value为BeanDefinition实例。
refreshBeanFactory：如果当前容器已经有了BeanFactory就销毁原来的BeanFactory。然后创建一个DefaultListableBeanFactory(); 对BeanFactory并进行配置，主要配置是否允许BeanDefinition覆盖，是否允许Bean间的循环引用。 加载BeanDefinition，解析XML文件和配置文件，将其转换为BeanDefinition，然后保存到DefaultListableBeanFactory的beanDefinitionMap字段中。 getBeanFactory() 简单的返回beanFactory，即DefaultListableBeanFactory。 prepareBeanFactory（） 设置BeanFactory的类加载器、设置支持SPEL表达式的解析器。 添加ApplicationContextAwareProcessor用于处理XXXAware接口的回调。 设置忽略一些接口。并注册一些类，这些类可以在bean里直接进行自动装配。 添加ApplicationListenerDetector用于识别并保存ApplicationListener的子类。 postProcessBeanFactory（）： 提供给子容器类，子容器类可以覆盖该方法在BeanFactory准备工作完成后处理一些工作。
invokeBeanFactoryPostProcessors() 执行BeanFactoryPostProcessor类型的监听方法。
BeanFactoryPostProcessor是beanFactory后置处理器，在整个BeanFactory标准初始化完成后进行拦截调用，
BeanDefinitionRegistryPostProcessor继承了BeanFactoryPostProcessor，在beanFactory解析完所有的BeanDefinition后拦截调用。
BeanFactoryPostProcessor来源
通过ApplicationContent的addBeanFactoryPostProcessor()方法手动添加自己的拦截器 系统默认了一些BeanFactoryPostProcessor。例如：ConfigurationClassPostProcessor用来处理@Configuration标注的Spring配置类。 调用顺序
先调用BeanDefinitionRegistryPostProcessor类型的拦截器， 然后再依次调用实现了PriorityOrdered,Ordered接口的BeanFactoryPostProcessor 最后调用普通的BeanFactoryPostProcessor BeanFactoryPostProcessor是beanFactory后置处理器，在整个BeanFactory标准初始化完成后进行拦截调用，
BeanDefinitionRegistryPostProcessor继承了BeanFactoryPostProcessor，在beanFactory解析完所有的BeanDefinition后拦截调用。
BeanFactoryPostProcessor来源
通过ApplicationContent的addBeanFactoryPostProcessor()方法手动添加自己的拦截器 系统默认了一些BeanFactoryPostProcessor。例如：ConfigurationClassPostProcessor用来处理@Configuration标注的Spring配置类。 调用顺序
先调用BeanDefinitionRegistryPostProcessor类型的拦截器， 然后再依次调用实现了PriorityOrdered,Ordered接口的BeanFactoryPostProcessor 最后调用普通的BeanFactoryPostProcessor registerBeanPostProcessors() 注册Bean的后置处理器。
从beanFactory里获取所有BeanPostProcessor类型的Bean的名称。
调用beanFactory的getBean方法并传入每一个BeanPostProcesso类型的Bean名称，从容器中获取该Bean的实例。
第一步向beanFactory注册实现了PriorityOrdered的BeanPostProcessor类型的Bean实例。 第二步向beanFactory注册实现了Ordered的BeanPostProcessor类型的Bean实例。 第三步向beanFactory注册普通的BeanPostProcessor类型的Bean实例。 最后一步向beanFactory重新注册实现了MergedBeanDefinitionPostProcessor的BeanPostProcessor类型的Bean实例 向beanFactory注册BeanPostProcessor的过程就是简单的将实例保存到beanFactory的beanPostProcessors属性中。
initMessageSource() 国际化相关功能
看容器中是否有id为messageSource的，类型是MessageSource的Bean实例。如果有赋值给messageSource，如果没有自己创建一个DelegatingMessageSource。 把创建好的MessageSource注册在容器中，以后获取国际化配置文件的值的时候，可以自动注入MessageSource。 initApplicationEventMulticaster() 初始化事件派发器；
看容中是否有名称为applicationEventMulticaster的，类型是ApplicationEventMulticaster的Bean实例。如果没有就创建一个SimpleApplicationEventMulticaster。 把创建好的ApplicationEventMulticaster添加到BeanFactory中。 onRefresh()： 提供给子容器类，供子容器去实例化其他的特殊的Bean。
registerListeners()： 处理容器中已有的ApplicationListener。
1. 从容器中获得所有的ApplicationListener 2. 将每个监听器添加到事件派发器（ApplicationEventMulticaster）中； 3. 处理之前步骤产生的事件； finishBeanFactoryInitialization()： 初始化容器中剩余的单实例bean：拿到剩余的所有的BeanDefinition，依次调用getBean方法（详看beanFactory.getBean的执行流程）
finishRefresh()： 最后一步。
1. 初始化和生命周期有关的后置处理器；LifecycleProcessor，如果容器中没有指定处理就创建一个DefaultLifecycleProcessor加入到容器。 2. 获取容器中所有的LifecycleProcessor回调onRefresh()方法。 3. 发布容器刷新完成事件ContextRefreshedEvent。 ConfigurationClassPostProcessor处理@Configuration的过程： 先从主从中心取出所有的BeanDefinition。依次判断，若一个BeanDefinition是被@Configuration标注的，spring将其标记为FullMode，否则若一个BeanDefinition没有被@Configuration标注，但有被@Bean标注的方法，spring将其标记为LightMode。筛选出所有候选配置BeanDefinition（FullMode和LightMode） 创建一个ConfigurationClassParser，调用parse方法解析每一个配置类。 解析@PropertySources,将解析结果设置到Environment 利用ComponentScanAnnotationParser，将@ComponentScans标签解析成BeanDefinitionHolder。再迭代解析BeanDefinitionHolder 解析@Import，@ImportResource 将@Bean解析为MethodMetadata，将结果保存到ConfigurationClass中。最终ConfigurationClass会被保存到ConfigurationClassParser的configurationClasses中。 调用ConfigurationClassParser的loadBeanDefinitions方法，加载解析结果到注册中。 从利用ComponentScanAnnotationParser的configurationClasses获取所有的ConfigurationClass，依次调用loadBeanDefinitionsForConfigurationClass方法。 loadBeanDefinitionsForConfigurationClass会将每一个BeanMethod转为ConfigurationClassBeanDefinition，最后将其添加到spring的注册中心。 beanFactory.getBean方法执行的过程 首先将方法传入的beanName进行转换：先去除FactoryBean前缀（&amp;符）如果传递的beanName是别名，则通过别名找到bean的原始名称。 根据名称先从singletonObjects（一个Map类型的容）获取bean实例。如果能获取到就先判断该bean实例是否实现了FactoryBean，如果是FactoryBean类型的bean实例，就通过FactoryBean获取Bean。然后直接返回该bean实例。getBean方法结束。 如果从singletonObjects没有获取到bean实例就开始创建Bean的过程。 首先标记该Bean处于创建状态。 根据Bean的名称找到BeanDefinition。查看该Bean是否有前置依赖的Bean。若有则先创建该Bean前置依赖的Bean。 spring调用AbstractAutowireCapableBeanFactory的createBean方法并传入BeanDefinition开始创建对象。先调用resolveBeforeInstantiation给BeanPostProcessor一个机会去返回一个代理对象去替代目标Bean的实例。 如果BeanPostProcessor没有返回Bean的代理就通过doCreateBean方法创建对象。 首先确定Bean的构造函数，如果有有参构造器，先自动装配有参构造器，默认使用无参数构造器。 选择一个实例化策略去实例化bean。默认使用CglibSubclassingInstantiationStrategy。该策略模式中,首先判断bean是否有方法被覆盖,如果没有则直接通过反射的方式来创建,如果有的话则通过CGLIB来实例化bean对象. 把创建好的bean对象包裹在BeanWrapper里。 调用MergedBeanDefinitionPostProcessor的postProcessMergedBeanDefinition 判断容器是否允许循环依赖，如果允许循环依赖，就创建一个ObjectFactory类并实现ObjectFactory接口的唯一的一个方法getObject（）用于返回Bean。然后将该ObjectFactory添加到singletonFactories中。 调用populateBean为bean实例赋值。在赋值之前执行InstantiationAwareBeanPostProcessor的postProcessAfterInstantiation和postProcessPropertyValues方法。 调用initializeBean初始化bean。如果Bean实现了XXXAware，就先处理对应的Aware方法。然后调用beanProcessor的postProcessBeforeInitialization方法。再以反射的方式调用指定的bean指定的init方法。最后调用beanProcessor的postProcessAfterInitialization方法。 调用registerDisposableBeanIfNecessary，将该bean保存在一个以beanName为key，以包装了bean引用的DisposableBeanAdapter，为value的map中，在spring容器关闭时，遍历这个map来获取需要调用bean来依次调用Bean的destroyMethod指定的方法。 将新创建出来的Bean保存到singletonObjects中 spring原理补充 spring解决循环依赖 以类A，B互相依赖注入为例
根据类A的名称先从singletonObjects获取Bean实例，发现获取不到，就通过doGetBean方法开始创建Bean的流程。 根据A的名称找到对应的BeanDefinition，通过doCreateBean（）方法创建对象，先确定类A的构造函数，然后选择一个实例化策略去实例化类A。 判断容器是否允许循环依赖，如果允许循环依赖，就创建一个ObjectFactory类并实现ObjectFactory接口的唯一的一个方法getObject（）用于返回类A。然后将该ObjectFactory添加到singletonFactories中。 调用populateBean（）为类A进行属性赋值，发现需要依赖类B，此时类B尚未创建，启动创建类B的流程。 根据类B的名称先从singletonObjects获取Bean实例，发现获取不到，就开始通过doGetBean方法开始创建Bean的流程 找到类B对应的BeanDefinition，确认B的构造函数，然后实例化B。 判断容器是否允许循环依赖，创建一个ObjectFactory并实现getObject（）方法，用于返回类B，并添加到singletonFactories中。 调用populateBean（）为类B进行属性赋值，发现需要依赖类A，调用getSingleton方法获取A：A现在已存在于singletonFactories中，getSingleton将A从singletonFactories方法中移除并放入earlySingletonObjects中。 调用getSingleton（）方法获取B：getSingleton将A从singletonFactories方法中移除并放入earlySingletonObjects中。 调用initializeBean初始化bean，最后将新创建出来的类B保存到singletonObjects中 调用getSingleton（）方法获取A，这时A已在earlySingletonObjects中了，就直接返回A 调用initializeBean初始化bean，最后将新创建出来的类B保存到singletonObjects中。 @Autowire 实现原理 上面介绍beanFactory.getBean方法执行的过程中提到：populateBean为bean实例赋值。在赋值之前执行InstantiationAwareBeanPostProcessor的postProcessAfterInstantiation和postProcessPropertyValues方法。@Autowire由AutowiredAnnotationBeanPostProcessor完成，它实现了InstantiationAwareBeanPostProcessor。 AutowiredAnnotationBeanPostProcessor执行过程：
postProcessAfterInstantiation方法执行，直接return null。 postProcessPropertyValues方法执行，主要逻辑在此处理。待补充。。。。。</content></entry><entry><title>Linux-unix编程手册-文件</title><url>/post/linux-unix-file/</url><categories><category>Linux</category><category>IO</category></categories><tags><tag>Linux</tag><tag>File</tag><tag>IO</tag></tags><content type="html"> Linux-unix编程手册-文件
1. 概述 所有执行 I/O 操作的系统调用都以文件描述符，一个非负整数（通常是小整数），来指代打开的文件。文件描述符用以表示所有类型的已打开文件，包括管道（pipe）、FIFO、socket、终端、设备和普通文件。针对每个进程，文件描述符都自成一套</content></entry><entry><title>软件架构设计读书笔记</title><url>/post/%E8%BD%AF%E4%BB%B6%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</url><categories><category>架构原理</category><category>中间件</category></categories><tags><tag>软件架构</tag><tag>底层原理</tag><tag>中间件</tag></tags><content type="html"> 根据软件架构设计：大型网站技术架构与业务架构融合之道一书所作的读书笔记
1. 架构分层 第一层：基础架构
指云平台、操作系统、网络、存储、数据库等
第二层：中间件与大数据平台
中间件：如分布式服务中间件，消息中间件、数据库中间件、缓存中间件、监控中间件、工作流或者规则引擎等 大数据架构：Hadoop生态体系，hive,Spark,Storm,Flink等 第三层：业务系统架构
通用软件系统，常用的办公软件、浏览器、播放器等 离线业务系统，如各种基于大数据的BI分析，数据挖掘，报表与可视化。 大型在线业务系统，如搜索，推荐，即时通信，电商，游戏，广告，企业ERP等 架构的道与术：解决一系列问题的方法论即为道，具体到某种语言技术，某个中间件的使用即为术。道是知行合一中的知，是理论，套路，方法论。术是行，是实践操作，用于解决一个个实际问题
2. 计算机功底 WAL即 Write Ahead Log，WAL的主要意思是说在将元数据的变更操作写入磁盘之前，先预先写入到一个log文件中，增加IO速度。磁盘顺序读写速度可媲美内存速度。 Checksum：总和检验码，校验和。在数据处理和数据通信领域中，用于校验目的的一组数据项的和。这些数据项可以是数字或在计算检验总和过程中看作数字的其它字符串，可以保证数据的完整性和正确性 TCP如何把不可靠变成可靠，mvcc解决并发多版本一致性等 计算机思维举例，可以借鉴
3. 操作系统 缓冲IO与直接IO
缓冲IO是C语言提供的函数库，以f打头，如fopen,fclose,fseek,fread,fwrite，直接IO是Linux系统的API,如open,read，write等
对于缓冲IO,读写都是三次拷贝
读：磁盘→内核缓冲区→用户缓冲区→应用程序内存
写：应用程序内存→用户缓冲区→内核缓冲区→磁盘
对于直接IO,读写都是两次数据拷贝
读：磁盘→内核缓冲区→应用程序内存
写：应用程序内存→内核缓冲区→磁盘
所以，直接IO没有用户缓冲区
应用层序内存：通常是代码用malloc/free、new/delete等分配出来的内存
用户缓冲区：C语言的FILE结构体中的buffer
内核缓冲区：Linux操作系统的Page Cahce。为了加快磁盘IO，Linux会把磁盘上的数据以page为单位加载到内存中，page是一个逻辑概念，一般一个page为4K
缓冲IO与直接IO有几点需要贴别说明：
fflush和fsync的区别。fflush是缓冲IO的一个api，作用是把数据从用户缓存刷到内核缓存，fsync是把数据从内核缓存刷到磁盘，所以无论是直接IO还是缓冲IO在写数据之后不调用fsync,此时断电的话会造成数据丢失。 对于直接IO也有read/write和pread/pwrite两组api，后者在多线程读写同一个文件时效率更高 内存映射与零拷贝
相较于直接IO,内存映射文件更进一步，其实现是用应用程序的逻辑内存与Linux操作系统的内核缓存区映射，相当于与内核共用内存，数据拷贝只需一次即
磁盘$\Leftrightarrow$内核缓冲区</content></entry><entry><title>java设计模式</title><url>/post/java%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/</url><categories><category>Design Pattern</category></categories><tags><tag>design pattern</tag><tag>java</tag></tags><content type="html"> java 设计模式学习
1 七大原则 单一职责原则：一个类只负责一个功能领域中的相应职责，或者可以定义为：就一个类而言，应该只有一个引起它变化的原因
开闭原则：一个软件实体应当对扩展开放，对修改关闭。即软件实体应尽量在不修改原有代码的情况下进行扩展。 为了满足开闭原则，需要对系统进行抽象化设计，抽象化是开闭原则的关键，可以为系统定义一个相对稳定的抽象层，而将不同的实现行为移至具体的实现层中完成。
里氏代换原则：所有引用基类（父类）的地方必须能透明地使用其子类的对象。里氏代换原则是实现开闭原则的重要方式之一，由于使用基类对象的地方都可以使用子类对象，因此在程序中尽量使用基类类型来对对象进行定义，而在运行时再确定其子类类型，用子类对象来替换父类对象
在使用里氏代换原则时需要注意如下几个问题：
子类的所有方法必须在父类中声明，或子类必须实现父类中声明的所有方法。根据里氏代换原 则，为了保证系统的扩展性，在程序中通常使用父类来进行定义，如果一个方法只存在子类中，在父类中不提供相应的声明，则无法在以父类定义的对象中使用该方法。 我们在运用里氏代换原则时，尽量把父类设计为抽象类或者接口，让子类继承父类或实现父接口，并实现在父类中声明的方法，运行时，子类实例替换父类实例，我们可以很方便地扩展系统的功能，同时无须修改原有子类的代码，增加新的功能可以通过增加一个新的子类来实现。里氏代换原则是开闭原则的具体实现手段之一。 依赖倒转原则：抽象不应该依赖于细节，细节应当 依赖于抽象。换言之，要针对接口编程，而不是针对实现编程。依赖倒转原则要求我们在程序代码中传递参数时或在关联关系中，尽量引用层次高的抽象层类，即使
用接口和抽象类进行变量类型声明、参数类型声明、方法返回类型声明，以及数据类型的转换等，而不要用具体类来做这些事情。
在实现依赖倒转原则时，我们需要针对抽象层编程，而将具体类的对象通过依赖注入(DependencyInjection, DI)的方式注入到其他对象中，依赖注入是指当一个对象要与其他对象 发生依赖关系时，通过抽象来注入所依赖的对象。常用的注入方式有三种，分别是：构造注入，设值注入（Setter注入）和接口注入
接口隔离原则：使用多个专门的接口，而不使用单一的总接口，即客户端不应该依赖那些它不需要的接口。
合成复用原则：尽量使用对象组合，而不是继承来达到复用的目的。合成复用原则就是在一个新的对象里通过关联关系（包括组合关系和聚合关系）来使用一些已有的对象，使之成为新对象的一部分；新对象通过委派调用已有对象的方法达到复用功能的目的。
两个类之间是“Has-A”的关系应使用组合或聚合，如果是“Is-A”关系可使用继 承。”Is-A”是严格的分类学意义上的定义，意思是一个类是另一个类的”一种”；而”Has-A”则不同，它表示某一个角色具有某一项责任。
迪米特法则：一个软件实体应当尽可能少地与其他实体发生相互作用（最少知道原则）。
不要和“陌生人”说话、只与你的直接朋友通信等，在迪米特法 则中，对于一个对象，其朋友包括以下几类：
当前对象本身(this)；
以参数形式传入到当前对象方法中的对象；
当前对象的成员对象；
如果当前对象的成员对象是一个集合，那么集合中的元素也都是朋友；
当前对象所创建的对象。
任何一个对象，如果满足上面的条件之一，就是当前对象的“朋友”，否则就是“陌生人”。
迪米特法则要求我们在设计系统时，应该尽量减少对象之间的交互，如果两个对象之间不必彼此直接 通信，那么这两个对象就不应该发生任何直接的相互作用，如果其中的一个对象需要调用另一个对象 的某一个方法的话，可以通过第三者转发这个调用。简言之，就是通过引入一个合理的第三者来降低 现有对象之间的耦合度。</content></entry><entry><title>MySql原理学习记录</title><url>/post/mysql%E5%8E%9F%E7%90%86%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</url><categories><category>MySql</category><category>MySql Basis</category></categories><tags><tag>MySql</tag><tag>原理知识</tag></tags><content type="html"> 根据《MySql是怎样运行的一书》整理记录知识点
1 mysql编码 mysql支持41种字符集包括常用的utf-8、ASCII、GB2312等
utf是unicode编码的一种实现方式，utf8使用1～4个字节编码一个字符，utf16使用2个或4个字节编码一个字符，utf32使用4个字节编码一个字符 mysql中的utf8(utf8mb3)是标准utf8的阉割版，采用1~3个字节存储字符，涵盖常用字符的表示范围 mysql中utf8mb4 才是正宗的 utf8 字符集，使用1～4个字节表示字符，可以表示不常用字符，如表情符号等 SHOW CHARACTER SET;查看字符集 比较规则，比较规则和字符集是绑定的
每种字符集都有几种对应的比较规则，如忽略大小写等，比较规则用于比较字符或者排序（order by）
SHOW COLLATION [LIKE 匹配的模式]; SHOW COLLATION LIKE &lsquo;utf8_%&rsquo;;查看utf8编码的比较规则 字符集和比较规则的应用
MySQL 有4个级别的字符集和比较规则，数据字符集采用就近原则，如果没有就从上级继承，从上到下级别分别是：①服务器级别②数据库③表级别④列级别
以服务器级别为例：
SHOW VARIABLES in(&lsquo;character_set_server&rsquo;,&lsquo;collation_server&rsquo;);查看服务器级别的字符集和比较规则
数据库乱码原因及原理
结论：编码和解码使用的字符集不一致的后果
mysql字符编系统变量
过程：客户端发往服务器的请求本质上就是一个字符串，服务器向客户端返回的结果本质上也是一个字符。过程分为三步：①客户端发送往服务器的字符串经过编码成二进制数据才能发送，比如客户端的默认编码是gbk，发送的数据就是以gbk字符集编码的二进制数据，数据到了mysql端，mysql就会使用character_set_client字符集来对数据进行解码，如果字符集不是gbk这一步就会乱码，导致sql语句无法正确解析②第一步成功编解码之后，服务器会把字符按照character_set_connection字符集进行编码，然后拿着编码后的数据去数据库表中对应列进行匹配（数据库中字段值是按照character_set_connection字符集编码后存储的）③最后将查出来的数据用character_set_results编码之后发给客户端，客户端再用客户端默认字符集解码得到最终展示数据
总结：服务器认为客户端发送过来的请求是用 character_set_client 编码的。假设你的客户端采用的字符集和 character_set_client 不一样的话，这就会出现意想不到的情况。比如我的客户端使用的是 utf8 字符集，如果把系统变量 character_set_client 的值设置为 ascii 的话，服务器可能无法理解我们发送的请求，更别谈处理这个请求了。服务器将把得到的结果集使用 character_set_results 编码后发送给客户端。假设你的客户端采用的字符集和 character_set_results 不一样的话，这就可能会出现客户端无法解码结果集的情况，结果就是在你的屏幕上出现乱码。客户端默认字符集==character_set_client==character_set_results才不会乱码
设置成统一字符集
SET NAMES 字符集名;
等价于：
SET character_set_client = 字符集名;
SET character_set_connection = 字符集名;
SET character_set_results = 字符集名;
等价于：
在my.cnf配置文件中
[client]
default-character-set=字符集名
2 存储引擎InnoDB 我们平时是以记录为单位来向表中插入数据的，这些记录在磁盘上的存放方式也被称为 行格式 或者 记录格式 设计 InnoDB 存储引擎的大叔们到现在为止设计了4种不同类型的 行格式 ，分别是 Compact 、 Redundant Dynamic 和 Compressed 行格式
行格式用法：
CREATE TABLE 表名 (列的信息) ROW_FORMAT=Compact
ALTER TABLE 表名 ROW_FORMAT=Compact
compact行格式
变长字段长度列表
变长字段，使用变长数据类型（varchar(n)，blob,text等）或者变长字符集（如utf8是1~3个字符）存储的字段。在 Compact 行格式中，把所有变长字段的真实数据占用的字节长度都存放在记录的开头部位，从而形成一个变长字段长度列表，各变长字段数据占用的字节数按照列的顺序逆序存放，
NULL值列表
我们知道表中的某些列可能存储 NULL 值，如果把这些 NULL 值都放到 记录的真实数据 中存储会很占地方，所以 Compact 行格式把这些值为 NULL 的列统一管理起来，存储到 NULL 值列表中，它的处理过程是这样的：
首先统计表中允许存储 NULL 的列有哪些。我们前边说过，主键列、被 NOT NULL 修饰的列都是不可以存储 NULL 值的，所以在统计的时候不会把这些列算进去。比方说表 record_format_demo 的3个列 c1 、 c3 、 c4 都是允许存储 NULL 值的，而 c2 列是被NOT NULL 修饰，不允许存储 NULL 值。
如果表中没有允许存储 NULL 的列，则 NULL值列表 也不存在了，否则将每个允许存储 NULL 的列对应一个二进制位，二进制位按照列的顺序逆序排列，二进制位表示的意义如下：二进制位的值为 1 时，代表该列的值为 NULL 。二进制位的值为 0 时，代表该列的值不为 NULL
MySQL 规定 NULL值列表 必须用整数个字节的位表示，如果使用的二进制位个数不是整数个字节，则在字节的高位补 0 。 表 record_format_demo 只有3个值允许为 NULL 的列，对应3个二进制位，不足一个字节，所以在字节的高位补 0
记录头信息
除了 变长字段长度列表 、 NULL值列表 之外，还有一个用于描述记录的 记录头信息 ，它是由固定的 5 个字节组成。 5 个字节也就是 40 个二进制位，不同的位代表不同的意思
存储行
/*MySQL 对一条记录占用的最大存储空间是有限制的，除了 BLOB 或者 TEXT 类型的列之 外，其他所有的列（不包括隐藏列和记录头信息）占用的字节长度加起来不能超过 65535 个字节 存储一个 VARCHAR(M) 类型的列，其实需要占用3部分存储空间： ①真实数据 ②真实数据占用字节的长度 ③NULL 值标识，如果该列有 NOT NULL 属性则可以没有这部分存储空间 如果该 VARCHAR 类型的列没有 NOT NULL 属性，那最多只能存储 65532 个字节的数据，因为真实数据的长度可能 占用2个字节， NULL 值标识需要占用1个字节： */ CREATE TABLE varchar_size_demo( c1 VARCHAR(65532) )CHARSET=ASCII ROW_FORMAT=COMPACT; /*编码如果是gbk,最多只能32766 （也就是：65532/2），因为gbk一个字符占两个字节 utf8 字符集表示一个字符最多需要 3 个字节，那在该字符集下， M 的最大取值就是 21844 ，就是说最多能存 储 21844 （也就是：65532/3）个字符*/ /*这些都是表中只有一个字段的情况下，如果是多个字段，则所有字段（（不包括隐藏 列和记录头信息））加起来不能超过65535*/ CREATE TABLE varchar_size_demo( c VARCHAR(32766) ) CHARSET=gbk ROW_FORMAT=COMPACT; 3 访问方法 const: 通过主键或者唯一二级索引列与常数的等值比较来定位一条记录,如果主键或者唯一二级索引是由多个列构成的话，索引中的每一个列都需要与常数进行等值比较
ref：通过某个普通的二级索引列与常数进行等值比较（普通二级索引与唯一二级索引对应，普通二级索引等值比较可能查出多个列）
二级索引列值为 NULL 的情况
不论是普通的二级索引，还是唯一二级索引，它们的索引列对包含 NULL 值的数量并不限制，所以我们采用key IS NULL 这种形式的搜索条件最多只能使用 ref 的访问方法，而不是 const 的访问方法。
对于某个包含多个索引列的二级索引来说，只要是最左边的连续索引列是与常数的等值比较就可能采用 ref的访问方法，比方说下边这几个查询：
SELECT * FROM single_table WHERE key_part1 = &lsquo;god like&rsquo;;
SELECT * FROM single_table WHERE key_part1 = &lsquo;god like&rsquo; AND key_part2 = &rsquo;legendary&rsquo;;
SELECT * FROM single_table WHERE key_part1 = &lsquo;god like&rsquo; AND key_part2 = &rsquo;legendary&rsquo;
AND key_part3 = &lsquo;penta kill&rsquo;。但是如果最左边的连续索引列并不全部是等值比较的话，它的访问方法就不能称为 ref 了，比方说这样： SELECT * FROM single_table WHERE key_part1 = &lsquo;god like&rsquo; AND key_part2 > &rsquo;legendary&rsquo;;
ref_or_null：有时候我们不仅想找出某个二级索引列的值等于某个常数的记录，还想把该列的值为 NULL 的记录也找出来，就像下边这个查询：
SELECT * FROM single_demo WHERE key1 = &lsquo;abc&rsquo; OR key1 IS NULL;
range：利用索引进行范围匹配
index：遍历二级索引记录的执行方式
SELECT key_part1, key_part2, key_part3 FROM single_table WHERE key_part2 = &lsquo;abc&rsquo;;
key_part1, key_part2, key_part3三个要查询的字段是联合索引，查询条件key_part2 不是最左索引，此时需要直接通过遍历 idx_key_part 索引的叶子节点的记录来比较 key_part2 = &lsquo;abc&rsquo; 这个条件是否成立，把匹配成功的二级索引记录的 key_part1 , key_part2 , key_part3 列的值直接加到结果集中就行了，不需要回表
当我们可以使用索引覆盖，但需要扫描全部的索引记录时，该表的访问方法就是 index ，比如这样：
mysql> EXPLAIN SELECT key_part2 FROM s1 WHERE key_part3 = &lsquo;a&rsquo;;
+&mdash;-+&mdash;&mdash;&mdash;&mdash;-+&mdash;&mdash;-+&mdash;&mdash;&mdash;&mdash;+&mdash;&mdash;-+&mdash;&mdash;&mdash;&mdash;&mdash;+&mdash;&mdash;&mdash;&mdash;&ndash;+&mdash;-
&mdash;&ndash;+&mdash;&mdash;+&mdash;&mdash;+&mdash;&mdash;&mdash;-+&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;+
| id | select_type | table | partitions | type | possible_keys | key | key
_len | ref | rows | filtered | Extra |
+&mdash;-+&mdash;&mdash;&mdash;&mdash;-+&mdash;&mdash;-+&mdash;&mdash;&mdash;&mdash;+&mdash;&mdash;-+&mdash;&mdash;&mdash;&mdash;&mdash;+&mdash;&mdash;&mdash;&mdash;&ndash;+&mdash;-
&mdash;&ndash;+&mdash;&mdash;+&mdash;&mdash;+&mdash;&mdash;&mdash;-+&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;+
| 1 | SIMPLE | s1 | NULL | index | NULL | idx_key_part | 909
| NULL | 9688 | 10.00 | Using where; Using index |
+&mdash;-+&mdash;&mdash;&mdash;&mdash;-+&mdash;&mdash;-+&mdash;&mdash;&mdash;&mdash;+&mdash;&mdash;-+&mdash;&mdash;&mdash;&mdash;&mdash;+&mdash;&mdash;&mdash;&mdash;&ndash;+&mdash;-
&mdash;&ndash;+&mdash;&mdash;+&mdash;&mdash;+&mdash;&mdash;&mdash;-+&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;+
1 row in set, 1 warning (0.00 sec)
上述查询中的搜索列表中只有 key_part2 一个列，而且搜索条件中也只有 key_part3 一个列，这两个列又恰
好包含在 idx_key_part 这个索引中，可是搜索条件 key_part3 不能直接使用该索引进行 ref 或者 range 方
式的访问，只能扫描整个 idx_key_part 索引的记录，所以查询计划的 type 列的值就是 index 。
小贴士：
再一次强调，对于使用InnoDB存储引擎的表来说，二级索引的记录只包含索引列和主键列的值，
而聚簇索引中包含用户定义的全部列以及一些隐藏列，所以扫描二级索引的代价比直接全表扫描，
也就是扫描聚簇索引的代价更低一些。
all：全表扫描
eq_ref：在连接查询时，如果被驱动表是通过主键或者唯一二级索引列等值匹配的方式进行访问的（如果该主键或者唯一二级索引是联合索引的话，所有的索引列都必须进行等值比较），则对该被驱动表的访问方法就是
eq_ref
index_merge：一般情况下对于某个表的查询只能使用到一个索引，在某些场景下可以使用 Intersection 、 Union 、 Sort-Union 这三种索引合并的方式来执行查询，如
mysql> EXPLAIN SELECT * FROM s1 WHERE key1 = &lsquo;a&rsquo; OR key3 = &lsquo;a&rsquo;;
+&mdash;-+&mdash;&mdash;&mdash;&mdash;-+&mdash;&mdash;-+&mdash;&mdash;&mdash;&mdash;+&mdash;&mdash;&mdash;&mdash;-+&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;-+&mdash;&mdash;&mdash;
&mdash;&mdash;&mdash;-+&mdash;&mdash;&mdash;+&mdash;&mdash;+&mdash;&mdash;+&mdash;&mdash;&mdash;-+&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;-
&mdash;&ndash;+
| id | select_type | table | partitions | type | possible_keys | key
| key_len | ref | rows | filtered | Extra |
+&mdash;-+&mdash;&mdash;&mdash;&mdash;-+&mdash;&mdash;-+&mdash;&mdash;&mdash;&mdash;+&mdash;&mdash;&mdash;&mdash;-+&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;-+&mdash;&mdash;&mdash;
&mdash;&mdash;&mdash;-+&mdash;&mdash;&mdash;+&mdash;&mdash;+&mdash;&mdash;+&mdash;&mdash;&mdash;-+&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;-
&mdash;&ndash;+
| 1 | SIMPLE | s1 | NULL | index_merge | idx_key1,idx_key3 | idx_key
1,idx_key3 | 303,303 | NULL | 14 | 100.00 | Using union(idx_key1,idx_key3); Using
where |
+&mdash;-+&mdash;&mdash;&mdash;&mdash;-+&mdash;&mdash;-+&mdash;&mdash;&mdash;&mdash;+&mdash;&mdash;&mdash;&mdash;-+&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;-+&mdash;&mdash;&mdash;
&mdash;&mdash;&mdash;-+&mdash;&mdash;&mdash;+&mdash;&mdash;+&mdash;&mdash;+&mdash;&mdash;&mdash;-+&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;-
&mdash;&ndash;+
1 row in set, 1 warning (0.01 sec)
unique_subquery：类似于两表连接中被驱动表的 eq_ref 访问方法， unique_subquery 是针对在一些包含 IN 子查询的查询语句中，如果查询优化器决定将 IN 子查询转换为 EXISTS 子查询，而且子查询可以使用到主键进行等值匹配的话，那么该子查询执行计划的 type 列的值就是 unique_subquery ，比如下边的这个查询语句：
mysql> EXPLAIN SELECT * FROM s1 WHERE key2 IN (SELECT id FROM s2 where s1.key1 = s2.
key1) OR key3 = &lsquo;a&rsquo;;
+&mdash;-+&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;+&mdash;&mdash;-+&mdash;&mdash;&mdash;&mdash;+&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;+&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;
+&mdash;&mdash;&mdash;+&mdash;&mdash;&mdash;+&mdash;&mdash;+&mdash;&mdash;+&mdash;&mdash;&mdash;-+&mdash;&mdash;&mdash;&mdash;-+
| id | select_type | table | partitions | type | possible_keys
| key | key_len | ref | rows | filtered | Extra |
+&mdash;-+&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;+&mdash;&mdash;-+&mdash;&mdash;&mdash;&mdash;+&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;+&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;
+&mdash;&mdash;&mdash;+&mdash;&mdash;&mdash;+&mdash;&mdash;+&mdash;&mdash;+&mdash;&mdash;&mdash;-+&mdash;&mdash;&mdash;&mdash;-+
| 1 | PRIMARY | s1 | NULL | ALL | idx_key3
| NULL | NULL | NULL | 9688 | 100.00 | Using where |
| 2 | DEPENDENT SUBQUERY | s2 | NULL | unique_subquery | PRIMARY,idx_key1
| PRIMARY | 4 | func | 1 | 10.00 | Using where |
+&mdash;-+&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;+&mdash;&mdash;-+&mdash;&mdash;&mdash;&mdash;+&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;+&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;
+&mdash;&mdash;&mdash;+&mdash;&mdash;&mdash;+&mdash;&mdash;+&mdash;&mdash;+&mdash;&mdash;&mdash;-+&mdash;&mdash;&mdash;&mdash;-+
system：当表中只有一条记录并且该表使用的存储引擎的统计数据是精确的，比如MyISAM、Memory，那么对该表的访问方法就是 system
4 redo log 概念：在系统奔溃重启时需要按照上述内容所记录的步骤重新更新数据页，所以上述内容也被称之为 重做日志 ，英文名为 redo log 。
描述：想让已经提交了的事务对数据库中数据所做的修改永久生效，即使后来系统崩溃，在重启后也能把这种修改恢复出来。所以我们其实没有必要在每次事务提交时就把该事务在内存中修改过的全部页面刷新到磁盘，只需要把修改了哪些东西记录一下就好，这样我们在事务提交时，把上述内容刷新到磁盘中，即使之后系统崩溃了，重启之后只要按照上述内容所记录的步骤重新更新一下数据页，那么该事务对数据库中所做的修改又可以被恢复出来。
结构：
type ：该条 redo 日志的类型。
在 MySQL 5.7.21 这个版本中，设计 InnoDB 的大叔一共为 redo 日志设计了53种不同的类型，稍后会详细介
绍不同类型的 redo 日志。
space ID ：表空间ID。
page number ：页号。
data ：该条 redo 日志的具体内容。
刷盘时机：redo日志不会直接写入磁盘，而是写入内存的log buffer中，将log buffer刷入磁盘的时机有以下几种情况：①log buffer空间不足②事务提交③后台线程大概每秒会做一次刷盘④正常关闭服务器时⑤做checkpoint时
Mini-Transaction：底层页面中的一次原子访问的过程称之为一个 Mini-Transaction ，简称 mtr ，比如上边
所说的修改一次 Max Row ID 的值算是一个 Mini-Transaction ，向某个索引对应的 B+ 树中插入一条记录的过程也算是一个 Mini-Transaction 。通过上边的叙述我们也知道，一个所谓的 mtr 可以包含一组 redo 日志，在进行奔溃恢复时这一组 redo 日志作为一个不可分割的整体。一个事务可以包含若干条语句，每一条语句其实是由若干个 mtr 组成，每一个 mtr 又可以包含若干条 redo 日志
lsn和flushed_to_disk_lsn：日志序列号 ，简称 lsn有新的 redo 日志写入到 log buffer 时，首先 lsn 的值会增长。刷新到磁盘中的 redo 日志量的全局变量，称之为flushed_to_disk_lsn 。系统第一次启动时，该变量的值和初始的 lsn 值是相同的，都是 8704 。随着系统的运行， redo 日志被不断写入 log buffer ，但是并不会立即刷新到磁盘， lsn 的值就和 flushed_to_disk_lsn 的值拉开了差距，如果两者的值相同时，说明log buffer中的所有redo日志都已经刷新到磁盘中了
checkpoint：全局变量 checkpoint_lsn 来代表当前系统中可以被覆盖的 redo 日志总量是多少，比方说现在 页a 被刷新到了磁盘， mtr_1 生成的 redo 日志就可以被覆盖了，所以我们可以进行一个增加checkpoint_lsn 的操作，我们把这个过程称之为做一次 checkpoint 。计算一下当前系统中可以被覆盖的 redo 日志对应的 lsn 值最大是多少，redo 日志可以被覆盖，意味着它对应的脏页被刷到了磁盘，只要我们计算出当前系统中被最早修改的脏页对应的 oldest_modification 值，那凡是在系统lsn值小于该节点的oldest_modification值时产生的redo日志都是可以被覆盖掉的，我们就把该脏页的 oldest_modification 赋值给 checkpoint_lsn
崩溃恢复：系统崩溃后重启时根据 redo 日志中的记录就可以将页面恢复到系统奔溃前的状态。
崩溃恢复起点：checkpoint_lsn 之前的 redo 日志都可以被覆盖，也就是说这些 redo 日志对应的脏页都已经被刷新到磁盘中了，既然它们已经被刷盘，我们就没必要恢复它们了。对于 checkpoint_lsn 之后的 redo 日志，它们对应的脏页可能没被刷盘，也可能被刷盘了，我们不能确定，所以需要从 checkpoint_lsn 开始读取 redo 日志来恢复页面。 崩溃恢复的终点：写 redo 日志的时候都是顺序写的，写满了一个block之后会再往下一个block，普通block的 log block header 部分有一个称之为 LOG_BLOCK_HDR_DATA_LEN 的属性，该属性值记录了当前block里使用了多少字节的空间。对于被填满的block来说，该值永远为 512 。如果该属性的值不为 512，那该block就是最后一个block，也就是redo日志的终点。 怎么恢复：按照 redo 日志的顺序依次扫描checkpoint_lsn 之后的各条redo日志，按照日志中记载的内容将对应的页面恢复出来， 5 undo log 定义：在事务中为了回滚而记录的这些东东称之为撤销日志，英文名为 undo log 6 隔离级别 事务并发遇到的问题：
脏写（ Dirty Write ）：如果一个事务修改了另一个未提交事务修改过的数据，那就意味着发生了 脏写 脏读（ Dirty Read ）：如果一个事务读到了另一个未提交事务修改过的数据，那就意味着发生了 脏读 不可重复读（Non-Repeatable Read）：如果一个事务只能读到另一个已经提交的事务修改过的数据，并且其他事务每对该数据进行一次修改并提交后，该事务都能查询得到最新值，那就意味着发生了 不可重复读 幻读（Phantom）：如果一个事务先根据某些条件查询出一些记录，之后另一个事务又向表中插入了符合这些条件的记录，原先的事务再次按照该条件查询时，能把另一个事务插入的记录也读出来，那就意味着发生了 幻读 四种隔离级别：
READ UNCOMMITTED ：未提交读。
READ COMMITTED ：已提交读。
REPEATABLE READ ：可重复读。
SERIALIZABLE ：可串行化。
READ UNCOMMITTED 隔离级别下，可能发生 脏读 、 不可重复读 和 幻读 问题。
READ COMMITTED 隔离级别下，可能发生 不可重复读 和 幻读 问题，但是不可以发生 脏读 问题。
REPEATABLE READ 隔离级别下，可能发生 幻读 问题，但是不可以发生 脏读 和 不可重复读 的问题。
SERIALIZABLE 隔离级别下，各种问题都不可以发生。
MySQL在REPEATABLE READ隔离级别下，是可以禁止幻读问题的发生的
MVCC原理
版本链描述：每次对记录进行改动，都会记录一条 undo日志 ，每条 undo日志 也都有一个 roll_pointer 属性（ INSERT 操作对应的 undo日志 没有该属性，因为该记录并没有更早的版本），可以将这些 undo日志 都连来，串成一个链表，对该记录每次更新后，都会将旧值放到一条 undo日志 中，就算是该记录的一个旧版本，随着更新次数的增多，所有的版本都会被 roll_pointer 属性连接成一个链表，我们把这个链表称之为 版本链 ，版本链的头节点就是当前记录最新的值。另外，每个版本中还包含生成该版本时对应的 事务id
ReadView：对于使用 READ UNCOMMITTED 隔离级别的事务来说，由于可以读到未提交事务修改过的记录，所以直接读取记录的最新版本就好了；对于使用 SERIALIZABLE 隔离级别的事务来说，设计 InnoDB 的大叔规定使用加锁的方式来访问记录（加锁是啥我们后续文章中说哈）；对于使用 READ COMMITTED 和 REPEATABLE READ 隔离级别的事务来说，都必须保证读到已经提交了的事务修改过的记录，也就是说假如另一个事务已经修改了记录但是尚未提交，是不能直接读取最新版本的记录的，核心问题就是：需要判断一下版本链中的哪个版本是当前事务可见的。为此，设计 InnoDB 的大叔提出了一个 ReadView 的概念，这个 ReadView 中主要包含4个比较重要的内容：
m_ids ：表示在生成 ReadView 时当前系统中活跃的读写事务的 事务id 列表。
min_trx_id ：表示在生成 ReadView 时当前系统中活跃的读写事务中最小的 事务id ，也就是 m_ids 中的最
小值。
max_trx_id ：表示生成 ReadView 时系统中应该分配给下一个事务的 id 值。
小贴士：
注意max_trx_id并不是m_ids中的最大值，事务id是递增分配的。比方说现在有id为1，2，3这三
个事务，之后id为3的事务提交了。那么一个新的读事务在生成ReadView时，m_ids就包括1和2，mi
n_trx_id的值就是1，max_trx_id的值就是4。
creator_trx_id ：表示生成该 ReadView 的事务的 事务id 。
有了这个 ReadView ，这样在访问某条记录时，只需要按照下边的步骤判断记录的某个版本是否可见：
如果被访问版本的 trx_id 属性值与 ReadView 中的 creator_trx_id 值相同，意味着当前事务在访问它自己
修改过的记录，所以该版本可以被当前事务访问。如果被访问版本的 trx_id 属性值小于 ReadView 中的 min_trx_id 值，表明生成该版本的事务在当前事务生成 ReadView 前已经提交，所以该版本可以被当前事务访问。
如果被访问版本的 trx_id 属性值大于 ReadView 中的 max_trx_id 值，表明生成该版本的事务在当前事务生成 ReadView 后才开启，所以该版本不可以被当前事务访问。
如果被访问版本的 trx_id 属性值在 ReadView 的 min_trx_id 和 max_trx_id 之间，那就需要判断一下
trx_id 属性值是不是在 m_ids 列表中，如果在，说明创建 ReadView 时生成该版本的事务还是活跃的，该
版本不可以被访问；如果不在，说明创建 ReadView 时生成该版本的事务已经被提交，该版本可以被访问。
**在 MySQL 中， READ COMMITTED 和 REPEATABLE READ 隔离级别的的一个非常大的区别就是它们生成ReadView的时机不同，READ COMMITTED —— 每次读取数据前都生成一个****ReadView，REPEATABLE READ —— 在第一次读取数据时生成一个****ReadView
小结：从上边的描述中我们可以看出来，所谓的 MVCC （Multi-Version Concurrency Control ，多版本并发控制）指的就是在使用 READ COMMITTD 、 REPEATABLE READ 这两种隔离级别的事务在执行普通的 SEELCT 操作时访问记录的版本链的过程，这样子可以使不同事务的 读-写 、 写-读 操作并发执行，从而提升系统性能。 READ COMMITTD 、REPEATABLE READ 这两个隔离级别的一个很大不同就是：生成ReadView的时机不同，READ COMMITTD在每一次进行普通SELECT操作前都会生成一个ReadView，而REPEATABLE READ只在第一次进行普通SELECT操作前生成一个ReadView，之后的查询操作都重复使用这个ReadView就好了。
7 锁 结构属性：
trx信息 ：代表这个锁结构是哪个事务生成的。
is_waiting ：代表当前事务是否在等待。
type：Next-Key Locks/插入意向锁/&hellip;
加解锁过程：
事务 T1 要改动某条记录时，就生成了一个 锁结构 与该记录关联，因为之前没有别的事务为这条记录加锁，所以 is_waiting 属性就是 false ，我们把这个场景就称之为获取锁成功，或者加锁成功，然后就可以继续执行操作了。
在事务 T1 提交之前，另一个事务 T2 也想对该记录做改动，那么先去看看有没有 锁结构 与这条记录关联，发现有一个 锁结构 与之关联后，然后也生成了一个 锁结构 与这条记录关联，不过 锁结构 的is_waiting 属性值为 true ，表示当前事务需要等待，我们把这个场景就称之为获取锁失败，或者加锁失败，或者没有成功的获取到锁
在事务 T1 提交之后，就会把该事务生成的 锁结构 释放掉，然后看看还有没有别的事务在等待获取锁，发现了事务 T2 还在等待获取锁，所以把事务 T2 对应的锁结构的 is_waiting 属性设置为 false ，然后把该事务对应的线程唤醒，让它继续执行，此时事务 T2 就算获取到锁了
读操作利用多版本并发控制（ MVCC ），写操作进行加锁，除非有特殊场景需要读写都加锁，比如一些业务场景不允许读取记录的旧版本，而是每次都必须去读取记录的最新版本，比方在银行存款的事务中，你需要先把账户的余额读出来，然后将其加上本次存款的数额，最后再写到数据库中。在将账户余额读取出来后，就不想让别的事务再访问该余额，直到本次存款事务执行完成，其他事务才可以访问账户的余额。这样在读取记录的时候也就需要对其进行 加锁 操作，这样也就意味着 读操作和 写 操作也像 写-写 操作那样排队执行
一致性读和锁定读
事务利用 MVCC 进行的读取操作称之为 一致性读 ，或者 一致性无锁读 ，有的地方也称之为 快照读 。所有普通的 SELECT 语句（ plain SELECT ）在 READ COMMITTED 、 REPEATABLE READ 隔离级别下都算是 一致性读，一致性读 并不会对表中的任何记录做 加锁 操作，其他事务可以自由的对表中的记录做改动。
锁定读要求在读-读 情况不受影响，又要使 写-写 、 读-写 或 写-读 情况中的操作相互阻塞，mysql中用两种锁独占锁共享锁和独占锁来实现：
共享锁 ，英文名： Shared Locks ，简称 S锁 。在事务要读取一条记录时，需要先获取该记录的 S锁 独占锁 ，也常称 排他锁 ，英文名： Exclusive Locks ，简称 X锁 。在事务要改动一条记录时，需要先获取该记录的 X锁 假如事务 T1 首先获取了一条记录的 S锁 之后，事务 T2 接着也要访问这条记录：如果事务 T2 想要再获取一个记录的 S锁 ，那么事务 T2 也会获得该锁，也就意味着事务 T1 和 T2 在该记录上同时持有 S锁 。如果事务 T2 想要再获取一个记录的 X锁 ，那么此操作会被阻塞，直到事务 T1 提交之后将 S锁 释放掉。如果事务 T1 首先获取了一条记录的 X锁 之后，那么不管事务 T2 接着想获取该记录的 S锁 还是 X锁 都会被阻塞，直到事务 T1 提交。 总结：S锁 和 S锁 是兼容的， S锁 和 X锁 是不兼容的， X锁 和 X锁 也是不兼容的 加锁语句：S锁 SELECT &hellip; LOCK IN SHARE MODE; X锁 SELECT &hellip; FOR UPDATE; 写操作 DELETE ：对一条记录做 DELETE 操作的过程其实是先在 B+ 树中定位到这条记录的位置，然后获取一下这条记录的 X 锁 ，然后再执行 delete mark 操作。我们也可以把这个定位待删除记录在 B+ 树中位置的过程看成是一个获取 X锁 的 锁定读 。
UPDATE ：在对一条记录做 UPDATE 操作时分为三种情况：如果未修改该记录的键值并且被更新的列占用的存储空间在修改前后未发生变化，则先在 B+ 树中定位到这条记录的位置，然后再获取一下记录的 X锁 ，最后在原记录的位置进行修改操作。其实我们也可以把这个定位待修改记录在 B+ 树中位置的过程看成是一个获取 X锁 的 锁定读 。如果未修改该记录的键值并且至少有一个被更新的列占用的存储空间在修改前后发生变化，则先在B+ 树中定位到这条记录的位置，然后获取一下记录的 X锁 ，将该记录彻底删除掉（就是把记录彻底移入垃圾链表），最后再插入一条新记录。这个定位待修改记录在 B+ 树中位置的过程看成是一个获取 X 锁 的 锁定读 ，新插入的记录由 INSERT 操作提供的 隐式锁 进行保护。如果修改了该记录的键值，则相当于在原录上做 DELETE 操作之后再来一次 INSERT 操作，加锁操作就需要按照 DELETE 和 INSERT 的规则进行了。
INSERT ：一般情况下，新插入一条记录的操作并不加锁，设计 InnoDB 的大叔通过一种称之为 隐式锁 的东东来保护这条新插入的记录在本事务提交前不被别的事务访问，更多细节我们后边看哈～
多粒度锁
我们前边提到的 锁 都是针对记录的，也可以被称之为 行级锁 或者 行锁 ，对一条记录加锁影响的也只是这条记录而已，我们就说这个锁的粒度比较细；其实一个事务也可以在 表 级别进行加锁，自然就被称之为 表级锁 或 者 表锁 ，对一个表加锁影响整个表中的记录，我们就说这个锁的粒度比较粗。给表加的锁也可以分为 共享锁 S锁 ）和 独占锁 （ X锁 ）
给表加 S锁 ：如果一个事务给表加了 S锁 ，那么别的事务可以继续获得该表的 S锁，别的事务可以继续获得该表中的某些记录的 S锁，别的事务不可以继续获得该表的 X锁，别的事务不可以继续获得该表中的某些记录的 X锁
给表加 X锁 ：如果一个事务给表加了 X锁 （意味着该事务要独占这个表），那么：别的事务不可以继续获得该表的 S锁，别的事务不可以继续获得该表中的某些记录的 S锁别的事务不可以继续获得该表的 X锁，别的事务不可以继续获得该表中的某些记录的 X锁
我们在对教学楼整体上锁（ 表锁 ）时，怎么知道教学楼中有没有教室已经被上锁（ 行锁 ）了呢？依次检查每一间教室门口有没有上锁？那这效率也太慢了吧！遍历是不可能遍历的，这辈子也不可能遍历的，于是乎设计
InnoDB 的大叔们提出了一种称之为 意向锁
意向共享锁，英文名： Intention Shared Lock ，简称 IS锁 。当事务准备在某条记录上加 S锁 时，需要先
在表级别加一个 IS锁 。
意向独占锁，英文名： Intention Exclusive Lock ，简称 IX锁 。当事务准备在某条记录上加 X锁 时，需要先在表级别加一个 IX锁 。
当加表锁时，如果要加S锁，要查看表级有无IX锁，如果要加X锁，要看有无表级IS锁和IX锁
IS、IX锁是表级锁，它们的提出仅仅为了在之后加表级别的S锁和X锁时可以快速判断表中的记录是否
被上锁，以避免用遍历的方式来查看表中有没有上锁的记录，也就是说其实IS锁和IX锁是兼容的，IX锁和IX锁是兼容的
InnoDB存储引擎中的锁
表级锁：在InnoDB 存储引擎提供的表级 S锁 或者 X锁 是相当鸡肋，只会在一些特殊情况下，比方说崩溃恢复过程中用到。不过我们还是可以手动获取一下的，比方说在系统变量autocommit=0，innodb_table_locks =1 时，手动获取 InnoDB 存储引擎提供的表 t 的 S锁 或者 X锁 可以这么写：LOCK TABLES t READ ： InnoDB 存储引擎会对表 t 加表级别的 S锁 。LOCK TABLES t WRITE ： InnoDB 存储引擎会对表 t 加表级别的 X锁 。
行级锁：行锁 ，也称为 记录锁 ，顾名思义就是在记录上加的锁。不过设计 InnoDB 的大叔很有才，一个 行锁 玩出了各种花样，也就是把 行锁 分成了各种类型。换句话说即使对同一条记录加 行锁 ，如果类型不同，起到的功效也是不同的
Record Locks：行记录锁，分为S锁和X锁
Gap Locks：间隙锁，MySQL 在 REPEATABLE READ 隔离级别下是可以解决幻读问题的，解决方案有两种，可以使用 MVCC 方案解决，也可以采用 加锁 方案解决。但是在使用 加锁 方案解决时有个大问题，就是事务在第一次执行读取操作时，那些幻影记录尚不存在，我们无法给这些幻影记录加上Record Locks，于是就有了间隙锁，顾名思义间隙锁是记录的间隙加锁，使其无法在某个范围内插入数据，从而解决幻读。
原文：A gap lock is a lock on a gap between index records, or a lock on the gap before the first or after the last index record.
译文：间隙锁是索引记录之间间隙上的锁，或者是第一个索引记录之前或最后一个索引记录之后间隙上的锁
Next-Key Locks：其实就是Record Locks+Gap Locks，即给当前行加锁，又给当前行的前后间隙加锁。
比如在查询select * from test_gaplock where id>1 and id&lt;7 for update中一共有id=3和id=5两条记录，其中id为主键或者唯一列的情况下，会锁定范围id(1,3)，（3，5），（5，7）之间不允许插入数据，并且id=3和id=5两条记录也会被锁定。如果id不为主键或者唯一列，则有可能锁定整张表，在本次事务结束前别的事物无法插入数据。
另外在id列为主键或者唯一列的情况下，select * from test_gaplock where id=1 for update 不会产生间隙锁，因为已经明确查询的范围只会有唯一一条数据，不需要间隙锁。
Insert Intention Locks：插入意向锁，事务在对语句加锁之前要先判断语句上有没有锁，于是就产生了插入意向锁。在1锁结构中有tyep字段来表明当前事务的锁是什么锁，插入意向锁就是其中一种所结构，它表示当前记录范围被其他事务锁定，当前事务对被锁定的记录范围有插入意向，正在等待插入（被阻塞）。插入意向锁并不会阻止别的事务继续获取该记录上任何类型的锁
隐式锁：一个事务对新插入的记录可以不显式的加锁（生成一个锁结构），当别的事务在对这条新加的记录加 S锁 或者 X锁时，程序会先判断新纪录上的trx_id是否与要加锁的事务一致，如果不一致，则会给插入记录的事务生成一个锁结构，然后再给此事务生成一个锁结构后进入等待状态，这种方式成为隐式加锁。</content></entry><entry><title>VMware虚拟机CentOS 7.5设置静态ip</title><url>/post/vmware%E8%99%9A%E6%8B%9F%E6%9C%BAcentos-7.5%E8%AE%BE%E7%BD%AE%E9%9D%99%E6%80%81ip/</url><categories><category>Linux</category><category>Linux Basis</category></categories><tags><tag>Linux</tag><tag>ip</tag></tags><content type="html"> CentOS 7.5设置静态ip,配置网关，DNS等
打开vmware虚拟机界面的编辑->虚拟网络编辑器如下图： 打开网配置文件
#vim /etc/sysconfig/network-scripts/ifcfg-ens33
DEFROUTE="yes" IPV4_FAILURE_FATAL="no" IPV6INIT="yes" IPV6_AUTOCONF="yes" IPV6_DEFROUTE="yes" IPV6_FAILURE_FATAL="no" IPV6_ADDR_GEN_MODE="stable-privacy" NAME="ens33" UUID="48aeeb81-96b5-4d08-880a-53e3f527469c" DEVICE="ens33" ONBOOT="yes" BOOTPROTO=static #静态ip获取方式 IPADDR="192.168.52.104" #静态ip地址 NETMASK="255.255.255.0" #子网掩码 GATEWAY="192.168.52.2" #网关 DNS1="114.114.114.114" #国内移动联通电信网络DNS</content></entry><entry><title>Linux常用设置、命令杂记</title><url>/post/linux%E5%B8%B8%E7%94%A8%E8%AE%BE%E7%BD%AE%E5%91%BD%E4%BB%A4%E6%9D%82%E8%AE%B0/</url><categories><category>Linux</category><category>Linux Command</category></categories><tags><tag>Linux</tag><tag>Command</tag></tags><content type="html"> 记录Linux常用的便捷设置和常用命令
快速卸载已安装的rpm软件 rpm -qa | grep -i java | xargs -n1 rpm -e &ndash;nodeps
Ø rpm -qa：查询所安装的所有rpm软件包
Ø grep -i：忽略大小写
Ø xargs -n1：表示每次只传递一个参数
Ø rpm -e –nodeps：强制卸载软件，忽略依赖
安装java *1**）**卸载现有**JDK*
注意：安装JDK前，一定确保提前删除了虚拟机自带的JDK。详细步骤见问文档3.1节中卸载JDK步骤。
*2**）**用**XShell传输**工具将JDK导入到opt目录下面的software文件夹下面*
*3**）**在Linux系统下的opt目录中查看软件包是否导入成功*
[atguigu@hadoop102 ~]$ ls /opt/software/
看到如下结果：
jdk-8u212-linux-x64.tar.gz
*4**）**解压JDK到/opt/module目录下*
[atguigu@hadoop102 software]$ tar -zxvf jdk-8u212-linux-x64.tar.gz -C /opt/module/
*5**）**配置JDK环境变量*
​ （1）新建/etc/profile.d/my_env.sh文件
[atguigu@hadoop102 ~]$ sudo vim /etc/profile.d/my_env.sh
添加如下内容
#JAVA_HOME
export JAVA_HOME=/opt/module/jdk1.8.0_212
export PATH=$PATH:$JAVA_HOME/bin
​ （2）保存后退出
:wq
​ （3）source一下/etc/profile文件，让新的环境变量PATH生效
[atguigu@hadoop102 ~]$ source /etc/profile
*6**）**测试JDK**是否**安装成功*
[atguigu@hadoop102 ~]$ java -version
如果能看到以下结果，则代表Java安装成功。
java version &ldquo;1.8.0_212&rdquo;
编写集群分发脚本xsync *1）scp（**secure copy**）**安全**拷贝*
（1）scp定义
scp可以实现服务器与服务器之间的数据拷贝。（from server1 to server2）
（2）基本语法
scp -r $pdir/$fname $user@$host:$pdir/$fname
命令 递归 要拷贝的文件路径/名称 目的地用户@主机:目的地路径/名称
（3）案例实操
Ø 前提：在hadoop102、hadoop103、hadoop104都已经创建好的/opt/module、 /opt/software两个目录，并且已经把这两个目录修改为atguigu:atguigu
[atguigu@hadoop102 ~]$ sudo chown atguigu:atguigu -R /opt/module
（a）在hadoop102上，将hadoop102中/opt/module/jdk1.8.0_212目录拷贝到hadoop103上。
[atguigu@hadoop102 ~]$ scp -r /opt/module/jdk1.8.0_212 atguigu@hadoop103:/opt/module
（b）在hadoop103上，将hadoop102中/opt/module/hadoop-3.1.3目录拷贝到hadoop103上。
[atguigu@hadoop103 ~]$ scp -r atguigu@hadoop102:/opt/module/hadoop-3.1.3 /opt/module/
（c）在hadoop103上操作，将hadoop102中/opt/module目录下所有目录拷贝到hadoop104上。
[atguigu@hadoop103 opt]$ scp -r atguigu@hadoop102:/opt/module/* atguigu@hadoop104:/opt/module
*2）rsync远程**同步**工具*
rsync主要用于备份和镜像。具有速度快、避免复制相同内容和支持符号链接的优点。
rsync和scp区别：用rsync做文件的复制要比scp的速度快，rsync只对差异文件做更新。scp是把所有文件都复制过去。
​ （1）基本语法
rsync -av $pdir/$fname $user@$host:$pdir/$fname
命令 选项参数 要拷贝的文件路径/名称 目的地用户@主机:目的地路径/名称
​ 选项参数说明
选项 功能 -a 归档拷贝 -v 显示复制过程 （2）案例实操
​ （a）删除hadoop103中/opt/module/hadoop-3.1.3/wcinput
[atguigu@hadoop103 hadoop-3.1.3]$ rm -rf wcinput/
​ （b）同步hadoop102中的/opt/module/hadoop-3.1.3到hadoop103
[atguigu@hadoop102 module]$ rsync -av hadoop-3.1.3/ atguigu@hadoop103:/opt/module/hadoop-3.1.3/
*3）**xsync集群分发**脚本*
（1）需求：循环复制文件到所有节点的相同目录下
​ （2）需求分析：
（a）rsync命令原始拷贝：
rsync -av /opt/module atguigu@hadoop103:/opt/
（b）期望脚本：
xsync要同步的文件名称
（c）期望脚本在任何路径都能使用（脚本放在声明了全局环境变量的路径）
[atguigu@hadoop102 ~]$ echo $PATH
/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/home/atguigu/.local/bin:/home/atguigu/bin:/opt/module/jdk1.8.0_212/bin
（3）脚本实现
（a）在/home/atguigu/bin目录下创建xsync文件
[atguigu@hadoop102 opt]$ cd /home/atguigu
[atguigu@hadoop102 ~]$ mkdir bin
[atguigu@hadoop102 ~]$ cd bin
[atguigu@hadoop102 bin]$ vim xsync
在该文件中编写如下代码
# #!/bin/bash #1. 判断参数个数 if [ $# -lt 1 ] then echo Not Enough Arguement! exit; fi #2. 遍历集群所有机器 for host in centos1 centos2 centos4 do echo ==================== $host ==================== #3. 遍历所有目录，挨个发送 for file in $@ do #4. 判断文件是否存在 if [ -e $file ] then #5. 获取父目录 pdir=$(cd -P $(dirname $file); pwd) #6. 获取当前文件的名称 fname=$(basename $file) ssh $host "mkdir -p $pdir" rsync -av $pdir/$fname $host:$pdir else echo $file does not exists! fi done done （b）修改脚本 xsync 具有执行权限
[atguigu@hadoop102 bin]$ chmod +x xsync
（c）测试脚本
[atguigu@hadoop102 ~]$ xsync /home/atguigu/bin
（d）将脚本复制到/bin中，以便全局调用
[atguigu@hadoop102 bin]$ sudo cp xsync /bin/
（e）同步环境变量配置（root所有者）
[atguigu@hadoop102 ~]$ sudo ./bin/xsync /etc/profile.d/my_env.sh
注意：如果用了sudo，那么xsync一定要给它的路径补全。
让环境变量生效
[atguigu@hadoop103 bin]$ source /etc/profile
[atguigu@hadoop104 opt]$ source /etc/profile
SSH无密登录配置 *1**）**配置ssh*
（1）基本语法
ssh另一台电脑的IP地址
（2）ssh连接时出现Host key verification failed的解决方法
[atguigu@hadoop102 ~]$ ssh hadoop103
Ø 如果出现如下内容
Are you sure you want to continue connecting (yes/no)?
Ø 输入yes，并回车
（3）退回到hadoop102
[atguigu@hadoop103 ~]$ exit
*2**）**无密钥配置*
（1）免密登录原理
（2）生成公钥和私钥
[atguigu@hadoop102 .ssh]$ pwd
/home/atguigu/.ssh
[atguigu@hadoop102 .ssh]$ ssh-keygen -t rsa
然后敲（三个回车），就会生成两个文件id_rsa（私钥）、id_rsa.pub（公钥）
（3）将公钥拷贝到要免密登录的目标机器上
[atguigu@hadoop102 .ssh]$ ssh-copy-id hadoop102
[atguigu@hadoop102 .ssh]$ ssh-copy-id hadoop103
[atguigu@hadoop102 .ssh]$ ssh-copy-id hadoop104
注意：
还需要在hadoop103上采用atguigu账号配置一下无密登录到hadoop102、hadoop103、hadoop104服务器上。
还需要在hadoop104上采用atguigu账号配置一下无密登录到hadoop102、hadoop103、hadoop104服务器上。
还需要在hadoop102上采用root账号，配置一下无密登录到hadoop102、hadoop103、hadoop104；
*3**）**.ssh文件夹下**（~/.ssh）**的文件功能解释*
known_hosts 记录ssh访问过计算机的公钥（public key） id_rsa 生成的私钥 id_rsa.pub 生成的公钥 authorized_keys 存放授权过的无密登录服务器公钥</content></entry><entry><title>Linux文件详细属性学习</title><url>/post/linux%E6%96%87%E4%BB%B6%E8%AF%A6%E7%BB%86%E5%B1%9E%E6%80%A7%E5%AD%A6%E4%B9%A0/</url><categories><category>Linux</category><category>Linux Basis</category></categories><tags><tag>Linux</tag><tag>文件属性</tag><tag>ls命令</tag></tags><content type="html"> 详细介绍如何查看并分辨Linux文件的详细属性，包括文件的类型，权限信息，所有者，用户等
Linux的基本思想有两点：第一，一切都是文件；第二，每个文件都有确定的用途。其中第一条详细来讲就是系统中的所有都归结为一个文件，包括命令、硬件和软件设备、操作系统、进程等等对于操作系统内核而言，都被视为拥有各自特性或类型的文件
ls -l 命令是以长格式的形式查看当前目录下所有可见文件的详细属性
文件的详细属性如下：
如果是一个符号链接，那么会有一个 “->" 箭头符号，后面根一个它指向的文件名;
灰白色表示普通文件；
亮绿色表示可执行文件；
亮红色表示压缩文件；
灰蓝色表示目录；
亮蓝色表示链接文件；
亮黄色表示设备文件；</content></entry><entry><title>Vim的四种模式及操作命令大全</title><url>/post/vim%E5%9B%9B%E7%A7%8D%E6%A8%A1%E5%BC%8F%E5%8F%8A%E6%93%8D%E4%BD%9C%E5%91%BD%E4%BB%A4%E5%A4%A7%E5%85%A8/</url><categories><category>Linux</category><category>Linux Command</category></categories><tags><tag>Linux</tag><tag>Vim</tag><tag>Command</tag></tags><content type="html"> 介绍Vim的四种模式及命令操作大全
一、四种模式 1、正常模式（normal） 正常模式是使用vim打开文件时的默认模式。 无论在哪种模式下，按下Esc键就会进入正常模式。 在这个模式下： 可以移动光标 选中行，复制（ctrl+C） 可以增、删 x删除光标后的一个字符，nx（n是数字）删除光标后的n个字符，X删除光标前的一个字符， dd剪切光标所在的那一行，ndd剪切光标所在行后的n行 p光标所在行开始，向后粘贴已经复制的内容，P光标所在行开始，向前粘贴已经复制的内容 yy复制光标所在的行，nyy复制光标所在行后的n行 u还原上一次的操作 2、命令模式（command） 在正常模式下输入:或/进入命令行模式 在该模式下可以进行保存，搜索，替换，退出，显示行号等。 /word 光标之后查找字符串word，按n向后搜索，按N向前搜索 ?word光标之前查找字符串word，按n向前搜索，按N向前搜索 :n1,n2/word1/word2/g 将n1到n2行之间的word1替换为word2，不加g则只替换每行的第一个word1，加g则搜到的word1全部替换为word2； :1,$s/word1/word2/g将文章中的word1替换为word2，不加g则只替换每行的第一个word1 :w保存文本 ，:w!强制保存 :q退出vim ；:q!强制退出 :wq 保存并退出 :set nu 显示行号，:set nonu不显示行号 3、插入模式（insert） 在正常模式下按下i键，进入插入模式。在插入模式下按Esc键切换到普通模式。 插入模式里可以进行文字的输入 i 在光标所在字符前开始输入文字并进入插入模式。 I 在行首开始输入文字并进入插入模式。此行首指第一个非空白字符处。如果行首有空格，则在空格之后输入文字并进入插入模式 a 在光标所在字符后开始输入文字并进入插入模式 A 在行尾开始输入文字并进入插入模式。这个好用，您不必管光标在此行的什麽地方，只要按 A 就会在行尾等着您输入文字。 o 在光标所在行的下面单独开一新行，来输入文字并进入插入模式 O 在光标所在行的上面单独开一新行来输入文字并进入插入模式 s 删除光标所在的字符并进入插入模式 S 删除光标所在行并进入插入模式 4、可视模式（visual） 在正常模式下按v（小写）进入字符文本，按V（大写）进入行文本，然后使用上下左右键操作选中区域，对选中的部分使用 d进行删除 y进行复制 p进行粘贴 r进行文本替换 gu转换为小写，gU转换为大写，g~大小写互换 二、操作命令大全 [常用] 剪切和复制、粘贴
[n]x: 剪切光标右边n个字符，相当于d[n]l。 [n]X: 剪切光标左边n个字符，相当于d[n]h。 y: 复制在可视模式下选中的文本。 yy or Y: 复制整行文本。 y[n]w: 复制一(n)个词。 y[n]l: 复制光标右边1(n)个字符。 y[n]h: 复制光标左边1(n)个字符。 y$: 从光标当前位置复制到行尾。 y0: 从光标当前位置复制到行首。 :m,ny 复制m行到n行的内容。 y1G或ygg: 复制光标以上的所有行。 yG: 复制光标以下的所有行。 yaw和yas：复制一个词和复制一个句子，即使光标不在词首和句首也没关系。 d: 删除（剪切）在可视模式下选中的文本。 d$ or D: 删除（剪切）当前位置到行尾的内容。 d[n]w: 删除（剪切）1(n)个单词 d[n]l: 删除（剪切）光标右边1(n)个字符。 d[n]h: 删除（剪切）光标左边1(n)个字符。 d0: 删除（剪切）当前位置到行首的内容 [n] dd: 删除（剪切）1(n)行。 :m,nd 剪切m行到n行的内容。 d1G或dgg: 剪切光标以上的所有行。 dG: 剪切光标以下的所有行。 daw和das：剪切一个词和剪切一个句子，即使光标不在词首和句首也没关系。 d/f：这是一个比较高级的组合命令，它将删除当前位置 到下一个f之间的内容。 p: 在光标之后粘贴。 P: 在光标之前粘贴。 [常用]基本插入
i: 在光标前插入；一个小技巧：按8，再按i，进入插入模式，输入=， 按esc进入命令模式，就会出现8个=。 这在插入分割线时非常有用，如30i+就插入了36个+组成的分割线。 I: 在当前行第一个非空字符前插入； gI: 在当前行第一列插入； a: 在光标后插入； A: 在当前行最后插入； o: 在下面新建一行插入； O: 在上面新建一行插入； :r filename在当前位置插入另一个文件的内容。 :[n]r filename在第n行插入另一个文件的内容。 :r !date 在光标处插入当前日期与时间。同理，:r !command可以将其它shell命令的输出插入当前文档。 [常用] 基本移动
以下移动都是在normal模式下。
h或退格: 左移一个字符； l或空格: 右移一个字符； j: 下移一行； k: 上移一行； gj: 移动到一段内的下一行； gk: 移动到一段内的上一行； +或Enter: 把光标移至下一行第一个非空白字符。 -: 把光标移至上一行第一个非空白字符。 w: 前移一个单词，光标停在下一个单词开头； W: 移动下一个单词开头，但忽略一些标点； e: 前移一个单词，光标停在下一个单词末尾； E: 移动到下一个单词末尾，如果词尾有标点，则移动到标点； b: 后移一个单词，光标停在上一个单词开头； B: 移动到上一个单词开头，忽略一些标点； ge: 后移一个单词，光标停在上一个单词末尾； gE: 同 ge ，不过‘单词’包含单词相邻的标点。 (: 前移1句。 ): 后移1句。 {: 前移1段。 }: 后移1段。 fc: 把光标移到同一行的下一个c字符处 Fc: 把光标移到同一行的上一个c字符处 tc: 把光标移到同一行的下一个c字符前 Tc: 把光标移到同一行的上一个c字符后 ;: 配合f &amp; t使用，重复一次 ,: 配合f &amp; t使用，反向重复一次 上面的操作都可以配合n使用，比如在正常模式(下面会讲到)下输入3h， 则光标向左移动3个字符。
0: 移动到行首。 g0: 移到光标所在屏幕行行首。 ^: 移动到本行第一个非空白字符。 g^: 同 ^ ，但是移动到当前屏幕行第一个非空字符处。 $: 移动到行尾。 g$: 移动光标所在屏幕行行尾。 n|: 把光标移到递n列上。 nG: 到文件第n行。 :n 移动到第n行。 :$ 移动到最后一行。 H: 把光标移到屏幕最顶端一行。 M: 把光标移到屏幕中间一行。 L: 把光标移到屏幕最底端一行。 gg: 到文件头部。 G: 到文件尾部。 2. 启动Vim
vim -c cmd file: 在打开文件前，先执行指定的命令； vim -r file: 恢复上次异常退出的文件； vim -R file: 以只读的方式打开文件，但可以强制保存； vim -M file: 以只读的方式打开文件，不可以强制保存； vim -y num file: 将编辑窗口的大小设为num行； vim + file: 从文件的末尾开始； vim +num file: 从第num行开始； vim +/string file: 打开file，并将光标停留在第一个找到的string上。 vim &ndash;remote file: 用已有的vim进程打开指定的文件。 如果你不想启用多个vim会话，这个很有用。但要注意， 如果你用vim，会寻找名叫VIM的服务器；如果你已经有一个gvim在运行了， 你可以用gvim &ndash;remote file在已有的gvim中打开文件。 3. 文档操作
:e file &ndash;关闭当前编辑的文件，并开启新的文件。 如果对当前文件的修改未保存，vi会警告。 :e! file &ndash;放弃对当前文件的修改，编辑新的文件。 :e+file &ndash; 开始新的文件，并从文件尾开始编辑。 :e+n file &ndash; 开始新的文件，并从第n行开始编辑。 :enew &ndash;编译一个未命名的新文档。(CTRL-W n) :e &ndash; 重新加载当前文档。 :e! &ndash; 重新加载当前文档，并丢弃已做的改动。 :e#或ctrl+^ &ndash; 回到刚才编辑的文件，很实用。 :f或ctrl+g &ndash; 显示文档名，是否修改，和光标位置。 :f filename &ndash; 改变编辑的文件名，这时再保存相当于另存为。 gf &ndash; 打开以光标所在字符串为文件名的文件。 :w &ndash; 保存修改。 :n1,n2w filename &ndash; 选择性保存从某n1行到另n2行的内容。 :wq &ndash; 保存并退出。 ZZ &ndash; 保存并退出。 :x &ndash; 保存并退出。 :q[uit] ——退出当前窗口。(CTRL-W q或CTRL-W CTRL-Q) :saveas newfilename &ndash; 另存为 :browse e &ndash; 会打开一个文件浏览器让你选择要编辑的文件。 如果是终端中，则会打开netrw的文件浏览窗口； 如果是gvim，则会打开一个图形界面的浏览窗口。 实际上:browse后可以跟任何编辑文档的命令，如sp等。 用browse打开的起始目录可以由browsedir来设置： :set browsedir=last &ndash; 用上次访问过的目录（默认）； :set browsedir=buffer &ndash; 用当前文件所在目录； :set browsedir=current &ndash; 用当前工作目录； :Sex &ndash; 水平分割一个窗口，浏览文件系统； :Vex &ndash; 垂直分割一个窗口，浏览文件系统； 4. 光标的移动
4.1 基本移动
以下移动都是在normal模式下。
h或退格: 左移一个字符； l或空格: 右移一个字符； j: 下移一行； k: 上移一行； gj: 移动到一段内的下一行； gk: 移动到一段内的上一行； +或Enter: 把光标移至下一行第一个非空白字符。 -: 把光标移至上一行第一个非空白字符。 w: 前移一个单词，光标停在下一个单词开头； W: 移动下一个单词开头，但忽略一些标点； e: 前移一个单词，光标停在下一个单词末尾； E: 移动到下一个单词末尾，如果词尾有标点，则移动到标点； b: 后移一个单词，光标停在上一个单词开头； B: 移动到上一个单词开头，忽略一些标点； ge: 后移一个单词，光标停在上一个单词末尾； gE: 同 ge ，不过‘单词’包含单词相邻的标点。 (: 前移1句。 ): 后移1句。 {: 前移1段。 }: 后移1段。 fc: 把光标移到同一行的下一个c字符处 Fc: 把光标移到同一行的上一个c字符处 tc: 把光标移到同一行的下一个c字符前 Tc: 把光标移到同一行的上一个c字符后 ;: 配合f &amp; t使用，重复一次 ,: 配合f &amp; t使用，反向重复一次 上面的操作都可以配合n使用，比如在正常模式(下面会讲到)下输入3h， 则光标向左移动3个字符。
0: 移动到行首。 g0: 移到光标所在屏幕行行首。 ^: 移动到本行第一个非空白字符。 g^: 同 ^ ，但是移动到当前屏幕行第一个非空字符处。 $: 移动到行尾。 g$: 移动光标所在屏幕行行尾。 n|: 把光标移到递n列上。 nG: 到文件第n行。 :n 移动到第n行。 :$ 移动到最后一行。 H: 把光标移到屏幕最顶端一行。 M: 把光标移到屏幕中间一行。 L: 把光标移到屏幕最底端一行。 gg: 到文件头部。 G: 到文件尾部。 4.2 翻屏
ctrl+f: 下翻一屏。 ctrl+b: 上翻一屏。 ctrl+d: 下翻半屏。 ctrl+u: 上翻半屏。 ctrl+e: 向下滚动一行。 ctrl+y: 向上滚动一行。 n%: 到文件n%的位置。 zz: 将当前行移动到屏幕中央。 zt: 将当前行移动到屏幕顶端。 zb: 将当前行移动到屏幕底端。 4.3 标记
使用标记可以快速移动。到达标记后，可以用Ctrl+o返回原来的位置。 Ctrl+o和Ctrl+i 很像浏览器上的 后退 和 前进 。
m{a-z}: 标记光标所在位置，局部标记，只用于当前文件。 m{A-Z}: 标记光标所在位置，全局标记。标记之后，退出Vim， 重新启动，标记仍然有效。 `{a-z}: 移动到标记位置。 &lsquo;{a-z}: 移动到标记行的行首。 `{0-9}：回到上[2-10]次关闭vim时最后离开的位置。 : 移动到上次编辑的位置。''也可以，不过精确到列，而&rsquo;&lsquo;精确到行 。如果想跳转到更老的位置，可以按C-o，跳转到更新的位置用C-i。 `": 移动到上次离开的地方。 `.: 移动到最后改动的地方。 :marks 显示所有标记。 :delmarks a b &ndash; 删除标记a和b。 :delmarks a-c &ndash; 删除标记a、b和c。 :delmarks a c-f &ndash; 删除标记a、c、d、e、f。 :delmarks! &ndash; 删除当前缓冲区的所有标记。 :help mark-motions 查看更多关于mark的知识。 5. 插入文本
[ 5.2 改写插入
c[n]w: 改写光标后1(n)个词。 c[n]l: 改写光标后n个字母。 c[n]h: 改写光标前n个字母。 [n]cc: 修改当前[n]行。 [n]s: 以输入的文本替代光标之后1(n)个字符，相当于c[n]l。 [n]S: 删除指定数目的行，并以所输入文本代替之。 注意，类似cnw,dnw,ynw的形式同样可以写为ncw,ndw,nyw。
6. 剪切复制和寄存器
6.2 文本对象
aw：一个词 as：一句。 ap：一段。 ab：一块（包含在圆括号中的）。 y, d, c, v都可以跟文本对象。
6.3 寄存器
a-z：都可以用作寄存器名。&ldquo;ayy把当前行的内容放入a寄存器。 A-Z：用大写字母索引寄存器，可以在寄存器中追加内容。 如"Ayy把当前行的内容追加到a寄存器中。 :reg 显示所有寄存器的内容。 &ldquo;"：不加寄存器索引时，默认使用的寄存器。 &ldquo;*：当前选择缓冲区，"*yy把当前行的内容放入当前选择缓冲区。 &ldquo;+：系统剪贴板。"+yy把当前行的内容放入系统剪贴板。 7. 查找与替换
7.1 查找
/something: 在后面的文本中查找something。 ?something: 在前面的文本中查找something。 /pattern/+number: 将光标停在包含pattern的行后面第number行上。 /pattern/-number: 将光标停在包含pattern的行前面第number行上。 n: 向后查找下一个。 N: 向前查找下一个。 可以用grep或vimgrep查找一个模式都在哪些地方出现过，
其中:grep是调用外部的grep程序，而:vimgrep是vim自己的查找算法。
用法为： :vim[grep]/pattern/[g] [j] files
g的含义是如果一个模式在一行中多次出现，则这一行也在结果中多次出现。
j的含义是grep结束后，结果停在第j项，默认是停在第一项。
vimgrep前面可以加数字限定搜索结果的上限，如
:1vim/pattern/ % 只查找那个模式在本文件中的第一个出现。
其实vimgrep在读纯文本电子书时特别有用，可以生成导航的目录。
比如电子书中每一节的标题形式为：n. xxxx。你就可以这样：
:vim/^d{1,}./ %
然后用:cw或:copen查看结果，可以用C-w H把quickfix窗口移到左侧，
就更像个目录了。
7.2 替换
:s/old/new - 用new替换当前行第一个old。 :s/old/new/g - 用new替换当前行所有的old。 :n1,n2s/old/new/g - 用new替换文件n1行到n2行所有的old。 :%s/old/new/g - 用new替换文件中所有的old。 :%s/^/xxx/g - 在每一行的行首插入xxx，^表示行首。 :%s/$/xxx/g - 在每一行的行尾插入xxx，$表示行尾。 所有替换命令末尾加上c，每个替换都将需要用户确认。 如：%s/old/new/gc，加上i则忽略大小写(ignore)。 还有一种比替换更灵活的方式，它是匹配到某个模式后执行某种命令，
语法为 :[range]g/pattern/command
例如 :%g/^ xyz/normal dd。
表示对于以一个空格和xyz开头的行执行normal模式下的dd命令。
关于range的规定为：
如果不指定range，则表示当前行。 m,n: 从m行到n行。 0: 最开始一行（可能是这样）。 $: 最后一行 .: 当前行 %: 所有行 7.3 正则表达式
高级的查找替换就要用到正则表达式。
d: 表示十进制数（我猜的） s: 表示空格 S: 非空字符 a: 英文字母 |: 表示 或 .: 表示. {m,n}: 表示m到n个字符。这要和 s与a等连用，如 a{m,n} 表示m 到n个英文字母。 {m,}: 表示m到无限多个字符。 **: 当前目录下的所有子目录。 :help pattern得到更多帮助。
8. 排版
8.1 基本排版
&laquo; 向左缩进一个shiftwidth >> 向右缩进一个shiftwidth :ce(nter) 本行文字居中 :le(ft) 本行文字靠左 :ri(ght) 本行文字靠右 gq 对选中的文字重排，即对过长的文字进行断行 gqq 重排当前行 gqnq 重排n行 gqap 重排当前段 gqnap 重排n段 gqnj 重排当前行和下面n行 gqQ 重排当前段对文章末尾 J 拼接当前行和下一行 gJ 同 J ，不过合并后不留空格。 8.2 拼写检查
:set spell－开启拼写检查功能 :set nospell－关闭拼写检查功能 ]s－移到下一个拼写错误的单词 [s－作用与上一命令类似，但它是从相反方向进行搜索 z=－显示一个有关拼写错误单词的列表，可从中选择 zg－告诉拼写检查器该单词是拼写正确的 zw－与上一命令相反，告诉拼写检查器该单词是拼写错误的 8.3 统计字数
g ^g可以统计文档字符数，行数。 将光标放在最后一个字符上，用字符数减去行数可以粗略统计中文文档的字数。 以上对 Mac 或 Unix 的文件格式适用。 如果是 Windows 文件格式（即换行符有两个字节），字数的统计方法为： 字符数 - 行数 * 2。
9. 编辑多个文件
9.1 一次编辑多个文件
我们可以一次打开多个文件，如
&lt;span style="font-size:14px;">vi a.txt b.txt c.txt &lt;/span> 使用:next(:n)编辑下一个文件。 :2n 编辑下2个文件。 使用:previous或:N编辑上一个文件。 使用:wnext，保存当前文件，并编辑下一个文件。 使用:wprevious，保存当前文件，并编辑上一个文件。 使用:args 显示文件列表。 :n filenames或:args filenames 指定新的文件列表。 vi -o filenames 在水平分割的多个窗口中编辑多个文件。 vi -O filenames 在垂直分割的多个窗口中编辑多个文件。 9.2 多标签编辑
vim -p files: 打开多个文件，每个文件占用一个标签页。 :tabe, tabnew &ndash; 如果加文件名，就在新的标签中打开这个文件， 否则打开一个空缓冲区。 ^w gf &ndash; 在新的标签页里打开光标下路径指定的文件。 :tabn &ndash; 切换到下一个标签。Control + PageDown，也可以。 :tabp &ndash; 切换到上一个标签。Control + PageUp，也可以。 [n] gt &ndash; 切换到下一个标签。如果前面加了 n ， 就切换到第n个标签。第一个标签的序号就是1。 :tab split &ndash; 将当前缓冲区的内容在新页签中打开。 :tabc[lose] &ndash; 关闭当前的标签页。 :tabo[nly] &ndash; 关闭其它的标签页。 :tabs &ndash; 列出所有的标签页和它们包含的窗口。 :tabm[ove] [N] &ndash; 移动标签页，移动到第N个标签页之后。 如 tabm 0 当前标签页，就会变成第一个标签页。 9.3 缓冲区
:buffers或:ls或:files 显示缓冲区列表。 ctrl+^：在最近两个缓冲区间切换。 :bn &ndash; 下一个缓冲区。 :bp &ndash; 上一个缓冲区。 :bl &ndash; 最后一个缓冲区。 :b[n]或:[n]b &ndash; 切换到第n个缓冲区。 :nbw(ipeout) &ndash; 彻底删除第n个缓冲区。 :nbd(elete) &ndash; 删除第n个缓冲区，并未真正删除，还在unlisted列表中。 :ba[ll] &ndash; 把所有的缓冲区在当前页中打开，每个缓冲区占一个窗口。 10. 分屏编辑
vim -o file1 file2:水平分割窗口，同时打开file1和file2 vim -O file1 file2:垂直分割窗口，同时打开file1和file2 10.1 水平分割
:split(:sp) &ndash; 把当前窗水平分割成两个窗口。(CTRL-W s 或 CTRL-W CTRL-S) 注意如果在终端下，CTRL-S可能会冻结终端，请按CTRL-Q继续。 :split filename &ndash; 水平分割窗口，并在新窗口中显示另一个文件。 :nsplit(:nsp) &ndash; 水平分割出一个n行高的窗口。 :[N]new &ndash; 水平分割出一个N行高的窗口，并编辑一个新文件。 (CTRL-W n或 CTRL-W CTRL-N) ctrl+w f &ndash;水平分割出一个窗口，并在新窗口打开名称为光标所在词的文件 。 C-w C-^ &ndash; 水平分割一个窗口，打开刚才编辑的文件。 10.2 垂直分割
:vsplit(:vsp) &ndash; 把当前窗口分割成水平分布的两个窗口。 (CTRL-W v或CTRL CTRL-V) :[N]vne[w] &ndash; 垂直分割出一个新窗口。 :vertical 水平分割的命令： 相应的垂直分割。 10.3 关闭子窗口
:qall &ndash; 关闭所有窗口，退出vim。 :wall &ndash; 保存所有修改过的窗口。 :only &ndash; 只保留当前窗口，关闭其它窗口。(CTRL-W o) :close &ndash; 关闭当前窗口，CTRL-W c能实现同样的功能。 (象 :q :x同样工作 ) 10.4 调整窗口大小
ctrl+w + &ndash;当前窗口增高一行。也可以用n增高n行。 ctrl+w - &ndash;当前窗口减小一行。也可以用n减小n行。 ctrl+w _ &ndash;当前窗口扩展到尽可能的大。也可以用n设定行数。 :resize n &ndash; 当前窗口n行高。 ctrl+w = &ndash; 所有窗口同样高度。 n ctrl+w _ &ndash; 当前窗口的高度设定为n行。 ctrl+w &lt; &ndash;当前窗口减少一列。也可以用n减少n列。 ctrl+w > &ndash;当前窗口增宽一列。也可以用n增宽n列。 ctrl+w | &ndash;当前窗口尽可能的宽。也可以用n设定列数。 10.5 切换和移动窗口
如果支持鼠标，切换和调整子窗口的大小就简单了。
ctrl+w ctrl+w: 切换到下一个窗口。或者是ctrl+w w。 ctrl+w p: 切换到前一个窗口。 ctrl+w h(l,j,k):切换到左（右，下，上）的窗口。 ctrl+w t(b):切换到最上（下）面的窗口。 ctrl+w H(L,K,J): 将当前窗口移动到最左（右、上、下）面。 ctrl+w r：旋转窗口的位置。 ctrl+w T: 将当前的窗口移动到新的标签页上。 11. 快速编辑
11.1 改变大小写
~: 反转光标所在字符的大小写。 可视模式下的U或u：把选中的文本变为大写或小写。 gu(U)接范围（如$，或G），可以把从光标当前位置到指定位置之间字母全部 转换成小写或大写。如ggguG，就是把开头到最后一行之间的字母全部变为小 写。再如gu5j，把当前行和下面四行全部变成小写。 11.2 替换（normal模式）
r: 替换光标处的字符，同样支持汉字。 R: 进入替换模式，按esc回到正常模式。 11.3 撤消与重做（normal模式）
[n] u: 取消一(n)个改动。 :undo 5 &ndash; 撤销5个改变。 :undolist &ndash; 你的撤销历史。 ctrl + r: 重做最后的改动。 U: 取消当前行中所有的改动。 :earlier 4m &ndash; 回到4分钟前 :later 55s &ndash; 前进55秒 11.4 宏
. &ndash;重复上一个编辑动作 qa：开始录制宏a（键盘操作记录） q：停止录制 @a：播放宏a 12. 编辑特殊文件
12.1 文件加解密
vim -x file: 开始编辑一个加密的文件。 :X &ndash; 为当前文件设置密码。 :set key= &ndash; 去除文件的密码。 这里是
滇狐总结的比较高级的vi技巧。
12.2 文件的编码
:e ++enc=utf8 filename, 让vim用utf-8的编码打开这个文件。 :w ++enc=gbk，不管当前文件什么编码，把它转存成gbk编码。 :set fenc或:set fileencoding，查看当前文件的编码。 在vimrc中添加set fileencoding=ucs-bom,utf-8,cp936，vim会根据要打开的文件选择合适的编码。 注意：编码之间不要留空格。 cp936对应于gbk编码。 ucs-bom对应于windows下的文件格式。 让vim 正确处理文件格式和文件编码，有赖于 ~/.vimrc的正确配置
12.3 文件格式
大致有三种文件格式：unix, dos, mac. 三种格式的区别主要在于回车键的编码：dos 下是回车加换行，unix 下只有 换行符，mac 下只有回车符。
:e ++ff=dos filename, 让vim用dos格式打开这个文件。 :w ++ff=mac filename, 以mac格式存储这个文件。 :set ff，显示当前文件的格式。 在vimrc中添加set fileformats=unix,dos,mac，让vim自动识别文件格式。 13. 编程辅助
13.1 一些按键
gd: 跳转到局部变量的定义处； gD: 跳转到全局变量的定义处，从当前文件开头开始搜索； g;: 上一个修改过的地方； g,: 下一个修改过的地方； [[: 跳转到上一个函数块开始，需要有单独一行的{。 ]]: 跳转到下一个函数块开始，需要有单独一行的{。 []: 跳转到上一个函数块结束，需要有单独一行的}。 ][: 跳转到下一个函数块结束，需要有单独一行的}。 [{: 跳转到当前块开始处； ]}: 跳转到当前块结束处； [/: 跳转到当前注释块开始处； ]/: 跳转到当前注释块结束处； %: 不仅能移动到匹配的(),{}或[]上，而且能在#if，#else， #endif之间跳跃。 下面的括号匹配对编程很实用的。
ci&rsquo;, di&rsquo;, yi&rsquo;：修改、剪切或复制&rsquo;之间的内容。 ca&rsquo;, da&rsquo;, ya&rsquo;：修改、剪切或复制&rsquo;之间的内容，包含&rsquo;。 ci&rdquo;, di&rdquo;, yi&rdquo;：修改、剪切或复制"之间的内容。 ca&rdquo;, da", ya"：修改、剪切或复制"之间的内容，包含"。 ci(, di(, yi(：修改、剪切或复制()之间的内容。 ca(, da(, ya(：修改、剪切或复制()之间的内容，包含()。 ci[, di[, yi[：修改、剪切或复制[]之间的内容。 ca[, da[, ya[：修改、剪切或复制[]之间的内容，包含[]。 ci{, di{, yi{：修改、剪切或复制{}之间的内容。 ca{, da{, ya{：修改、剪切或复制{}之间的内容，包含{}。 ci&lt;, di&lt;, yi&lt;：修改、剪切或复制&lt;>之间的内容。 ca&lt;, da&lt;, ya&lt;：修改、剪切或复制&lt;>之间的内容，包含&lt;>。 13.2 ctags
ctags -R: 生成tag文件，-R表示也为子目录中的文件生成tags :set tags=path/tags &ndash; 告诉ctags使用哪个tag文件 :tag xyz &ndash; 跳到xyz的定义处，或者将光标放在xyz上按C-]，返回用C-t :stag xyz &ndash; 用分割的窗口显示xyz的定义，或者C-w ]， 如果用C-w n ]，就会打开一个n行高的窗口 :ptag xyz &ndash; 在预览窗口中打开xyz的定义，热键是C-w }。 :pclose &ndash; 关闭预览窗口。热键是C-w z。 :pedit abc.h &ndash; 在预览窗口中编辑abc.h :psearch abc &ndash; 搜索当前文件和当前文件include的文件，显示包含abc的行。 有时一个tag可能有多个匹配，如函数重载，一个函数名就会有多个匹配。 这种情况会先跳转到第一个匹配处。
:[n]tnext &ndash; 下一[n]个匹配。 :[n]tprev &ndash; 上一[n]个匹配。 :tfirst &ndash; 第一个匹配 :tlast &ndash; 最后一个匹配 :tselect tagname &ndash; 打开选择列表 tab键补齐
:tag xyz &ndash; 补齐以xyz开头的tag名，继续按tab键，会显示其他的。 :tag /xyz &ndash; 会用名字中含有xyz的tag名补全。 13.3 cscope
cscope -Rbq: 生成cscope.out文件 :cs add /path/to/cscope.out /your/work/dir :cs find c func &ndash; 查找func在哪些地方被调用 :cw &ndash; 打开quickfix窗口查看结果 13.4 gtags
Gtags综合了ctags和cscope的功能。 使用Gtags之前，你需要安装GNU Gtags。 然后在工程目录运行 gtags 。
:Gtags funcname 定位到 funcname 的定义处。 :Gtags -r funcname 查询 funcname被引用的地方。 :Gtags -s symbol 定位 symbol 出现的地方。 :Gtags -g string Goto string 出现的地方。 :Gtags -gi string 忽略大小写。 :Gtags -f filename 显示 filename 中的函数列表。 你可以用 :Gtags -f % 显示当前文件。 :Gtags -P pattern 显示路径中包含特定模式的文件。 如 :Gtags -P .h$ 显示所有头文件， :Gtags -P /vm/ 显示vm目录下的文件。 13.5 编译
vim提供了:make来编译程序，默认调用的是make， 如果你当前目录下有makefile，简单地:make即可。
如果你没有make程序，你可以通过配置makeprg选项来更改make调用的程序。 如果你只有一个abc.java文件，你可以这样设置：
&lt;span style="font-size:14px;">set makeprg=javac abc.java &lt;/span> 然后:make即可。如果程序有错，可以通过quickfix窗口查看错误。 不过如果要正确定位错误，需要设置好errorformat，让vim识别错误信息。 如：
&lt;span style="font-size:14px;">:setl efm=%A%f:%l: %m,%-Z%p^,%-C%.%# &lt;/span> %f表示文件名，%l表示行号， %m表示错误信息，其它的还不能理解。 请参考 :help errorformat。
13.6 快速修改窗口
其实是quickfix插件提供的功能， 对编译调试程序非常有用 :)
:copen &ndash; 打开快速修改窗口。 :cclose &ndash; 关闭快速修改窗口。 快速修改窗口在make程序时非常有用，当make之后：
:cl &ndash; 在快速修改窗口中列出错误。 :cn &ndash; 定位到下一个错误。 :cp &ndash; 定位到上一个错误。 :cr &ndash; 定位到第一个错误。 13.7 自动补全
C-x C-s &ndash; 拼写建议。 C-x C-v &ndash; 补全vim选项和命令。 C-x C-l &ndash; 整行补全。 C-x C-f &ndash; 自动补全文件路径。弹出菜单后，按C-f循环选择，当然也可以按 C-n和C-p。 C-x C-p 和C-x C-n &ndash; 用文档中出现过的单词补全当前的词。 直接按C-p和C-n也可以。 C-x C-o &ndash; 编程时可以补全关键字和函数名啊。 C-x C-i &ndash; 根据头文件内关键字补全。 C-x C-d &ndash; 补全宏定义。 C-x C-n &ndash; 按缓冲区中出现过的关键字补全。 直接按C-n或C-p即可。 当弹出补全菜单后：
C-p 向前切换成员； C-n 向后切换成员； C-e 退出下拉菜单，并退回到原来录入的文字； C-y 退出下拉菜单，并接受当前选项。 13.8 多行缩进缩出
正常模式下，按两下>;光标所在行会缩进。 如果先按了n，再按两下>;，光标以下的n行会缩进。 对应的，按两下&lt;;，光标所在行会缩出。 如果在编辑代码文件，可以用=进行调整。 在可视模式下，选择要调整的代码块，按=，代码会按书写规则缩排好。 或者n =，调整n行代码的缩排。 13.9 折叠
zf &ndash; 创建折叠的命令，可以在一个可视区域上使用该命令； zd &ndash; 删除当前行的折叠； zD &ndash; 删除当前行的折叠； zfap &ndash; 折叠光标所在的段； zo &ndash; 打开折叠的文本； zc &ndash; 收起折叠； za &ndash; 打开/关闭当前折叠； zr &ndash; 打开嵌套的折行； zm &ndash; 收起嵌套的折行； zR (zO) &ndash; 打开所有折行； zM (zC) &ndash; 收起所有折行； zj &ndash; 跳到下一个折叠处； zk &ndash; 跳到上一个折叠处； zi &ndash; enable/disable fold; 14. 命令行
normal模式下按:进入命令行模式
14.1 命令行模式下的快捷键：
上下方向键：上一条或者下一条命令。如果已经输入了部分命令，则找上一 条或者下一条匹配的命令。 左右方向键：左/右移一个字符。 C-w： 向前删除一个单词。 C-h： 向前删除一个字符，等同于Backspace。 C-u： 从当前位置移动到命令行开头。 C-b： 移动到命令行开头。 C-e： 移动到命令行末尾。 Shift-Left： 左移一个单词。 Shift-Right： 右移一个单词。 @： 重复上一次的冒号命令。 q： 正常模式下，q然后按&rsquo;:&rsquo;，打开命令行历史缓冲区， 可以像编辑文件一样编辑命令。 q/和q? 可以打开查找历史记录。 14.2 执行外部命令
:! cmd 执行外部命令。 :!! 执行上一次的外部命令。 :sh 调用shell，用exit返回vim。 :r !cmd 将命令的返回结果插入文件当前位置。 :m,nw !cmd 将文件的m行到n行之间的内容做为命令输入执行命令。 15. 其它
15.1 工作目录
:pwd 显示vim的工作目录。 :cd path 改变vim的工作目录。 :set autochdir 可以让vim 根据编辑的文件自动切换工作目录。 15.2 一些快捷键（收集中）
K: 打开光标所在词的manpage。 *: 向下搜索光标所在词。 g*: 同上，但部分符合即可。 #: 向上搜索光标所在词。 g#: 同上，但部分符合即可。 g C-g: 统计全文或统计部分的字数。 15.3 在线帮助
:h(elp)或F1 打开总的帮助。 :help user-manual 打开用户手册。 命令帮助的格式为：第一行指明怎么使用那个命令； 然后是缩进的一段解释这个命令的作用，然后是进一步的信息。 :helptags somepath 为somepath中的文档生成索引。 :helpgrep 可以搜索整个帮助文档，匹配的列表显示在quickfix窗口中。 Ctrl+] 跳转到tag主题，Ctrl+t 跳回。 :ver 显示版本信息。 15.4 一些小功能
简单计算器: 在插入模式下，输入C-r =，然后输入表达式，就能在 光标处得到计算结果。 vim命令小技巧 保存文件并退出 说起来有些惭愧，我也是最近才学到这个命令 x
和下面的命令是等价的： wq
都是保存当前文件并退出。
（译者注：这两个命令实际上并不完全等价，当文件被修改时两个命令时相同的。但如果未被修改，使用 : x 不会更改文件的修改时间，而使用 :wq 会改变文件的修改时间。）
基本计算器 在插入模式下，你可以使用 Ctrl+r 键然后输入 =，再输入一个简单的算式。按 Enter 键，计算结果就会插入到文件中。例如，尝试输入：
Ctrl+r '=2+2' ENTER 然后计算结果“4 ”会被插入到文件中。
查找重复的连续的单词 当你很快地打字时，很有可能会连续输入同一个单词两次，就像 this this。这种错误可能骗过任何一个人，即使是你自己重新阅读一遍也不可避免。幸运的是，有一个简单的正则表达式可以用来预防这个错误。使用搜索命令（默认是 /）然后输入：
这会显示所有重复的单词。要达到最好的效果，不要忘记把下面的命令：
set hlsearch 放到你的 .vimrc 文件中高亮所有的匹配。
缩写
一个很可能是最令人印象深刻的窍门是你可以在 Vim 中定义缩写，它可以实时地把你输入的东西替换为另外的东西。语法格式如下：
:ab [缩写] [要替换的文字] 一个通用的例子是：
:ab asap as soon as possible 会把你输入的 “asap” 替换为 “as soon as possible”。
在你忘记用 root 方式打开文件时的文件保存 这可能是一个在论坛中一直受欢迎的命令。每当你打开一个你没有写入权限的文件（比如系统配置文件）并做了一些修改，Vim 无法通过普通的 “:w” 命令来保存。
你不需要重新以 root 方式打开文件再进行修改，只需要运行：
:w !sudo tee % 这会直接以 root 方式保存。
实时加密文本 如果你不想让别人看懂你的屏幕上的内容，你可以使用一个内置的选项，通过下面的命令使用 ROT13
来对文本进行编码：
ggVGg? gg 把光标移动到 Vim 缓冲区的第一行，V 进入可视模式，G 把光标移动到缓冲区的最后一行。因此，ggVG 使可视模式覆盖这个当前缓冲区。最后 g? 使用 ROT13 对整个区域进行编码。
注意它可以被映射到一个最常使用的键。它对字母符号也可以很好地工作。要对它进行撤销，最好的方法就是使用撤销命令：u。
自动补全 这是另外一个令我感到惭愧的功能，但我发现周围很多人并不知道。Vim 默认有自动补全的功能。的确这个功能是很基本的，并且可以通过插件来增强，但它也很有帮助。方法很简单。Vim 尝试通过已经输入的单词来预测单词的结尾。比如当你在同一个文件中第二次输入 “compiler” 时，仅仅输入 “com” 然后保持在插入模式，按 Ctrl+n 键就可以看到 Vim 为你补全了单词。很简单，但也很有用。
比较两个文件的不同 你们中的大多数很可能都知道 vimdiff 命令，它可以使用分离模式打开 Vim 并比较两个文件的不同。语法如下：
$ vimdiff [文件1] [文件2] 但同样的结果也可以通过下面的 Vim 命令来获得：
:diffthis 首先在 Vim 中打开原始文件。然后使用分离模式带来第二个文件：
:vsp [文件2] 最后在第一个缓冲区里输入：
:diffthis 通过 Ctrl+w 来切换缓冲区并再次输入：
:diffthis 这样两个文件中不同的部分就会被高亮。
（译者注：可以直接在一个缓冲区里使用命令 :windo diffthis，而不用输入 :diffthis 两次）
要停止比较，使用：
:diffoff 按时间回退文件 Vim 会记录文件的更改，你很容易可以回退到之前某个时间。该命令是相当直观的。比如：
:earlier 1m 会把文件回退到 1 分钟以前的状态。
注意，你可以使用下面的命令进行相反的转换：
:later 删除标记内部的文字 当我开始使用 Vim 时，一件我总是想很方便做的事情是如何轻松的删除方括号或圆括号里的内容。转到开始的标记，然后使用下面的语法：
di[标记] 比如，把光标放在开始的圆括号上，使用下面的命令来删除圆括号内的文字：
di( 如果是方括号或者是引号，则使用：
di{ 和：
di" 删除指定标记前的内容 和删除标记内部有些相似，但目的不同。命令如下：
dt[标记] 会删除所有光标和标记之间的内容（保持标记不动），如果在同一行有这个标记的话。例如
dt. 会删除至句子的末尾，但保持 ‘.’ 不动。
把 Vim 变为十六进制编辑器 这不是我最喜欢的窍门，但有时会很有趣。你可以把 Vim 和 xxd 功能连起来来把文件转换为十六进制模式。命令如下：
:%!xxd 类似的，你可以通过下面的命令恢复原来的状态：
:%!xxd -r 把光标下的文字置于屏幕中央 我们所要做的事情如标题所示。如果你想强制滚动屏幕来把光标下的文字置于屏幕的中央，在可视模式中使用命令（译者注：在普通模式中也可以）：
zz
跳到上一个／下一个位置 当你编辑一个很大的文件时，经常要做的事是在某处进行修改，然后跳到另外一处。如果你想跳回之前修改的地方，使用命令：
Ctrl+o 来回到之前修改的地方
类似的：
Ctrl+i 会回退上面的跳动。
把当前文件转化为网页 这会生成一个 HTML 文件来显示文本，并在分开的窗口显示源代码：
:%TOhtml</content></entry><entry><title>Linux(CentOS 7)系统四种安装软件的方式及mysql5.7的详细安装配置</title><url>/post/linuxcentos-7%E7%B3%BB%E7%BB%9F%E5%9B%9B%E7%A7%8D%E5%AE%89%E8%A3%85%E8%BD%AF%E4%BB%B6%E7%9A%84%E6%96%B9%E5%BC%8F%E5%8F%8Amysql5.7%E7%9A%84%E8%AF%A6%E7%BB%86%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/</url><categories><category>Linux</category><category>tool</category></categories><tags><tag>Linux</tag><tag>mysql</tag><tag>rpm</tag><tag>yum</tag><tag>CentOS 7</tag></tags><content type="html"> 本文以安装mysql为例介绍了Linux(CentOS 7)环境下安装软件的四种方式，比较四种方式的难易程度，以及详细介绍了mysql5.7的安装和配置方法
Linux安装软件的四种方式介绍 四种方式：rpm命令、yum命令、带bin目录的tar安装包和source源码编译安装
四种方式比较 rpm与yum为命令安装，不同的是npm在安装时需要手动下载依赖包，而yum会自动下载依赖
带bin的tar包和source源码安装区别是前者是编译好的，bin文件夹中就是编译之后的二进制可执行文件，后者需要自己手动编译
四种方式操作说明 rpm与yum命令对比（yum简单，rpm复杂） RPM 全名 RedHat Package Managerment，是由Red Hat公司提出，被众多Linux发行版本所采用，是一种数据库记录的方式来将所需要的软件安装到到Linux系统的一套软件管理机制
rpm在安装时有严格的顺序限制，包与包有依赖关系，且安装过程中可能依赖别的包需要手动安装，而yum安装某个功能（例如mysql的server端）会自动下载安装依赖
安装软件：rpm -ivh [软件包名称] 卸载软件：rpm -e [软件包名称] 更新软件：rpm -Uvh [软件包名称]
yum check-update：列出所有可更新的软件清单命令;
yum update：更新所有软件或指定软件命令;
yum install ：仅安装指定的软件命令；
yum list：列出所有可安装的软件清单命令；
yum remove ：删除软件包命令；
yum search ：查找软件包命令：
以安装mysql为例，对比yum和rpm的安装过程
①查看是否安装了mysql/mariadb的服务
[root@localhost ~]# rpm -qa |grep -i mysql MySQL-client-5.6.23-1.sles11.x86_64 MySQL-server-5.6.23-1.sles11.x86_64 MySQL-shared-5.6.23-1.sles11.x86_64 MySQL-devel-5.6.23-1.sles11.x86_64 ... [root@localhost ~]# root@# rpm -qa |grep -i mariadb ... ②如果安装需要卸载所有服务
[root@localhost ~]# rpm -e --nodeps MySQL-client-5.6.23-1.sles11.x86_64 [root@localhost ~]# rpm -e --nodeps MySQL-server-5.6.23-1.sles11.x86_64 ... ③使用命令或者去mysql官网下载rpm包
yum安装mysql需要先下载一个基础包安装 [root@localhost ~]# wget -i -c http://dev.mysql.com/get/mysql57-community-release-el7-10.noarch.rpm rpm安装需要下载bundle包（rpm文件打包合集）
rpm Bundle表示rpm的打包合集，包含基础包，lib包，client,server 等包如下图
④安装：
yum方式
先安装基础包： [root@localhost ~]# yum install y mysql57-community-release-el7-10.noarch.rpm [root@localhost ~]# yum install mysql-community-server --nogpgcheck --安装完毕 rpm
rpm需要依次安装bundle包中的rpm包，包括基础包，库，client和server等 安装mysql-server服务，只需要安装如下4个软件包即可，使⽤rpm -ivh进⾏安装（按顺序安装，后⾯的 服务依赖前⾯的服务 [root@localhost ~]# rpm -ivh mysql-community-common-5.7.23-1.el7.x86_64.rpm [root@localhost ~]# rpm -ivh mysql-community-libs-5.7.23-1.el7.x86_64.rpm [root@localhost ~]# rpm -ivh mysql-community-client-5.7.23-1.el7.x86_64.rpm [root@localhost ~]# rpm -ivh mysql-community-server-5.7.23-1.el7.x86_64.rpm 安装时如果出现缺少依赖，如少libaio、net-tools还需要yum install [名称]来安装依赖 ⑤启动mysql，设置密码
1、[root@localhost ~]# systemctl start mysqld.service -->启动mysql 2、[root@localhost ~]# grep "password" /var/log/mysqld.log -->查看密码 CSLQ:F=Um5i1 A temporary password is generated for root@localhost: CSLQ:F=Um5i1 3、[root@localhost ~]# mysql -uroot -p -->登录root用户 4、[root@localhost ~]# CSLQ:F=Um5i1 -->输入密码 5、登录进mysql之后设置密码规则(不设置有可能无法修改成简单密码) set global validate_password_policy=0; set global validate_password_length=1; 6、ALTER USER 'root'@'localhost' IDENTIFIED BY 'root'; -->修改密码为root ⑥查找并修改mysql配置文件
1、[root@localhost ~]# which mysql -->查找mysql命令在什么位置 usr/bin/mysql 2.[root@localhost ~]# /usr/bin/mysql --verbose --help | grep -A 1 'Default options' Default options are read from the following files in the given order: /etc/mysql/my.cnf /etc/my.cnf ~/.my.cnf 返回信息表示首先读取的是/etc/mysql/my.cnf文件，如果前一个文件不存在则继续读/etc/my.cnf文件，如若还不存在便会去读~/.my.cnf文件,这三处即是mysql配置文件存放处，找到修改即可 默认配置文件如下： # For advice on how to change settings please see # http://dev.mysql.com/doc/refman/5.7/en/server-configuration-defaults.html [mysqld] # # Remove leading # and set to the amount of RAM for the most important data # cache in MySQL. Start at 70% of total RAM for dedicated server, else 10%. # innodb_buffer_pool_size = 128M # # Remove leading # to turn on a very important data integrity option: logging # changes to the binary log between backups. # log_bin # # Remove leading # to set options mainly useful for reporting servers. # The server defaults are faster for transactions and fast SELECTs. # Adjust sizes as needed, experiment to find the optimal values. # join_buffer_size = 128M # sort_buffer_size = 2M # read_rnd_buffer_size = 2M datadir=/var/lib/mysql socket=/var/lib/mysql/mysql.sock # Disabling symbolic-links is recommended to prevent assorted security risks symbolic-links=0 log-error=/var/log/mysqld.log pid-file=/var/run/mysqld/mysqld.pid 已编译tar包(带bin目录的tar)和source源码安装区别是前者是编译好的，bin文件夹中就是编译之后的二进制可执行文件，后者需要自己手动编译
①带bin的tar包安装
1、[root@localhost ~]# tar -xvf mysql-5.7.26-linux-glibc2.12-x86_64.tar 2、[root@localhost ~]# cp -r mysql-5.7.26-linux-glibc2.12-x86_64 /usr/local/mysql -->拷贝文件夹到/usr/local目录下并重命名为mysql 3、[root@localhost ~]# mkdir /usr/local/mysql/data /usr/local/mysql/logs -->创建data和logs文件夹 4、[root@localhost ~]# groupadd mysql -->添加mysql用户组 5、[root@localhost ~]# useradd -r -g mysql mysql -->向mysql用户组添加mysql用户，-r &lt;参数表示mysql用户是系统用户，不可用于登录系统，-g 参数表示把mysql用户添加到mysql用户组中 6、chown -R mysql:mysql /usr/local/mysql/ -->将mysql目录权限分配给mysql用户组下的mysql用户 已编译tar包安装需要新建mysql用户和用户组，并将mysql目录权限分配给用户，若不进行此操作，在mysql服务启动时会报Starting MySQL. ERROR! The server quit without updating PID file错误 7、[root@localhost ~]# vim /etc/my.cnf -->在/etc下新增配置文件 [mysqld] port = 3306 user = mysql basedir = /usr/local/mysql datadir = /usr/local/mysql/data socket = /usr/local/mysql/data/mysql.sock bind-address = 0.0.0.0 pid-file = /usr/local/mysql/data/mysqld.pid character-set-server = utf8 collation-server = utf8_general_ci max_connections = 200 log-error = /usr/local/mysql/logs/mysqld.log 8、[root@localhost ~]# cd /usr/local/mysql/bin/ -->进入mysql的bin目录 9、[root@localhost ~]#./mysqld --defaults-file=/etc/my.cnf --user=mysql --basedir=/usr/local/mysql/ --datadir=/data/mysql/ --initialize -->初始化 10、[root@localhost ~]# cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysql -->将mysql.server放置到/etc/init.d/mysql中 11、[root@localhost ~]# service mysql start -->启动服务 12、[root@localhost ~]# cat /usr/local/mysql/logs/mysqld.log -->日志最后一行有随机生成的初始密码,可登录mysql 13、[root@localhost ~]# ln -s /usr/local/mysql/bin/mysql /usr/bin -->创建软连接到/usr/bin可以全局使用mysql命令(方便登录mysql) 14、[root@localhost ~]# mysql -uroot -p -->登录mysql 15、[root@localhost ~]# 输入12步得到的密码，登录mysql 16、若登录出现Can't connect to local MySQL server through socket '/tmp/mysql.sock' (2)，需要将mysql.sock软连接到tmp目录即可 [root@localhost ~]# ln -s /usr/local/mysql/data/mysql.sock /tmp ②source源码安装
(1)创建安装目录 [root@localhost ~]# mkdir /usr/local/mysql/{data,logs,tmp,run} -p (2）首先安装源码编译所需要的包 [root@localhost ~]# yum -y install make gcc-c++ cmake bison-devel ncurses-devel (3)解压 [root@localhost ~]# tar -zxvf mysql-5.7.27.tar.gz [root@localhost ~]# tar -zxvf mysql-boost-5.7.27.tar.gz #（不需要安装，在安装mysql时自动安装，） 两个文件解压以后都会在同一个目录上 mysql-5.7.27 (4)编译安装（编译参数按实际情况制定） cd mysql-5.7.27 cmake . \ -DCMAKE_INSTALL_PREFIX=/usr/local/mysql/ \ -DMYSQL_DATADIR=/usr/local/mysql/data \ -DDOWNLOAD_BOOST=1 \ -DWITH_BOOST=/opt/software/mysql-5.7.27/boost \ -DSYSCONFDIR=/etc \ -DWITH_INNOBASE_STORAGE_ENGINE=1 \ -DWITH_PARTITION_STORAGE_ENGINE=1 \ -DWITH_FEDERATED_STORAGE_ENGINE=1 \ -DWITH_BLACKHOLE_STORAGE_ENGINE=1 \ -DWITH_MYISAM_STORAGE_ENGINE=1 \ -DENABLED_LOCAL_INFILE=1 \ -DMYSQL_UNIX_ADDR=/usr/local/mysql/run/mysql.sock \ -DENABLE_DTRACE=0 \ -DDEFAULT_CHARSET=utf8 \ -DDEFAULT_COLLATION=utf8_general_ci \ -DWITH_EMBEDDED_SERVER=1 make &amp; make install (5)/etc/my.cnf配置mysql (6) ./mysqld --defaults-file=/etc/my.cnf --initialize #初始化 (7) cp support-files/mysql.server /etc/init.d/mysql #启动项设置 (8) service mysqld start (9)登录不在赘述 ​</content></entry><entry><title>Markdown语法手册</title><url>/post/markdown-syntax/</url><categories><category>themes</category><category>syntax</category></categories><tags><tag>markdown</tag><tag>css</tag><tag>html</tag></tags><content type="html"> 本文提供了一个可以在 Hugo 内容文件中使用的基本Markdown语法示例，还展示了基本 HTML 元素在 Hugo 主题中是否使用 CSS 装饰。
标题 下面的 HTML 代码&lt;h1>—&lt;h6> 元素表示六个级别的节标题。 &lt;h1>是最高的节级别，&lt;h6>是最低的节级别。
H1 H2 H3 H4 H5 H6 段落 生活是什么？生活是柴米油盐的平淡；是行色匆匆早出晚归的奔波；生活是错的时间遇到对的人的遗憾；是爱的付出与回报；生活是看不同的风景，遇到不同的人；是行至水穷尽，坐看云起时的峰回路转；生活是灵魂经历伤痛后的微笑怒放；是挫折坎坷被晾晒后的坚强；生活是酸甜苦辣被岁月沉淀后的馨香；是经历风霜雪雨洗礼后的懂得；生活是走遍千山万水后，回眸一笑的洒脱。
有些事，猝不及防，不管你在不在乎；有些人，并非所想，不管你明不明白；有些路，必须得走，不管你愿不愿意。不怕事，不惹事，不避事，做好自己，用真心面对一切；少埋怨，少指责，少发火，学会沉静，用微笑考量一切；多体察，多包容，多思索，尽心尽力，虽缺憾但无悔。像蒲公英一样美丽，虽轻盈，但并不卑微，它有自己的生命，也有自己的世界！
引用 blockquote 元素表示从另一个来源引用的内容，可选的引用必须在 footer 或 cite元素内，也可选的内嵌更改，如注释和缩写。
引用没有归属 读懂自我，带着简单的心情，看复杂的人生，走坎坷的路！
注意： 可以在块引用中使用 Markdown 语法。
带归属的引用 不要通过分享记忆来交流，通过交流来分享记忆。
— 罗布·派克1
表格 表不是Markdown核心规范的一部分，但是Hugo支持开箱即用。
Name Age Bob 27 Alice 23 表格内使用Markdown语法 Italics Bold Code italics bold code 图像 ![图像描述](图像地址) 示例 常规用法 SVG图像 Google Chrome
Firefox Browser
小图标
点击图像可以打开图像浏览器，快试试吧。
代码块 带有引号的代码块 &lt;!doctype html> &lt;html lang="en"> &lt;head> &lt;meta charset="utf-8"> &lt;title>Example HTML5 Document&lt;/title> &lt;/head> &lt;body> &lt;p>Test&lt;/p> &lt;/body> &lt;/html> 用四个空格缩进的代码块 &lt;!doctype html>
&lt;html lang="en">
&lt;head>
&lt;meta charset="utf-8">
&lt;title>Example HTML5 Document&lt;/title>
&lt;/head>
&lt;body>
&lt;p>Test&lt;/p>
&lt;/body>
&lt;/html>
代码块引用Hugo的内部高亮短代码 &lt;!doctype html> &lt;html lang="en"> &lt;head> &lt;meta charset="utf-8"> &lt;title>Example HTML5 Document&lt;/title> &lt;/head> &lt;body> &lt;p>Test&lt;/p> &lt;/body> &lt;/html> 列表类型 有序列表 First item Second item Third item 无序列表 List item Another item And another item 嵌套列表 Fruit Apple Orange Banana Dairy Milk Cheese 其他元素 — abbr, sub, sup, kbd, mark GIF 是位图图像格式。
H2O
Xn + Yn = Zn
按 CTRL+ALT+Delete 组合键结束会话。
大多数蝾螈在夜间活动，捕食昆虫、蠕虫和其他小动物。
以上引文摘自Rob Pike在2015年11月18日 Gopherfest 上的演讲
。&#160;&#8617;&#xfe0e;</content></entry><entry><title>富文本内容测试pp</title><url>/post/rich-content/</url><categories/><tags><tag>shortcodes</tag><tag>privacy</tag></tags><content type="html"> Hugo 上有几个内置短码
，用于丰富内容，以及隐私配置
还有一组简单的短代码，支持各种社交媒体嵌入的静态和非 JS 版本。
YouTube 增强隐私短码 {{/&lt; youtube ZJthWmvUzzc >/}}
Twitter 短码 {{/&lt; twitter_simple 1085870671291310081 >/}}
Vimeo 短码 {{/&lt; vimeo_simple 48912912 >/}}
哔哩哔哩短码</content></entry><entry><title>图像占位符显示</title><url>/post/placeholder-text/</url><categories/><tags><tag>markdown</tag><tag>text</tag></tags><content type="html"> 范德格拉夫原理（Van de Graaf Canon）重构了曾经用于书籍设计中将页面划分为舒适比例的方法。这一原理也被称为“秘密原理”，用于许多中世纪的手稿和古板书中。在范德格拉夫原理中，文本区域和页面的长款具有相同的比例，并且文本区域的高度等于页面宽度，通过划分页面得到九分之一的订口边距和九分之二的切口边距，以及与页面长宽相同的比例的文本区域。
Vagus 示例
The Van de Graaf Canon
总结 当然设计中的黄金比例是为人所熟知的，黄金分割的公式为a:b=b:(a+b)。这是指较小的两个矩形与较大的两个矩形以相同的组合方式相关联。黄金分割比例为1:1.618。</content></entry><entry><title>数据公式设置显示</title><url>/post/math-typesetting/</url><categories/><tags/><content type="html"> Hugo 项目中的数学表示法可以通过使用第三方 JavaScript 库来实现。
在这个例子中，我们将使用 MathJax
创建一个文件 /content/en[zh-CN]/math.md
可以全局启用MathJax，请在项目配置中将参数math设置为true
或是在每页基础上启用MathJax，在内容文件中包括参数math: true
注意： 使用支持的TeX功能
的联机参考资料
例子 重复的分数 $$ \frac{1}{\Bigl(\sqrt{\phi \sqrt{5}}-\phi\Bigr) e^{\frac25 \pi}} \equiv 1+\frac{e^{-2\pi}} {1+\frac{e^{-4\pi}} {1+\frac{e^{-6\pi}} {1+\frac{e^{-8\pi}} {1+\cdots} } } } $$
总和记号 $$ \left( \sum_{k=1}^n a_k b_k \right)^2 \leq \left( \sum_{k=1}^n a_k^2 \right) \left( \sum_{k=1}^n b_k^2 \right) $$
几何级数之和 我把接下来的两个例子分成了几行，这样它在手机上表现得更好。这就是为什么它们包含 \displaystyle。
$$ \displaystyle\sum_{i=1}^{k+1}i $$
$$ \displaystyle= \left(\sum_{i=1}^{k}i\right) +(k+1) $$
$$ \displaystyle= \frac{k(k+1)}{2}+k+1 $$
$$ \displaystyle= \frac{k(k+1)+2(k+1)}{2} $$
$$ \displaystyle= \frac{(k+1)(k+2)}{2} $$
$$ \displaystyle= \frac{(k+1)((k+1)+1)}{2} $$
乘记号 $$ \displaystyle 1 + \frac{q^2}{(1-q)}+\frac{q^6}{(1-q)(1-q^2)}+\cdots = \displaystyle \prod_{j=0}^{\infty}\frac{1}{(1-q^{5j+2})(1-q^{5j+3})}, \displaystyle\text{ for }\lvert q\rvert &lt; 1. $$
随文数式 这是一些线性数学: $$ k_{n+1} = n^2 + k_n^2 - k_{n-1} $$ ， 然后是更多的文本。
希腊字母 $$ \Gamma\ \Delta\ \Theta\ \Lambda\ \Xi\ \Pi\ \Sigma\ \Upsilon\ \Phi\ \Psi\ \Omega \alpha\ \beta\ \gamma\ \delta\ \epsilon\ \zeta\ \eta\ \theta\ \iota\ \kappa\ \lambda\ \mu\ \nu\ \xi \ \omicron\ \pi\ \rho\ \sigma\ \tau\ \upsilon\ \phi\ \chi\ \psi\ \omega\ \varepsilon\ \vartheta\ \varpi\ \varrho\ \varsigma\ \varphi $$
箭头 $$ \gets\ \to\ \leftarrow\ \rightarrow\ \uparrow\ \Uparrow\ \downarrow\ \Downarrow\ \updownarrow\ \Updownarrow $$
$$ \Leftarrow\ \Rightarrow\ \leftrightarrow\ \Leftrightarrow\ \mapsto\ \hookleftarrow \leftharpoonup\ \leftharpoondown\ \rightleftharpoons\ \longleftarrow\ \Longleftarrow\ \longrightarrow $$
$$ \Longrightarrow\ \longleftrightarrow\ \Longleftrightarrow\ \longmapsto\ \hookrightarrow\ \rightharpoonup $$
$$ \rightharpoondown\ \leadsto\ \nearrow\ \searrow\ \swarrow\ \nwarrow $$
符号 $$ \surd\ \barwedge\ \veebar\ \odot\ \oplus\ \otimes\ \oslash\ \circledcirc\ \boxdot\ \bigtriangleup $$
$$ \bigtriangledown\ \dagger\ \diamond\ \star\ \triangleleft\ \triangleright\ \angle\ \infty\ \prime\ \triangle $$
微积分学 $$ \int u \frac{dv}{dx},dx=uv-\int \frac{du}{dx}v,dx $$
$$ f(x) = \int_{-\infty}^\infty \hat f(\xi),e^{2 \pi i \xi x} $$
$$ \oint \vec{F} \cdot d\vec{s}=0 $$
洛伦茨方程 $$ \begin{aligned} \dot{x} &amp; = \sigma(y-x) \ \dot{y} &amp; = \rho x - y - xz \ \dot{z} &amp; = -\beta z + xy \end{aligned} $$
交叉乘积 这在KaTeX中是可行的，但在这种环境中馏分的分离不是很好。
$$ \mathbf{V}_1 \times \mathbf{V}_2 = \begin{vmatrix} \mathbf{i} &amp; \mathbf{j} &amp; \mathbf{k} \ \frac{\partial X}{\partial u} &amp; \frac{\partial Y}{\partial u} &amp; 0 \ \frac{\partial X}{\partial v} &amp; \frac{\partial Y}{\partial v} &amp; 0 \end{vmatrix} $$
这里有一个解决方案:使用“mfrac”类(在MathJax情况下没有区别)的额外类使分数更小:
$$ \mathbf{V}_1 \times \mathbf{V}_2 = \begin{vmatrix} \mathbf{i} &amp; \mathbf{j} &amp; \mathbf{k} \ \frac{\partial X}{\partial u} &amp; \frac{\partial Y}{\partial u} &amp; 0 \ \frac{\partial X}{\partial v} &amp; \frac{\partial Y}{\partial v} &amp; 0 \end{vmatrix} $$
强调 $$ \hat{x}\ \vec{x}\ \ddot{x} $$
有弹性的括号 $$ \left(\frac{x^2}{y^3}\right) $$
评估范围 $$ \left.\frac{x^3}{3}\right|_0^1 $$
诊断标准 $$ f(n) = \begin{cases} \frac{n}{2}, &amp; \text{if } n\text{ is even} \ 3n+1, &amp; \text{if } n\text{ is odd} \end{cases} $$
麦克斯韦方程组 $$ \begin{aligned} \nabla \times \vec{\mathbf{B}} -, \frac1c, \frac{\partial\vec{\mathbf{E}}}{\partial t} &amp; = \frac{4\pi}{c}\vec{\mathbf{j}} \ \nabla \cdot \vec{\mathbf{E}} &amp; = 4 \pi \rho \ \nabla \times \vec{\mathbf{E}}, +, \frac1c, \frac{\partial\vec{\mathbf{B}}}{\partial t} &amp; = \vec{\mathbf{0}} \ \nabla \cdot \vec{\mathbf{B}} &amp; = 0 \end{aligned} $$
这些方程式很狭窄。我们可以使用(例如)添加垂直间距 [1em] 在每个换行符(\)之后。正如你在这里看到的：
$$ \begin{aligned} \nabla \times \vec{\mathbf{B}} -, \frac1c, \frac{\partial\vec{\mathbf{E}}}{\partial t} &amp; = \frac{4\pi}{c}\vec{\mathbf{j}} \[1em] \nabla \cdot \vec{\mathbf{E}} &amp; = 4 \pi \rho \[0.5em] \nabla \times \vec{\mathbf{E}}, +, \frac1c, \frac{\partial\vec{\mathbf{B}}}{\partial t} &amp; = \vec{\mathbf{0}} \[1em] \nabla \cdot \vec{\mathbf{B}} &amp; = 0 \end{aligned} $$
统计学 固定词组：
$$ \frac{n!}{k!(n-k)!} = {^n}C_k {n \choose k} $$
分数在分数 $$ \frac{\frac{1}{x}+\frac{1}{y}}{y-z} $$
ｎ次方根 $$ \sqrt[n]{1+x+x^2+x^3+\ldots} $$
矩阵 $$ \begin{pmatrix} a_{11} &amp; a_{12} &amp; a_{13}\ a_{21} &amp; a_{22} &amp; a_{23}\ a_{31} &amp; a_{32} &amp; a_{33} \end{pmatrix} \begin{bmatrix} 0 &amp; \cdots &amp; 0 \ \vdots &amp; \ddots &amp; \vdots \ 0 &amp; \cdots &amp; 0 \end{bmatrix} $$
标点符号 $$ f(x) = \sqrt{1+x} \quad (x \ge -1) f(x) \sim x^2 \quad (x\to\infty) $$
现在用标点符号:
$$ f(x) = \sqrt{1+x}, \quad x \ge -1 f(x) \sim x^2, \quad x\to\infty $$</content></entry><entry><title>关于我</title><url>/about.html</url><categories/><tags/><content type="html"> Hugo是用Go编写的一个开放源代码静态站点生成器，可在Apache许可证2.0
下使用。 Hugo支持TOML, YAML和JSON数据文件类型，Markdown和HTML内容文件，并使用短代码添加丰富的内容。其他值得注意的功能包括分类法、多语言模式、图像处理、自定义输出格式、HTML/CSS/JS缩小和对Sass SCSS工作流的支持。
Hugo使用了多种开源项目，包括:
https://github.com/yuin/goldmark
https://github.com/alecthomas/chroma
https://github.com/muesli/smartcrop
https://github.com/spf13/cobra
https://github.com/spf13/viper
Hugo是博客、企业网站、创意作品集、在线杂志、单页应用程序甚至是数千页的网站的理想选择。
Hugo适合那些想要手工编写自己的网站代码，而不用担心设置复杂的运行时、依赖关系和数据库的人。
使用Hugo建立的网站非常快速、安全，可以部署在任何地方，包括AWS、GitHub Pages、Heroku、Netlify和任何其他托管提供商。
更多信息请访问GitHub
.</content></entry></search>